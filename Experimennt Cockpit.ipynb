{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828f58a6",
   "metadata": {},
   "source": [
    "# Experimentation Mainframe\n",
    "\n",
    "This notebook automates the synthesis of SHACL constraints from natural language using LLMs, validates their syntax, and evaluates them through scenario-based mutation testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0e9d4",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "This section imports all necessary libraries and modules required for the experimentation framework. It includes standard library modules, third-party packages for graph processing and validation and local utilities from the src directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e86903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import datetime\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Third-party imports\n",
    "import pandas as pd\n",
    "from pyshacl import validate\n",
    "from rdflib import Graph, Namespace\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Local imports\n",
    "from src.llm_utils import GeminiExhaustedException\n",
    "from src.pipeline_core import run_main_pipeline\n",
    "from src.testing_utils import apply_mutations, flush_context_to_csv, parse_validation_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ce611",
   "metadata": {},
   "source": [
    "## Configuration and Context Initialization\n",
    "\n",
    "Here, we define the experiment parameters and a function to set up the initial context for each run. The context tracks metadata, artifacts and results throughout the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration variables for the experiment\n",
    "DOCUMENT_NAME = \"parental_leave\"\n",
    "PROMPT_VERSION = 'Default'\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
    "CSV_FILE = \"Master_Results.csv\"\n",
    "ARTIFACT_DIRECTORY = \"Testing Artifacts\"\n",
    "NUM_RUNS = 1\n",
    "\n",
    "# Create the CSV file if it does not already exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    CSV_HEADERS = [\n",
    "    \"Run ID\", \"Timestamp\", \"Document Name\", \"Prompts\", \"Model Name\",\n",
    "    \"Service Graph Hash\", \"SHACL Graph Hash\", \"SHACL Valid Syntax\",\n",
    "    \"SHACL Error Type\", \"SHACL Error Message\", \"Execution Time\",\n",
    "    \"Scenario ID\", \"Scenario Description\", \"Expected Violation Count\",\n",
    "    \"Actual Violation Count\", \"Violated Shapes\", \"Violation Messages\",\n",
    "    \"Successfully Executed\"\n",
    "    ]\n",
    "    pd.DataFrame(columns=CSV_HEADERS).to_csv(CSV_FILE, index=False)\n",
    "\n",
    "# Determine the next run ID by checking the existing CSV\n",
    "df = pd.read_csv(CSV_FILE, usecols=[0])\n",
    "if df.empty:\n",
    "    last_run_id = 0\n",
    "else: \n",
    "    last_run_id = df.iloc[:, 0].max()\n",
    "\n",
    "# Function to initialize the context dictionary for a single experiment run\n",
    "def initialize_run_context(run_id, doc_name, model_name):\n",
    "    return {\n",
    "        # Metadata section\n",
    "        \"Run ID\": run_id,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(sep=\" \", timespec=\"seconds\"),\n",
    "        \"Document Name\": doc_name,\n",
    "        \"Prompts\":  PROMPT_VERSION,\n",
    "        \"Model Name\": model_name,\n",
    "        \n",
    "        # Pipeline artifacts placeholders\n",
    "        \"Service Graph Hash\": \"N/A\",\n",
    "        \"SHACL Graph Hash\": \"N/A\",\n",
    "        \"SHACL Valid Syntax\": \"N/A\",\n",
    "        \"SHACL Error Type\": \"N/A\",\n",
    "        \"SHACL Error Message\": \"N/A\",\n",
    "        \"Execution Time\": \"N/A\",\n",
    "        \n",
    "        # Scenario specifics (will be overwritten per scenario)\n",
    "        \"Scenario ID\": \"N/A\",\n",
    "        \"Scenario Description\": \"N/A\",\n",
    "        \"Expected Violation Count\": \"N/A\",\n",
    "        \"Actual Violation Count\": \"N/A\",\n",
    "        \"Violated Shapes\": \"N/A\",\n",
    "        \"Violation Messages\": \"N/A\",\n",
    "        \n",
    "        # Execution stats\n",
    "        \"Successfully Executed\": False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1606f",
   "metadata": {},
   "source": [
    "## Main Experiment Execution\n",
    "\n",
    "The core loop of the experiment runs multiple iterations, each generating SHACL shapes, performing mutations based on the predefined scenarios and validating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main experiment loop\n",
    "with tqdm(total=NUM_RUNS, desc=\"Initializing...\") as pbar:\n",
    "    for run_id in range(last_run_id+1, last_run_id+NUM_RUNS+1):\n",
    "        try:\n",
    "            # Create artifact directory for this run\n",
    "            artifact_dir = f\"{ARTIFACT_DIRECTORY}/RUN_{run_id}_{DOCUMENT_NAME}\" \n",
    "            if not os.path.exists(artifact_dir):\n",
    "                os.makedirs(artifact_dir)\n",
    "            else:\n",
    "                raise FileExistsError(f\"Artifact directory {artifact_dir} already exists. Aborting to prevent overwriting.\")    \n",
    "            \n",
    "            # Initialize context for this run\n",
    "            ctx = initialize_run_context(run_id, DOCUMENT_NAME, GEMINI_MODEL)\n",
    "            \n",
    "            # Run the main pipeline, creating artifacts and updating context\n",
    "            ctx = run_main_pipeline(ctx, artifact_dir, pbar, DOCUMENT_NAME, PROMPT_VERSION, GEMINI_MODEL, run_id)\n",
    "            \n",
    "            if ctx[\"SHACL Valid Syntax\"]: # Begin scenario testing only if SHACL syntax is valid\n",
    "                \n",
    "                # Load the Golden Citizen (Baseline) graph\n",
    "                golden_ttl = f\"Citizens/{DOCUMENT_NAME} eligible.ttl\"\n",
    "                golden_graph = Graph()\n",
    "                golden_graph.parse(golden_ttl, format=\"turtle\")\n",
    "                golden_graph.bind(\"\", Namespace(\"http://example.org/schema#\"))\n",
    "                \n",
    "                # Load SHACL Shapes Graph\n",
    "                shacl_ttl = f\"{artifact_dir}/{DOCUMENT_NAME} shacl shapes.ttl\"\n",
    "                shacl_graph = Graph()\n",
    "                shacl_graph.parse(shacl_ttl, format=\"turtle\")\n",
    "                shacl_graph.bind(\"\", Namespace(\"http://example.org/schema#\"))\n",
    "\n",
    "                # Load the Scenarios from YAML\n",
    "                with open(f\"Citizens/{DOCUMENT_NAME} scenarios.yaml\", \"r\") as f:\n",
    "                    scenarios = yaml.safe_load(f)\n",
    "\n",
    "                # Iterate through each scenario\n",
    "                for scn in scenarios:\n",
    "                    # Set scenario details in context\n",
    "                    ctx[\"Scenario ID\"] = scn['id']\n",
    "                    ctx[\"Scenario Description\"] = scn['description']\n",
    "                    ctx[\"Expected Violation Count\"] = scn['expected_violation_count']\n",
    "                    \n",
    "                    # Apply mutations to create a new mutated graph (leaving golden_graph untouched)\n",
    "                    mutated_graph = apply_mutations(golden_graph, scn['actions'])\n",
    "\n",
    "                    # Validate the mutated graph against SHACL shapes\n",
    "                    conforms, results_graph, results_text = validate(\n",
    "                        data_graph=mutated_graph,\n",
    "                        shacl_graph=shacl_graph,    \n",
    "                        inference='rdfs',\n",
    "                    )\n",
    "                    \n",
    "                    # Parse the validation report\n",
    "                    parse_result = parse_validation_report(conforms, results_graph, results_text, shacl_graph)\n",
    "                    ctx[\"Actual Violation Count\"] = parse_result[\"violation_count\"]\n",
    "                    ctx[\"Violated Shapes\"] = parse_result[\"failed_shapes\"]\n",
    "                    ctx[\"Violation Messages\"] = parse_result[\"messages\"]\n",
    "                    \n",
    "                    # Mark scenario as successfully executed if we made it this far\n",
    "                    ctx[\"Successfully Executed\"] = True\n",
    "                    flush_context_to_csv(ctx, CSV_FILE) \n",
    "            else:\n",
    "                # SHACL syntax was invalid, log and move on to the next run\n",
    "                flush_context_to_csv(ctx, CSV_FILE)\n",
    "                \n",
    "        except GeminiExhaustedException:\n",
    "            # Handle API exhaustion error\n",
    "            print(f\"ðŸ›‘ FATAL: Gemini exhausted too many times. Check your API usage limits.\")\n",
    "            break # Exit the entire run loop\n",
    "                \n",
    "        except Exception as e: \n",
    "            # Handle unexpected errors\n",
    "            ctx[\"Successfully Executed\"] = str(e).replace(\"\\n\", \" \")[:250] # Truncate long error messages\n",
    "            flush_context_to_csv(ctx, CSV_FILE)\n",
    "            \n",
    "        finally:\n",
    "            # Report end of the run to console\n",
    "            status_msg = \"Everything went well!\" if ctx[\"Successfully Executed\"] is True else \"Exited with some errors.\"\n",
    "            pbar.write(f\"Logged Run {ctx['Run ID']} to CSV. {status_msg}\") \n",
    "            pbar.update(1) # Increment progress bar by 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
