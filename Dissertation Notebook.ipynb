{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2121267f",
   "metadata": {},
   "source": [
    "# Experimental notebook for document structured knowledge extraction: Version 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import webbrowser\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import rdflib\n",
    "from rdflib.compare import to_isomorphic\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal\n",
    "from pyvis.network import Network\n",
    "from pyshacl import validate\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6751506",
   "metadata": {},
   "source": [
    "### Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client \n",
    "client = genai.Client()\n",
    "gemini_model = \"gemini-2.5-pro\"\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not found. Add it to a .env file in the notebook root.\")\n",
    "\n",
    "# Which document we'll be testing\n",
    "document_name = \"student_housing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3480ed",
   "metadata": {},
   "source": [
    "Aux functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf0cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation in general\n",
    "def call_gemini(content):\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents = content\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# Document understanding \n",
    "def call_gemini_pdf(content, file_name):    \n",
    "    # Retrieve and encode the PDF byte\n",
    "    file_path = Path(file_name)\n",
    "\n",
    "    # Upload the PDF using the File API\n",
    "    content_file = client.files.upload(file = file_path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents=[content_file, content]\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# JSON structured output\n",
    "def call_gemini_json(content, schema):\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents=content,\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": schema\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# Read txt file into a string (used for prompts)\n",
    "def read_txt(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "# Read a JSON file and return it as string or raw JSON\n",
    "def read_json(path, raw = False):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    if (raw):\n",
    "        return json_file\n",
    "    # Else, convert JSON to string \n",
    "    return json.dumps(json_file, indent=2)\n",
    "\n",
    "# Retry wrapper to combat model overload errors\n",
    "def with_retries(func, *args, base_delay=4.0):\n",
    "    overloads = 0    \n",
    "    exhaustions = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except Exception as e:\n",
    "            msg = str(e).lower()\n",
    "            overloaded = \"overloaded\" in msg\n",
    "            exhausted = \"exhausted\" in msg            \n",
    "            if overloaded:\n",
    "                overloads += 1\n",
    "                wait = base_delay * (2 ** overloads)\n",
    "                print(f\"Gemini overloaded {overloads} times, retrying in {wait:.1f}s...\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            elif exhausted:\n",
    "                exhaustions +=1\n",
    "                print(f\"Gemini exhausted {exhaustions} times, waiting 1 minute and rerunning the code...\")\n",
    "                time.sleep(60) \n",
    "                overloads = 0                \n",
    "                continue          \n",
    "            # Anything else\n",
    "            raise\n",
    "\n",
    "# Pyvis graph visualization\n",
    "def visualize_graph(ttl_file):\n",
    "    # Load TTL file\n",
    "    g = Graph()\n",
    "    g.parse(ttl_file, format=\"turtle\")  \n",
    "\n",
    "    # Namespace\n",
    "    CCCEV = Namespace(\"http://data.europa.eu/m8g/\")\n",
    "    CPSV = Namespace(\"http://purl.org/vocab/cpsv#\")\n",
    "    EX = Namespace(\"http://example.org/\")\n",
    "    SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "    net = Network(height=\"1440px\", width=\"100%\", notebook=True, directed=True)\n",
    "    net.force_atlas_2based()\n",
    "\n",
    "    # Just visual effects\n",
    "    def node_color(uri):\n",
    "        if (uri, RDF.type, CPSV.PublicService) in g:\n",
    "            return \"gold\"\n",
    "        if (uri, RDF.type, CCCEV.Constraint) in g:\n",
    "            return \"maroon\"\n",
    "        if (uri, RDF.type, CCCEV.InformationConcept) in g:\n",
    "            return \"darkturquoise\"\n",
    "        if (uri, RDF.type, SC.Applicant) in g:\n",
    "            return \"yellowgreen\"\n",
    "        return \"lightgrey\"\n",
    "\n",
    "    # Just a way to make the graph more readable\n",
    "    def node_label(uri):\n",
    "        if isinstance(uri, Literal):\n",
    "            return str(uri)\n",
    "\n",
    "        for lbl in g.objects(uri, RDFS.label):\n",
    "            return str(lbl)\n",
    "        for lbl in g.objects(uri, CCCEV.name):\n",
    "            return str(lbl)\n",
    "\n",
    "        uri_str = str(uri).rstrip('/') # <--- SAFETY FIX\n",
    "        if \"#\" in uri_str:\n",
    "            return uri_str.split(\"#\")[-1]\n",
    "        return uri_str.split(\"/\")[-1]\n",
    "\n",
    "    # Add nodes and edges, skipping rdf:type for extra readability\n",
    "    for s, p, o in g:\n",
    "        if p == RDF.type:\n",
    "            continue\n",
    "\n",
    "        # Subject\n",
    "        net.add_node(str(s), label=node_label(s), color=node_color(s))\n",
    "\n",
    "        # Object\n",
    "        if isinstance(o, Literal):\n",
    "            net.add_node(str(o), label=node_label(o), color=\"beige\", shape=\"box\") # if it's a literal put it in a text box instead of a circular node\n",
    "        else:\n",
    "            net.add_node(str(o), label=node_label(o), color=node_color(o))\n",
    "\n",
    "        # Edge\n",
    "        net.add_edge(str(s), str(o), label=node_label(p), arrows=\"to\")\n",
    "\n",
    "    html_file = ttl_file.replace(\"ttl\", \"html\")\n",
    "    # Render and show\n",
    "    net.save_graph(html_file)\n",
    "    webbrowser.open(\"file://\" + os.path.abspath(html_file)) # Use absolute path for browser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d72fec",
   "metadata": {},
   "source": [
    "## Phase 1: Public service modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c0ef0",
   "metadata": {},
   "source": [
    "### 1.1 Document → Preconditions Summary\n",
    "\n",
    "Use LLM to summarize the document into a list of preconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Student Housing Allowance\n",
      "Conditions:\n",
      "- The student must be a Greek citizen or a citizen of another European Union country.\n",
      "- The student must be enrolled in a Higher Education Institution (HEI) and possess a valid academic ID.\n",
      "- The student must have successfully passed exams for at least half of the required courses from the previous academic year.\n",
      "- The student must be renting accommodation in a city different from their primary family residence, and the lease must be valid for at least six months.\n",
      "- Neither the student nor their parents can have full ownership or usufruct of a property in the city where the student is studying.\n",
      "- The annual family income must not exceed €30,000, with this limit increasing by €3,000 for each dependent child after the first.\n",
      "- The total area of real estate (owner-occupied or rented out) owned by the student or their parents must not cumulatively exceed 200 square meters. (This limit excludes properties located in a municipality or community with a population of less than 3,000 inhabitants).\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"Precondition documents/{document_name}.pdf\"\n",
    "\n",
    "prompt = read_txt('Prompts/summarization.txt')\n",
    "\n",
    "preconditions_summary = with_retries(call_gemini_pdf, prompt, file_name)\n",
    "print(preconditions_summary)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} preconditions summary.txt\", \"w\") as f:\n",
    "    f.write(preconditions_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5a4f3",
   "metadata": {},
   "source": [
    "### 1.2. Preconditions Summary + Citizen Ontology (TTL) → Information Model (JSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditions_summary = read_txt(f\"Results/{document_name} preconditions summary.txt\")\n",
    "citizen_ontology = read_txt(f\"Citizens/{document_name} ontology.ttl\")\n",
    "\n",
    "class Paths(BaseModel):\n",
    "    path: List[str]\n",
    "    datatype: str\n",
    "    \n",
    "class InformationConcept(BaseModel):\n",
    "    name: str\n",
    "    related_paths: List[Paths]  # links the concept to citizen data available\n",
    "    \n",
    "class Constraint(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    constrains: List[InformationConcept]  \n",
    "\n",
    "schema = list[Constraint]\n",
    "\n",
    "# Formulate prompt content and call Gemini\n",
    "prompt = read_txt('Prompts/preconditions_to_JSON.txt')\n",
    "content = [prompt, preconditions_summary, citizen_ontology]\n",
    "\n",
    "info_model = with_retries(call_gemini_json, content, schema)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} information model.json\", \"w\") as f:\n",
    "    f.write(info_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e56db",
   "metadata": {},
   "source": [
    "### 1.3 Information Model (JSON) → Public Service Graph (TTL)\n",
    "\n",
    "Use deterministic code to turn the JSON into a knowledge graph using TTL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIXES = \"\"\"@prefix ex: <http://example.org/> .\n",
    "@prefix cccev: <http://data.europa.eu/m8g/> .\n",
    "@prefix cpsv: <http://purl.org/vocab/cpsv#> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON string\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "# Get service name. As per the prompt, it's in the first line of the preconditions summary file\n",
    "with open(f\"Results/{document_name} preconditions summary.txt\") as f:\n",
    "    line = f.readline()\n",
    "    service_name = re.findall(r'Title: (.+)', line)[0].strip()\n",
    "\n",
    "triples = [PREFIXES]\n",
    "triples.append(f\"ex:{service_name} a cpsv:PublicService .\\n\\n\")\n",
    "\n",
    "# Convert constraints + concepts into triples\n",
    "for constraint in info_model:\n",
    "    constraint_name = constraint[\"name\"]\n",
    "    constraint_desc = constraint[\"desc\"].replace('\"', '\\\\\"')\n",
    "\n",
    "    # Public service -> holdsRequirement -> constraint\n",
    "    triples.append(f\"ex:{service_name} cpsv:holdsRequirement ex:{constraint_name} .\\n\")\n",
    "\n",
    "    # Constraint node\n",
    "    triples.append(f'ex:{constraint_name} a cccev:Constraint ; dct:description \"{constraint_desc}\" .\\n')\n",
    "\n",
    "    # InformationConcept nodes\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        concept_name = concept[\"name\"]\n",
    "\n",
    "        # Link constraint to concept\n",
    "        triples.append(f\"ex:{constraint_name} cccev:constrains ex:{concept_name} .\\n\")\n",
    "\n",
    "        # Declare information concept\n",
    "        triples.append(f'ex:{concept_name} a cccev:InformationConcept .\\n')\n",
    "\n",
    "    triples.append(\"\\n\")  # spacing for readability\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} service graph.ttl\", \"w\") as f:\n",
    "    f.write(\"\".join(triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cde916",
   "metadata": {},
   "source": [
    "### 1.4. Graph Visualization / Inspection\n",
    "\n",
    "Visualize part of the knowledge graph to more easily inspect correct structure and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c214e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "# Render graph of the public service\n",
    "visualize_graph(f\"Results/{document_name} service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a786b99",
   "metadata": {},
   "source": [
    "## Phase 2: SHACL Rule Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df71800",
   "metadata": {},
   "source": [
    "### 2.1. Information Model (JSON) → SHACL-spec (JSON)\n",
    "\n",
    "Use deterministic code on the JSON from before to make a new intermediate JSON that contains only the necessary information to construct SHACL shapes, one for each constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a72ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the information model JSON\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "shacl_spec_json = []\n",
    "\n",
    "for constraint in info_model:\n",
    "    # 1. Rename for clarity downstream\n",
    "    shape_name = constraint[\"name\"].replace(\"_condition\", \"_shape\")\n",
    "    desc = constraint[\"desc\"]\n",
    "    \n",
    "    concepts = []\n",
    "    \n",
    "    # 2. Iterate concepts (e.g., family_income, residency_city)\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        related_paths = []\n",
    "        \n",
    "        paths_source = concept.get(\"related_paths\", []) \n",
    "        \n",
    "        for rp in paths_source:\n",
    "            # Capture the path AND the datatype (URI vs Literal)\n",
    "            related_paths.append({\n",
    "                \"path\": rp[\"path\"],\n",
    "                \"datatype\": rp[\"datatype\"] \n",
    "            })\n",
    "            \n",
    "        concepts.append({\n",
    "            \"name\": concept[\"name\"],\n",
    "            \"related_paths\": related_paths\n",
    "        })\n",
    "    \n",
    "    shacl_spec_json.append({\n",
    "        \"shape_name\": shape_name,\n",
    "        \"desc\": desc,\n",
    "        \"concepts\": concepts\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(f\"Results/{document_name} shacl-spec.json\", \"w\") as f:\n",
    "    json.dump(shacl_spec_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d920d7",
   "metadata": {},
   "source": [
    "### 2.2. SHACL-spec (JSON) + Citizen Ontology (TTL) → SHACL Shapes (TTL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON as string \n",
    "shacl_spec_json = read_json(f\"Results/{document_name} shacl-spec.json\")\n",
    "citizen_ontology = read_txt(f\"Citizens/{document_name} ontology.ttl\")\n",
    "\n",
    "prompt = read_txt('Prompts/shacl_spec_to_shacl_ttl.txt')\n",
    "content = [prompt, shacl_spec_json, citizen_ontology]\n",
    "\n",
    "shacl_shapes = with_retries(call_gemini, content)\n",
    "\n",
    "# Cleanup gemini markdown formatting\n",
    "shacl_shapes = shacl_shapes.strip(\"`\").replace(\"turtle\", \"\").strip()\n",
    "\n",
    "# Save it to a file too\n",
    "with open(f\"Results/{document_name} shacl shapes.ttl\", \"w\") as f:\n",
    "    f.write(shacl_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153df350",
   "metadata": {},
   "source": [
    "## Phase 3: Citizen - Service Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b18742",
   "metadata": {},
   "source": [
    "### 3.1 Public Service Graph (TTL) + Citizen Graph (TTL) + Information Model (JSON) → Citizen-Service Graph (TTL) \n",
    "\n",
    "We expand the Public Service Graph to include Citizen data, properly connected with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e4ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Na3872fddc5774dd3aab92142190a91ee (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EX = Namespace(\"http://example.org/\")\n",
    "SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "# Load service and citizen ttl's and info model\n",
    "public_service_ttl = f\"Results/{document_name} service graph.ttl\"\n",
    "citizen_ttl = f\"Citizens/{document_name} eligible.ttl\"\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "# Realize them into graphs\n",
    "g = Graph()\n",
    "g.parse(public_service_ttl, format=\"turtle\")\n",
    "citizen_g = Graph()\n",
    "citizen_g.parse(citizen_ttl, format=\"turtle\")\n",
    "\n",
    "# Merge citizen triples into main graph\n",
    "for t in citizen_g:\n",
    "    g.add(t)\n",
    "    \n",
    "# Automatically determine the root citizen node \n",
    "root_candidates = list(citizen_g.subjects(predicate=None, object=SC.Applicant))\n",
    "citizen_root = root_candidates[0]\n",
    "\n",
    "# Helper: resolve node paths (return nodes, not literals) \n",
    "def resolve_node_path(citizen_g, root_uri, path_list, datatype):\n",
    "    \n",
    "    # 1. Determine how deep to go\n",
    "    if datatype == \"URI\":\n",
    "        # For Identity logic (City, Person), the Value IS the Node.\n",
    "        traversal_parts = path_list\n",
    "    else:\n",
    "        # For Value logic (Income, Area), the Value is a Literal. Stop one step BEFORE the literal to get the Node holding it.\n",
    "        traversal_parts = path_list[:-1]\n",
    "\n",
    "    # 2. Traverse\n",
    "    current_nodes = {root_uri}\n",
    "    \n",
    "    for part in traversal_parts:\n",
    "        next_nodes = set()\n",
    "        pred = SC[part] # Assumes your ontology matches the namespace\n",
    "        \n",
    "        for node in current_nodes:\n",
    "            # Find all objects connected by this predicate\n",
    "            for obj in citizen_g.objects(node, pred):\n",
    "                # Safety check: Ensure we don't accidentally traverse into a Literal \n",
    "                # (unless it's the final step of a URI path, but usually URIs point to URIs)\n",
    "                if isinstance(obj, Literal) and datatype == \"URI\":\n",
    "                     continue # Skip weird data errors\n",
    "                next_nodes.add(obj)\n",
    "        \n",
    "        current_nodes = next_nodes\n",
    "        \n",
    "        # Optimization: If dead end, stop early\n",
    "        if not current_nodes:\n",
    "            return set()\n",
    "\n",
    "    return current_nodes\n",
    "\n",
    "# Add mapsTo edges \n",
    "for constraint in info_model:\n",
    "    for concept in constraint[\"constrains\"]:\n",
    "        concept_uri = EX[concept[\"name\"]]\n",
    "\n",
    "        for path_obj in concept[\"related_paths\"]: \n",
    "            path_list = path_obj[\"path\"]\n",
    "            dtype = path_obj[\"datatype\"] \n",
    "            \n",
    "            # Pass the datatype to the resolver\n",
    "            subject_nodes = resolve_node_path(citizen_g, citizen_root, path_list, dtype)\n",
    "\n",
    "            for subj in subject_nodes:\n",
    "                # Connect the Information Concept to the Data Node\n",
    "                g.add((concept_uri, EX.mapsTo, subj))\n",
    "\n",
    "# Serialize unified graph into ttl and save to file\n",
    "g.serialize(f\"Results/{document_name} citizen-service graph.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ec8ac",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the unified graph\n",
    "\n",
    "We reuse the same function from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7766b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    }
   ],
   "source": [
    "visualize_graph(f\"Results/{document_name} citizen-service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb7ce6",
   "metadata": {},
   "source": [
    "## Phase 4: Citizen Validation and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8306f6",
   "metadata": {},
   "source": [
    "### SHACL Shape Validation\n",
    "\n",
    "Use deterministic code and a pre-made synthetic citizen graph, constructed to fulfil all conditions, and check it against the shape. If something went wrong, a list of violations and comments will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e324340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report\n",
      "Conforms: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validate_and_report(citizen_graph, shacl_graph):\n",
    "    conforms, results_graph, results_text = validate(\n",
    "        data_graph=citizen_graph,\n",
    "        shacl_graph=shacl_graph,\n",
    "        inference='rdfs'\n",
    "    )\n",
    "        \n",
    "    print(results_text)\n",
    "    \n",
    "validate_and_report(f\"Citizens/{document_name} eligible.ttl\", f\"Results/{document_name} shacl shapes.ttl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808d372",
   "metadata": {},
   "source": [
    "For completeness we test a citizen doomed to fail as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d118d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Report\n",
      "Conforms: False\n",
      "Results (1):\n",
      "Constraint Violation in SPARQLConstraintComponent (http://www.w3.org/ns/shacl#SPARQLConstraintComponent):\n",
      "\tSeverity: sh:Violation\n",
      "\tSource Shape: :academic_status_shape\n",
      "\tFocus Node: ex:Katerina\n",
      "\tValue Node: ex:Katerina\n",
      "\tSource Constraint: [ rdf:type sh:SPARQLConstraint ; sh:message Literal(\"The student is not enrolled in a Higher Education Institution or does not possess a valid academic ID.\") ; sh:select Literal(\"\n",
      "            SELECT ?this\n",
      "            WHERE {\n",
      "                FILTER NOT EXISTS {\n",
      "                    ?this :hasEducation ?edu .\n",
      "                    ?edu :isEnrolledAt ?hei .\n",
      "                    ?edu :hasValidAcademicID true .\n",
      "                }\n",
      "            }\n",
      "        \") ]\n",
      "\tMessage: The student is not enrolled in a Higher Education Institution or does not possess a valid academic ID.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate_and_report(f\"Citizens/{document_name} not eligible.ttl\", f\"Results/{document_name} shacl shapes.ttl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633d491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27f35a5f11ba0ea10ff0049f3681a560'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hashing graphs\n",
    "\n",
    "def get_semantic_hash(rdf_text):\n",
    "    \"\"\"\n",
    "    Parses RDF, canonicalizes it, and returns a hash of the logical structure.\n",
    "    Ignores formatting, whitespace, and line order.\n",
    "    \"\"\"\n",
    "    g = rdflib.Graph()\n",
    "    try:\n",
    "        g.parse(data=rdf_text, format=\"turtle\")\n",
    "    except Exception as e:\n",
    "        return \"INVALID_RDF\"\n",
    "\n",
    "    # distinct=True ensures we treat it as a set of triples\n",
    "    iso_g = to_isomorphic(g)\n",
    "    \n",
    "    # Generate a deterministic hash based on the sorted triples\n",
    "    # rdflib doesn't have a direct 'hash' for graphs, so we sort and hash the string representation\n",
    "    triples = sorted(list(iso_g))\n",
    "    triples_string = \"\".join([str(t) for t in triples])\n",
    "    return hashlib.md5(triples_string.encode('utf-8')).hexdigest()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec61563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conforms': False, 'violation_count': 1, 'failed_shapes': 'academic_status_shape', 'messages': 'The student is not enrolled in a Higher Education Institution or does not possess a valid academic ID.', 'full_report': 'Validation Report\\nConforms: False\\nResults (1):\\nConstraint Violation in SPARQLConstraintComponent (http://www.w3.org/ns/shacl#SPARQLConstraintComponent):\\n\\tSeverity: sh:Violation\\n\\tSource Shape: :academic_status_shape\\n\\tFocus Node: ex:Katerina\\n\\tValue Node: ex:Katerina\\n\\tSource Constraint: [ rdf:type sh:SPARQLConstraint ; sh:message Literal(\"The student is not enrolled in a Higher Education Institution or does not possess a valid academic ID.\") ; sh:select Literal(\"\\r\\n            SELECT ?this\\r\\n            WHERE {\\r\\n                FILTER NOT EXISTS {\\r\\n                    ?this :hasEducation ?edu .\\r\\n                    ?edu :isEnrolledAt ?hei .\\r\\n                    ?edu :hasValidAcademicID true .\\r\\n                }\\r\\n            }\\r\\n        \") ]\\n\\tMessage: The student is not enrolled in a Higher Education Institution or does not possess a valid academic ID.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# results graph parsing\n",
    "\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.namespace import SH, RDF\n",
    "\n",
    "conforms, results_graph, results_text = validate(\n",
    "    data_graph=f\"Citizens/{document_name} not eligible.ttl\",\n",
    "    shacl_graph=f\"{document_name} shacl shapes.ttl\",\n",
    "    inference='rdfs',\n",
    ")\n",
    "    \n",
    "def parse_validation_report(conforms, results_graph, results_text):\n",
    "    \"\"\"\n",
    "    Parses the SHACL validation graph into a flat dictionary for CSV logging.\n",
    "    \"\"\"\n",
    "    # If it passed, return a clean success record\n",
    "    if conforms:\n",
    "        return {\n",
    "            \"conforms\": True,\n",
    "            \"violation_count\": 0,\n",
    "            \"failed_shapes\": [],\n",
    "            \"messages\": [],\n",
    "            \"full_report\": \"Conforms\"\n",
    "        }\n",
    "\n",
    "    # If it failed, extract details from the graph\n",
    "    violations = []\n",
    "    failed_shapes = set()\n",
    "    messages = []\n",
    "\n",
    "    # Find all nodes of type sh:ValidationResult\n",
    "    for result_node in results_graph.subjects(RDF.type, SH.ValidationResult):\n",
    "        \n",
    "        # Extract the Shape Name (Source Shape)\n",
    "        # usually returns a URI like http://example.org/income_shape\n",
    "        source_shape = results_graph.value(result_node, SH.sourceShape)\n",
    "        if source_shape:\n",
    "            # Split to get just \"income_shape\"\n",
    "            shape_name = str(source_shape).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            failed_shapes.add(shape_name)\n",
    "\n",
    "        # Extract the Message\n",
    "        message = results_graph.value(result_node, SH.resultMessage)\n",
    "        if message:\n",
    "            messages.append(str(message))\n",
    "\n",
    "    return {\n",
    "        \"conforms\": False,\n",
    "        \"violation_count\": len(messages),\n",
    "        \"failed_shapes\": \"; \".join(sorted(list(failed_shapes))), # Stringify for CSV\n",
    "        \"messages\": \" | \".join(messages), # Stringify for CSV\n",
    "        \"full_report\": results_text # Keep raw text just in case\n",
    "    }\n",
    "    \n",
    "report = parse_validation_report(conforms, results_graph, results_text)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39d49761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHACL Syntax Valid: False, Stage: RDF_SYNTAX, Message: at line 32 of <>: Bad syntax (objectList expected) at ^ in: \"...b'tus_shape\\n    a sh:NodeShape .\\n    sh:targetClass :Applicant'^b' ;\\n    sh:sparql [\\n        a sh:SPARQLConstraint ;\\n        s'...\"\n"
     ]
    }
   ],
   "source": [
    "# shacl shape syntax deep check\n",
    "\n",
    "from rdflib import Graph, Namespace\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from rdflib.plugins.parsers.notation3 import BadSyntax\n",
    "import pyparsing\n",
    "\n",
    "def validate_shacl_syntax(shacl_ttl_string):\n",
    "    \"\"\"\n",
    "    Checks syntactic validity of a SHACL file on three levels:\n",
    "    1. RDF/Turtle Syntax\n",
    "    2. SHACL Structure (Basic)\n",
    "    3. Embedded SPARQL Syntax\n",
    "    \n",
    "    Returns: (is_valid (bool), error_stage (str), error_message (str))\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    \n",
    "    # --- LEVEL 1: RDF Syntax ---\n",
    "    try:\n",
    "        g.parse(data=shacl_ttl_string, format=\"turtle\")\n",
    "    except (BadSyntax, Exception) as e:\n",
    "        return False, \"RDF_SYNTAX\", str(e).replace(\"\\n\", \" \")\n",
    "\n",
    "    # --- LEVEL 2: Namespace Safety ---\n",
    "    # Extract namespaces to help the SPARQL parser later\n",
    "    namespaces = dict(g.namespaces())\n",
    "    \n",
    "    # --- LEVEL 3: Embedded SPARQL Syntax ---\n",
    "    # We query the graph to find every 'sh:select' string\n",
    "    query_finder = \"\"\"\n",
    "        PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
    "        SELECT ?shape ?sparql\n",
    "        WHERE {\n",
    "            ?shape sh:select ?sparql .\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = g.query(query_finder)\n",
    "        \n",
    "        for row in results:\n",
    "            shape_uri = str(row.shape)\n",
    "            sparql_string = str(row.sparql)\n",
    "            \n",
    "            try:\n",
    "                # Attempt to compile the SPARQL string\n",
    "                # initNs passes the prefixes defined in the TTL to the SPARQL parser\n",
    "                prepareQuery(sparql_string, initNs=namespaces)\n",
    "                \n",
    "            except pyparsing.ParseException as pe:\n",
    "                # This captures syntax errors like missing brackets } or bad keywords\n",
    "                return False, \"SPARQL_SYNTAX\", f\"Shape {shape_name(shape_uri)}: {pe}\"\n",
    "            except Exception as e:\n",
    "                return False, \"SPARQL_OTHER\", f\"Shape {shape_name(shape_uri)}: {str(e)}\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        return False, \"QUERY_EXTRACTION\", str(e)\n",
    "\n",
    "    # If we survived all checks\n",
    "    return True, \"VALID\", \"OK\"\n",
    "\n",
    "def shape_name(uri):\n",
    "    # Helper to make error messages readable\n",
    "    return uri.split(\"#\")[-1] if \"#\" in uri else uri.split(\"/\")[-1]\n",
    "\n",
    "shacl_ttl_string = read_txt(f\"{document_name} shacl shapes.ttl\")\n",
    "is_valid, error_stage, error_message = validate_shacl_syntax(shacl_ttl_string)\n",
    "print(f\"SHACL Syntax Valid: {is_valid}, Stage: {error_stage}, Message: {error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a8829",
   "metadata": {},
   "source": [
    "PAYLOAD GENERATOR MEGAMIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da7e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyexpat.errors import messages\n",
    "\n",
    "\n",
    "document_identifier = document_name\n",
    "\n",
    "service_hash = get_semantic_hash(read_txt(f\"{document_name} service graph.ttl\"))\n",
    "\n",
    "shacl_hash = get_semantic_hash(read_txt(f\"{document_name} shacl shapes.ttl\"))\n",
    "\n",
    "is_valid, error_stage, error_message = validate_shacl_syntax(read_txt(f\"{document_name} shacl shapes.ttl\"))\n",
    "\n",
    "citizen_identifier = document_name # fix this later\n",
    "\n",
    "num_expected_violations = 1\n",
    "\n",
    "conforms, results_graph, results_text = validate(\n",
    "    data_graph=f\"Citizens/{document_name} not eligible.ttl\",\n",
    "    shacl_graph=f\"{document_name} shacl shapes.ttl\",\n",
    "    inference='rdfs',\n",
    ")\n",
    "\n",
    "report = parse_validation_report(conforms, results_graph, results_text)\n",
    "\n",
    "violated_shapes = report[\"failed_shapes\"].split(\"; \") if not report[\"conforms\"] else []\n",
    "num_violations = report[\"violation_count\"]\n",
    "messages = report[\"messages\"].split(\" | \") if not report[\"conforms\"] else []\n",
    "validation_report_raw = report[\"full_report\"]\n",
    "\n",
    "report_dict = {\n",
    "    \"document_identifier\": document_identifier,\n",
    "    \"service_hash\": service_hash,\n",
    "    \"shacl_hash\": shacl_hash,\n",
    "    \"citizen_identifier\": citizen_identifier,\n",
    "    \"is_shacl_syntax_valid\": is_valid,\n",
    "    \"shacl_syntax_error_stage\": error_stage,\n",
    "    \"shacl_syntax_error_message\": error_message,\n",
    "    \"num_expected_violations\": num_expected_violations,\n",
    "    \"num_actual_violations\": num_violations,\n",
    "    \"violated_shapes\": violated_shapes,\n",
    "    \"messages\": messages,\n",
    "    \"validation_report_raw\": validation_report_raw,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
