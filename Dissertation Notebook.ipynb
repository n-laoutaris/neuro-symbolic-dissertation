{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2121267f",
   "metadata": {},
   "source": [
    "# Experimental notebook for document structured knowledge extraction\n",
    "\n",
    "This is the fourth iteration of the pipeline, the first one to be pushed in the repo, and thus the first official version. Version history will now be handled by git.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "from typing import List\n",
    "import csv\n",
    "\n",
    "\n",
    "# Validation / data models\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# RDF / graph libraries\n",
    "from rdflib import Graph, Namespace, RDF, Literal\n",
    "from rdflib.namespace import SH\n",
    "\n",
    "# Visualization and SHACL\n",
    "from pyshacl import validate\n",
    "\n",
    "# Parsing helpers\n",
    "\n",
    "import datetime\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Local imports\n",
    "from src.llm_utils import initialize_gemini_client, call_gemini, call_gemini_pdf, call_gemini_json, with_retries\n",
    "from src.graph_utils import visualize_graph, get_semantic_hash, validate_shacl_syntax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6751506",
   "metadata": {},
   "source": [
    "### Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GEMINI_MODEL = \"gemini-2.5-pro\"\n",
    "\n",
    "initialize_gemini_client(model_name=GEMINI_MODEL)\n",
    "\n",
    "# Which document we'll be testing\n",
    "DOCUMENT_NAME = \"student_housing\"\n",
    "\n",
    "CSV_FILE = \"Master_Results.csv\"\n",
    "\n",
    "current_run_id = 1 # this will be part of the framework later, fetched from the csv last entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3480ed",
   "metadata": {},
   "source": [
    "Aux functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read txt file into a string (used for prompts)\n",
    "def read_txt(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "# Read a JSON file and return it as string or raw JSON\n",
    "def read_json(path, raw = False):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    if (raw):\n",
    "        return json_file\n",
    "    # Else, convert JSON to string \n",
    "    return json.dumps(json_file, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d72fec",
   "metadata": {},
   "source": [
    "## Preparation: Get everything ready for logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a blank slate for a single run\n",
    "def initialize_run_context(run_id, doc_name, model_name):\n",
    "    return {\n",
    "        # --- Metadata ---\n",
    "        \"Run ID\": run_id,\n",
    "        \"Document Name\": doc_name,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(sep=\" \", timespec=\"seconds\"),\n",
    "        \"Model Name\": model_name,\n",
    "        \n",
    "        # --- Pipeline Artifacts (Placeholders) ---\n",
    "        \"Service Graph Hash\": \"N/A\",\n",
    "        \"SHACL Graph Hash\": \"N/A\",\n",
    "        \"SHACL Valid Syntax\": False,\n",
    "        \"SHACL Error Type\": \"N/A\",\n",
    "        \"SHACL Error Message\": \"N/A\",\n",
    "        \n",
    "        # --- Scenario Specifics (Will be overwritten per scenario) ---\n",
    "        \"Scenario ID\": \"N/A\",\n",
    "        \"Scenario Description\": \"N/A\",\n",
    "        \"Expected Violation Count\": 0,\n",
    "        \"Actual Violation Count\": 0,\n",
    "        \"Violated Shapes\": [],\n",
    "        \"Violation Messages\": [],\n",
    "        \"Raw Validation Report\": \"N/A\",\n",
    "        \n",
    "        # --- Execution Stats ---\n",
    "        \"Execution Time\": 0.0,\n",
    "        \"Successfully Executed\": False,\n",
    "    }\n",
    "    \n",
    "ctx = initialize_run_context(current_run_id, DOCUMENT_NAME, GEMINI_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed94713",
   "metadata": {},
   "source": [
    "## Phase 1: Public service modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4446dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin\n",
    "execution_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c0ef0",
   "metadata": {},
   "source": [
    "### 1.1 Document → Preconditions Summary\n",
    "\n",
    "Use LLM to summarize the document into a list of preconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Student Housing Allowance\n",
      "Conditions:\n",
      "- The student must be a Greek citizen or a citizen of another European Union country.\n",
      "- The student must be enrolled in a Higher Education Institution (HEI) and possess a valid academic ID.\n",
      "- The student must have successfully passed exams in at least half of the courses of the previous academic year for which the allowance is requested.\n",
      "- The annual family income for the previous tax year must not exceed €30,000. This limit is increased by €3,000 for each dependent child after the first.\n",
      "- The student must rent a property in a city different from their family's primary residence due to their studies.\n",
      "- Neither the student nor their parents can have full ownership or usufruct of a residence in the city of study.\n",
      "- The total area of real estate (owner-occupied or rented out) owned by the student or their parents must not exceed 200 square meters, excluding properties in municipalities with a population under 3,000.\n",
      "- To qualify for an increased allowance due to cohabitation, the cohabiting student must also be an undergraduate at an HEI, studying for their first degree within the standard duration of their program, and studying in the same city or regional unit as the applicant.\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"Precondition documents/{DOCUMENT_NAME}.pdf\"\n",
    "\n",
    "prompt = read_txt('Prompts/summarization.txt')\n",
    "\n",
    "preconditions_summary = with_retries(call_gemini_pdf, prompt, file_name)\n",
    "print(preconditions_summary)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{DOCUMENT_NAME} preconditions summary.txt\", \"w\") as f:\n",
    "    f.write(preconditions_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5a4f3",
   "metadata": {},
   "source": [
    "### 1.2. Preconditions Summary + Citizen Schema (TTL) → Information Model (JSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditions_summary = read_txt(f\"Results/{DOCUMENT_NAME} preconditions summary.txt\")\n",
    "citizen_schema = read_txt(f\"Citizens/{DOCUMENT_NAME} schema.ttl\")\n",
    "\n",
    "class Paths(BaseModel):\n",
    "    path: List[str]\n",
    "    datatype: str\n",
    "    \n",
    "class InformationConcept(BaseModel):\n",
    "    name: str\n",
    "    related_paths: List[Paths]  # links the concept to citizen data available\n",
    "    \n",
    "class Constraint(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    constrains: List[InformationConcept]  \n",
    "\n",
    "schema = list[Constraint]\n",
    "\n",
    "# Formulate prompt content and call Gemini\n",
    "prompt = read_txt('Prompts/preconditions_to_JSON.txt')\n",
    "content = [prompt, preconditions_summary, citizen_schema]\n",
    "\n",
    "info_model = with_retries(call_gemini_json, content, schema)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{DOCUMENT_NAME} information model.json\", \"w\") as f:\n",
    "    f.write(info_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e56db",
   "metadata": {},
   "source": [
    "### 1.3 Information Model (JSON) → Public Service Graph (TTL)\n",
    "\n",
    "Use deterministic code to turn the JSON into a knowledge graph using TTL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIXES = \"\"\"@prefix ex: <http://example.org/> .\n",
    "@prefix cccev: <http://data.europa.eu/m8g/> .\n",
    "@prefix cpsv: <http://purl.org/vocab/cpsv#> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON string\n",
    "info_model = read_json(f\"Results/{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "# Get service name. As per the prompt, it's in the first line of the preconditions summary file\n",
    "with open(f\"Results/{DOCUMENT_NAME} preconditions summary.txt\") as f:\n",
    "    line = f.readline()\n",
    "    service_name = re.findall(r'Title: (.+)', line)[0].strip().replace(\" \", \"_\")\n",
    "\n",
    "triples = [PREFIXES]\n",
    "triples.append(f\"ex:{service_name} a cpsv:PublicService .\\n\\n\")\n",
    "\n",
    "# Convert constraints + concepts into triples\n",
    "for constraint in info_model:\n",
    "    constraint_name = constraint[\"name\"]\n",
    "    constraint_desc = constraint[\"desc\"].replace('\"', '\\\\\"')\n",
    "\n",
    "    # Public service -> holdsRequirement -> constraint\n",
    "    triples.append(f\"ex:{service_name} cpsv:holdsRequirement ex:{constraint_name} .\\n\")\n",
    "\n",
    "    # Constraint node\n",
    "    triples.append(f'ex:{constraint_name} a cccev:Constraint ; dct:description \"{constraint_desc}\" .\\n')\n",
    "\n",
    "    # InformationConcept nodes\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        concept_name = concept[\"name\"]\n",
    "\n",
    "        # Link constraint to concept\n",
    "        triples.append(f\"ex:{constraint_name} cccev:constrains ex:{concept_name} .\\n\")\n",
    "\n",
    "        # Declare information concept\n",
    "        triples.append(f'ex:{concept_name} a cccev:InformationConcept .\\n')\n",
    "\n",
    "    triples.append(\"\\n\")  # spacing for readability\n",
    "\n",
    "triples_string = \"\".join(triples)\n",
    "# Save to a file too\n",
    "with open(f\"Results/{DOCUMENT_NAME} service graph.ttl\", \"w\") as f:\n",
    "    f.write(triples_string)   \n",
    "     \n",
    "# Log \n",
    "ctx[\"Service Graph Hash\"] = get_semantic_hash(triples_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cde916",
   "metadata": {},
   "source": [
    "### 1.4. Graph Visualization / Inspection\n",
    "\n",
    "Visualize part of the knowledge graph to more easily inspect correct structure and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c214e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render graph of the public service\n",
    "visualize_graph(f\"Results/{DOCUMENT_NAME} service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a786b99",
   "metadata": {},
   "source": [
    "## Phase 2: SHACL Rule Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df71800",
   "metadata": {},
   "source": [
    "### 2.1. Information Model (JSON) → SHACL-spec (JSON)\n",
    "\n",
    "Use deterministic code on the JSON from before to make a new intermediate JSON that contains only the necessary information to construct SHACL shapes, one for each constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a72ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the information model JSON\n",
    "info_model = read_json(f\"Results/{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "shacl_spec_json = []\n",
    "\n",
    "for constraint in info_model:\n",
    "    # 1. Rename for clarity downstream\n",
    "    shape_name = constraint[\"name\"].replace(\"_condition\", \"_shape\")\n",
    "    desc = constraint[\"desc\"]\n",
    "    \n",
    "    concepts = []\n",
    "    \n",
    "    # 2. Iterate concepts (e.g., family_income, residency_city)\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        related_paths = []\n",
    "        \n",
    "        paths_source = concept.get(\"related_paths\", []) \n",
    "        \n",
    "        for rp in paths_source:\n",
    "            # Capture the path AND the datatype (URI vs Literal)\n",
    "            related_paths.append({\n",
    "                \"path\": rp[\"path\"],\n",
    "                \"datatype\": rp[\"datatype\"] \n",
    "            })\n",
    "            \n",
    "        concepts.append({\n",
    "            \"name\": concept[\"name\"],\n",
    "            \"related_paths\": related_paths\n",
    "        })\n",
    "    \n",
    "    shacl_spec_json.append({\n",
    "        \"shape_name\": shape_name,\n",
    "        \"desc\": desc,\n",
    "        \"concepts\": concepts\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(f\"Results/{DOCUMENT_NAME} shacl-spec.json\", \"w\") as f:\n",
    "    json.dump(shacl_spec_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d920d7",
   "metadata": {},
   "source": [
    "### 2.2. SHACL-spec (JSON) + Citizen Schema (TTL) → SHACL Shapes (TTL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON as string \n",
    "shacl_spec_json = read_json(f\"Results/{DOCUMENT_NAME} shacl-spec.json\")\n",
    "citizen_schema = read_txt(f\"Citizens/{DOCUMENT_NAME} schema.ttl\")\n",
    "\n",
    "prompt = read_txt('Prompts/shacl_spec_to_shacl_ttl.txt')\n",
    "content = [prompt, shacl_spec_json, citizen_schema]\n",
    "\n",
    "shacl_shapes = with_retries(call_gemini, content)\n",
    "\n",
    "# Cleanup gemini markdown formatting\n",
    "shacl_shapes = shacl_shapes.strip(\"`\").replace(\"turtle\", \"\").replace(\"ttl\", \"\").strip()\n",
    "\n",
    "# Save it to a file too\n",
    "with open(f\"Results/{DOCUMENT_NAME} shacl shapes.ttl\", \"w\") as f:\n",
    "    f.write(shacl_shapes)\n",
    "    \n",
    "# Log\n",
    "ctx[\"SHACL Graph Hash\"] = get_semantic_hash(shacl_shapes)\n",
    "\n",
    "is_valid, error_stage, error_message = validate_shacl_syntax(shacl_shapes)\n",
    "ctx[\"SHACL Valid Syntax\"] = is_valid\n",
    "ctx[\"SHACL Error Type\"] = error_stage\n",
    "ctx[\"SHACL Error Message\"] = error_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153df350",
   "metadata": {},
   "source": [
    "## Phase 3: Citizen - Service Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b18742",
   "metadata": {},
   "source": [
    "### 3.1 Public Service Graph (TTL) + Citizen Graph (TTL) + Information Model (JSON) → Citizen-Service Graph (TTL) \n",
    "\n",
    "We expand the Public Service Graph to include Citizen data, properly connected with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1b3b3494b4634305b57f0f1232329d47 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EX = Namespace(\"http://example.org/\")\n",
    "SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "# Load service and citizen ttl's and info model\n",
    "public_service_ttl = f\"Results/{DOCUMENT_NAME} service graph.ttl\"\n",
    "citizen_ttl = f\"Citizens/{DOCUMENT_NAME} eligible.ttl\"\n",
    "info_model = read_json(f\"Results/{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "# Realize them into graphs\n",
    "g = Graph()\n",
    "g.parse(public_service_ttl, format=\"turtle\")\n",
    "citizen_g = Graph()\n",
    "citizen_g.parse(citizen_ttl, format=\"turtle\")\n",
    "\n",
    "# Merge citizen triples into main graph\n",
    "for t in citizen_g:\n",
    "    g.add(t)\n",
    "    \n",
    "# Automatically determine the root citizen node \n",
    "root_candidates = list(citizen_g.subjects(predicate=None, object=SC.Applicant))\n",
    "citizen_root = root_candidates[0]\n",
    "\n",
    "# Helper: resolve node paths (return nodes, not literals) \n",
    "def resolve_node_path(citizen_g, root_uri, path_list, datatype):\n",
    "    \n",
    "    # 1. Determine how deep to go\n",
    "    if datatype == \"URI\":\n",
    "        # For Identity logic (City, Person), the Value IS the Node.\n",
    "        traversal_parts = path_list\n",
    "    else:\n",
    "        # For Value logic (Income, Area), the Value is a Literal. Stop one step BEFORE the literal to get the Node holding it.\n",
    "        traversal_parts = path_list[:-1]\n",
    "\n",
    "    # 2. Traverse\n",
    "    current_nodes = {root_uri}\n",
    "    \n",
    "    for part in traversal_parts:\n",
    "        next_nodes = set()\n",
    "        pred = SC[part] # Assumes our schema matches the namespace\n",
    "        \n",
    "        for node in current_nodes:\n",
    "            # Find all objects connected by this predicate\n",
    "            for obj in citizen_g.objects(node, pred):\n",
    "                # Safety check: Ensure we don't accidentally traverse into a Literal \n",
    "                # (unless it's the final step of a URI path, but usually URIs point to URIs)\n",
    "                if isinstance(obj, Literal) and datatype == \"URI\":\n",
    "                     continue # Skip weird data errors\n",
    "                next_nodes.add(obj)\n",
    "        \n",
    "        current_nodes = next_nodes\n",
    "        \n",
    "        # Optimization: If dead end, stop early\n",
    "        if not current_nodes:\n",
    "            return set()\n",
    "\n",
    "    return current_nodes\n",
    "\n",
    "# Add mapsTo edges  \n",
    "for constraint in info_model:\n",
    "    for concept in constraint[\"constrains\"]:\n",
    "        concept_uri = EX[concept[\"name\"]]\n",
    "\n",
    "        for path_obj in concept[\"related_paths\"]: \n",
    "            path_list = path_obj[\"path\"]\n",
    "            dtype = path_obj[\"datatype\"] \n",
    "            \n",
    "            # Pass the datatype to the resolver\n",
    "            subject_nodes = resolve_node_path(citizen_g, citizen_root, path_list, dtype)\n",
    "\n",
    "            for subj in subject_nodes:\n",
    "                # Connect the Information Concept to the Data Node\n",
    "                g.add((concept_uri, EX.mapsTo, subj))\n",
    "\n",
    "# Serialize unified graph into ttl and save to file\n",
    "g.serialize(f\"Results/{DOCUMENT_NAME} citizen-service graph.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ec8ac",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the unified graph\n",
    "\n",
    "We reuse the same function from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(f\"Results/{DOCUMENT_NAME} citizen-service graph.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This marks the end of the main pipeline. \n",
    "ctx[\"Execution Time\"] = round(time.time() - execution_start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb7ce6",
   "metadata": {},
   "source": [
    "## Phase 4: Citizen Validation and Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8306f6",
   "metadata": {},
   "source": [
    "### SHACL Shape Validation\n",
    "\n",
    "Use deterministic code and a pre-made synthetic citizen graph, constructed to fulfil all conditions, and check it against the shape. If something went wrong, a list of violations and comments will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c2b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to parse SHACL validation report\n",
    "def parse_validation_report(conforms, results_graph, results_text):\n",
    "    \"\"\"\n",
    "    Parses the SHACL validation graph into a flat dictionary for CSV logging.\n",
    "    \"\"\"\n",
    "    # If it passed, return a clean success record\n",
    "    if conforms:\n",
    "        return {\n",
    "            \"violation_count\": 0,\n",
    "            \"failed_shapes\": \"None\",\n",
    "            \"messages\": \"None\",\n",
    "            \"full_report\": \"Conforms: True\"\n",
    "        }\n",
    "\n",
    "    # If it failed, extract details from the graph\n",
    "    violations = []\n",
    "    failed_shapes = set()\n",
    "    messages = []\n",
    "\n",
    "    # Find all nodes of type sh:ValidationResult\n",
    "    for result_node in results_graph.subjects(RDF.type, SH.ValidationResult):\n",
    "        \n",
    "        # Extract the Shape Name (Source Shape) should return a URI like http://example.org/income_shape\n",
    "        source_shape = results_graph.value(result_node, SH.sourceShape)\n",
    "        if source_shape:\n",
    "            # Split to get just \"income_shape\"\n",
    "            shape_name = str(source_shape).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            failed_shapes.add(shape_name)\n",
    "\n",
    "        # Extract the Message\n",
    "        message = results_graph.value(result_node, SH.resultMessage)\n",
    "        if message:\n",
    "            messages.append(str(message))\n",
    "\n",
    "    return {\n",
    "        \"violation_count\": len(messages),\n",
    "        \"failed_shapes\": \"; \".join(sorted(list(failed_shapes))), # Stringify for CSV\n",
    "        \"messages\": \" | \".join(messages), # Stringify for CSV\n",
    "        \"full_report\": results_text # Keep raw text just in case\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_mutations(base_graph, actions):\n",
    "    \"\"\"\n",
    "    Applies text-based Turtle mutations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pre-defined header to allow \"lazy\" Turtle snippets in YAML\n",
    "    PREFIX_HEADER = \"\"\"\n",
    "    @prefix : <http://example.org/schema#> .\n",
    "    @prefix ex: <http://example.org/> .\n",
    "    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Clone the graph (Memory safe)\n",
    "    new_graph = Graph()\n",
    "    for t in base_graph: new_graph.add(t)\n",
    "    \n",
    "    for action in actions:\n",
    "        if action['type'] == 'replace_node':\n",
    "            snippet = action['turtle']\n",
    "            \n",
    "            # A. Parse the snippet into a temporary graph\n",
    "            # We prepend prefixes so the user doesn't have to type them every time\n",
    "            full_turtle = PREFIX_HEADER + \"\\n\" + snippet\n",
    "            snippet_graph = Graph()\n",
    "            try:\n",
    "                snippet_graph.parse(data=full_turtle, format=\"turtle\")\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Invalid Turtle in mutation: {e}\")\n",
    "\n",
    "            # B. Identify the Subject(s) being replaced\n",
    "            # The snippet describes 1+ nodes. We find them all.\n",
    "            subjects = set(snippet_graph.subjects())\n",
    "            \n",
    "            for s in subjects:\n",
    "                # C. Wipe OLD properties for this subject from the main graph\n",
    "                # We remove (s, ?, ?) -> outgoing edges\n",
    "                # We KEEP (?, ?, s) -> incoming edges (e.g. Dad -> hasIncome -> DadIncome)\n",
    "                new_graph.remove((s, None, None))\n",
    "                \n",
    "                # D. Add NEW properties from the snippet\n",
    "                for p, o in snippet_graph.predicate_objects(s):\n",
    "                    new_graph.add((s, p, o))\n",
    "                    \n",
    "        elif action['type'] == 'no_action':\n",
    "            pass\n",
    "    \n",
    "    new_graph.bind(\"ex\", Namespace(\"http://example.org/\"))     \n",
    "    new_graph.bind(\"\", Namespace(\"http://example.org/schema#\"))\n",
    "           \n",
    "    return new_graph\n",
    "\n",
    "# Write to csv\n",
    "def flush_context_to_csv(context_dict, csv_file):\n",
    "    # Read headers from the existing file\n",
    "    with open(csv_file, 'r', encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader) # Grabs the first row (the headers)\n",
    "\n",
    "    # Align data to those headers\n",
    "    row_data = []\n",
    "    for h in headers:\n",
    "        value = context_dict.get(h, \"N/A\") # safe get with default\n",
    "        row_data.append(value)\n",
    "\n",
    "    # Write the row\n",
    "    with open(csv_file, 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row_data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a2fc6",
   "metadata": {},
   "source": [
    "Begin the scenario loop, writing to csv after every scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Run 1 to CSV.\n"
     ]
    }
   ],
   "source": [
    "# Load the Golden Citizen (Baseline)\n",
    "golden_ttl = \"Citizens/student_housing eligible.ttl\"\n",
    "golden_graph = Graph()\n",
    "golden_graph.parse(golden_ttl, format=\"turtle\")\n",
    "\n",
    "# Load the Scenarios from YAML\n",
    "with open(\"Citizens/student_housing scenarios.yaml\", \"r\") as f:\n",
    "    scenarios = yaml.safe_load(f)\n",
    "\n",
    "# Iterate and Apply\n",
    "for scn in scenarios:\n",
    "    ctx[\"Scenario ID\"] = scn['id']\n",
    "    ctx[\"Scenario Description\"] = scn['description']\n",
    "    ctx[\"Expected Violation Count\"] = scn['expected_violation_count']\n",
    "    \n",
    "    # Apply mutations (Returns a NEW graph, leaving golden_graph untouched)\n",
    "    mutated_graph = apply_mutations(golden_graph, scn['actions'])\n",
    "\n",
    "    # Proceed to Validation \n",
    "    conforms, results_graph, results_text = validate(\n",
    "        data_graph=mutated_graph,\n",
    "        shacl_graph=f\"Results/{DOCUMENT_NAME} shacl shapes.ttl\",\n",
    "        inference='rdfs',\n",
    "    )\n",
    "    \n",
    "    # Parse validation report\n",
    "    parse_result = parse_validation_report(conforms, results_graph, results_text)\n",
    "    ctx[\"Actual Violation Count\"] = parse_result[\"violation_count\"]\n",
    "    ctx[\"Violated Shapes\"] = parse_result[\"failed_shapes\"]\n",
    "    ctx[\"Violation Messages\"] = parse_result[\"messages\"]\n",
    "\n",
    "    # If we made it this far\n",
    "    ctx[\"Successfully Executed\"] = True\n",
    "    \n",
    "    flush_context_to_csv(ctx, CSV_FILE)\n",
    "    \n",
    "# End of the run\n",
    "print(f\"Logged Run {ctx['Run ID']} to CSV.\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
