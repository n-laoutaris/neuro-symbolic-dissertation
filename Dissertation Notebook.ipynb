{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2121267f",
   "metadata": {},
   "source": [
    "# Experimental notebook for document structured knowledge extraction\n",
    "\n",
    "This is the fourth iteration of the pipeline, the first one to be pushed in the repo, and thus the first official version. Version history will now be handled by git.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import webbrowser\n",
    "from typing import List\n",
    "import csv\n",
    "\n",
    "# Environment/config\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Validation / data models\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# LLM client\n",
    "from google import genai\n",
    "\n",
    "# RDF / graph libraries\n",
    "import rdflib\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, Literal\n",
    "from rdflib.compare import to_isomorphic\n",
    "from rdflib.plugins.sparql import prepareQuery\n",
    "from rdflib.plugins.parsers.notation3 import BadSyntax\n",
    "from rdflib.namespace import SH\n",
    "\n",
    "# Visualization and SHACL\n",
    "from pyvis.network import Network\n",
    "from pyshacl import validate\n",
    "\n",
    "# Parsing helpers\n",
    "import pyparsing\n",
    "from pyexpat.errors import messages\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6751506",
   "metadata": {},
   "source": [
    "### Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client \n",
    "client = genai.Client()\n",
    "gemini_model = \"gemini-2.5-pro\"\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_KEY:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not found. Add it to a .env file in the notebook root.\")\n",
    "\n",
    "# Which document we'll be testing\n",
    "document_name = \"student_housing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3480ed",
   "metadata": {},
   "source": [
    "Aux functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf0cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation in general\n",
    "def call_gemini(content):\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents = content\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# Document understanding \n",
    "def call_gemini_pdf(content, file_name):    \n",
    "    # Retrieve and encode the PDF byte\n",
    "    file_path = Path(file_name)\n",
    "\n",
    "    # Upload the PDF using the File API\n",
    "    content_file = client.files.upload(file = file_path)\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents=[content_file, content]\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# JSON structured output\n",
    "def call_gemini_json(content, schema):\n",
    "    response = client.models.generate_content(\n",
    "        model = gemini_model,\n",
    "        contents=content,\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": schema\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# Read txt file into a string (used for prompts)\n",
    "def read_txt(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "    \n",
    "# Read a JSON file and return it as string or raw JSON\n",
    "def read_json(path, raw = False):\n",
    "    with open(path, \"r\") as f:\n",
    "        json_file = json.load(f)\n",
    "    if (raw):\n",
    "        return json_file\n",
    "    # Else, convert JSON to string \n",
    "    return json.dumps(json_file, indent=2)\n",
    "\n",
    "# Retry wrapper to combat model overload errors\n",
    "def with_retries(func, *args, base_delay=4.0):\n",
    "    overloads = 0    \n",
    "    exhaustions = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except Exception as e:\n",
    "            msg = str(e).lower()\n",
    "            overloaded = \"overloaded\" in msg\n",
    "            exhausted = \"exhausted\" in msg            \n",
    "            if overloaded:\n",
    "                overloads += 1\n",
    "                wait = base_delay * (2 ** overloads)\n",
    "                print(f\"Gemini overloaded {overloads} times, retrying in {wait:.1f}s...\")\n",
    "                time.sleep(wait)\n",
    "                continue\n",
    "            elif exhausted:\n",
    "                exhaustions +=1\n",
    "                print(f\"Gemini exhausted {exhaustions} times, waiting 1 minute and rerunning the code...\")\n",
    "                time.sleep(60) \n",
    "                overloads = 0                \n",
    "                continue          \n",
    "            # Anything else\n",
    "            raise\n",
    "\n",
    "# Pyvis graph visualization\n",
    "def visualize_graph(ttl_file):\n",
    "    # Load TTL file\n",
    "    g = Graph()\n",
    "    g.parse(ttl_file, format=\"turtle\")  \n",
    "\n",
    "    # Namespace\n",
    "    CCCEV = Namespace(\"http://data.europa.eu/m8g/\")\n",
    "    CPSV = Namespace(\"http://purl.org/vocab/cpsv#\")\n",
    "    EX = Namespace(\"http://example.org/\")\n",
    "    SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "    net = Network(height=\"1440px\", width=\"100%\", notebook=True, directed=True, cdn_resources='remote')\n",
    "    net.force_atlas_2based()\n",
    "\n",
    "    # Just visual effects\n",
    "    def node_color(uri):\n",
    "        if (uri, RDF.type, CPSV.PublicService) in g:\n",
    "            return \"gold\"\n",
    "        if (uri, RDF.type, CCCEV.Constraint) in g:\n",
    "            return \"maroon\"\n",
    "        if (uri, RDF.type, CCCEV.InformationConcept) in g:\n",
    "            return \"darkturquoise\"\n",
    "        if (uri, RDF.type, SC.Applicant) in g:\n",
    "            return \"yellowgreen\"\n",
    "        return \"lightgrey\"\n",
    "\n",
    "    # Just a way to make the graph more readable\n",
    "    def node_label(uri):\n",
    "        if isinstance(uri, Literal):\n",
    "            return str(uri)\n",
    "\n",
    "        for lbl in g.objects(uri, RDFS.label):\n",
    "            return str(lbl)\n",
    "        for lbl in g.objects(uri, CCCEV.name):\n",
    "            return str(lbl)\n",
    "\n",
    "        uri_str = str(uri).rstrip('/') # <--- SAFETY FIX\n",
    "        if \"#\" in uri_str:\n",
    "            return uri_str.split(\"#\")[-1]\n",
    "        return uri_str.split(\"/\")[-1]\n",
    "\n",
    "    # Add nodes and edges, skipping rdf:type for extra readability\n",
    "    for s, p, o in g:\n",
    "        if p == RDF.type:\n",
    "            continue\n",
    "\n",
    "        # Subject\n",
    "        net.add_node(str(s), label=node_label(s), color=node_color(s))\n",
    "\n",
    "        # Object\n",
    "        if isinstance(o, Literal):\n",
    "            net.add_node(str(o), label=node_label(o), color=\"beige\", shape=\"box\") # if it's a literal put it in a text box instead of a circular node\n",
    "        else:\n",
    "            net.add_node(str(o), label=node_label(o), color=node_color(o))\n",
    "\n",
    "        # Edge\n",
    "        net.add_edge(str(s), str(o), label=node_label(p), arrows=\"to\")\n",
    "\n",
    "    html_file = ttl_file.replace(\"ttl\", \"html\")\n",
    "    # Render and show\n",
    "    net.save_graph(html_file)\n",
    "    webbrowser.open(\"file://\" + os.path.abspath(html_file)) # Use absolute path for browser\n",
    "\n",
    "# Hashing Graphs\n",
    "def get_semantic_hash(rdf_text):\n",
    "    \"\"\"\n",
    "    Parses RDF, canonicalizes it, and returns a hash of the logical structure.\n",
    "    Ignores formatting, whitespace and line order.\n",
    "    \"\"\"\n",
    "    g = rdflib.Graph()\n",
    "    try:\n",
    "        g.parse(data=rdf_text, format=\"turtle\")\n",
    "    except Exception as e:\n",
    "        return \"INVALID_RDF\"\n",
    "\n",
    "    iso_g = to_isomorphic(g)\n",
    "    \n",
    "    # Generate a deterministic hash based on the sorted triples (the string representation)\n",
    "    triples = sorted(list(iso_g))\n",
    "    triples_string = \"\".join([str(t) for t in triples])\n",
    "    return hashlib.md5(triples_string.encode('utf-8')).hexdigest()\n",
    "\n",
    "# shacl shape syntax deep check\n",
    "def validate_shacl_syntax(shacl_ttl_string):\n",
    "    \"\"\"\n",
    "    Checks syntactic validity of a SHACL file on three levels:\n",
    "    1. RDF/Turtle Syntax\n",
    "    2. SHACL Structure (Basic)\n",
    "    3. Embedded SPARQL Syntax\n",
    "    \n",
    "    Returns: (is_valid (bool), error_stage (str), error_message (str))\n",
    "    \"\"\"\n",
    "    def shape_name(uri):\n",
    "        # Helper to make error messages readable\n",
    "        return uri.split(\"#\")[-1] if \"#\" in uri else uri.split(\"/\")[-1]\n",
    "    \n",
    "    g = Graph()\n",
    "    \n",
    "    # --- LEVEL 1: RDF Syntax ---\n",
    "    try:\n",
    "        g.parse(data=shacl_ttl_string, format=\"turtle\")\n",
    "    except (BadSyntax, Exception) as e:\n",
    "        return False, \"RDF_SYNTAX\", str(e).replace(\"\\n\", \" \")\n",
    "\n",
    "    # Extract namespaces to help the SPARQL parser later\n",
    "    namespaces = dict(g.namespaces())\n",
    "    \n",
    "    # --- LEVEL 2: Embedded SPARQL Syntax ---\n",
    "    # We query the graph to find every 'sh:select' string\n",
    "    query_finder = \"\"\"\n",
    "        PREFIX sh: <http://www.w3.org/ns/shacl#>\n",
    "        SELECT ?shape ?sparql\n",
    "        WHERE {\n",
    "            ?shape sh:select ?sparql .\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = g.query(query_finder)        \n",
    "        for row in results:\n",
    "            shape_uri = str(row.shape)\n",
    "            sparql_string = str(row.sparql)\n",
    "            \n",
    "            try:\n",
    "                # Attempt to compile the SPARQL string\n",
    "                prepareQuery(sparql_string, initNs=namespaces)\n",
    "                \n",
    "            except pyparsing.ParseException as pe:\n",
    "                # This captures syntax errors like missing brackets } or bad keywords\n",
    "                return False, \"SPARQL_SYNTAX\", f\"Shape {shape_name(shape_uri)}: {pe}\"\n",
    "            except Exception as e:\n",
    "                return False, \"SPARQL_OTHER\", f\"Shape {shape_name(shape_uri)}: {str(e)}\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        return False, \"QUERY_EXTRACTION\", str(e)\n",
    "\n",
    "    # If we survived all checks\n",
    "    return True, \"VALID\", \"OK\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d72fec",
   "metadata": {},
   "source": [
    "## Preparation: Get everything ready for logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac5d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a blank slate for a single run\n",
    "def initialize_run_context(run_id, doc_name, model_name):\n",
    "    return {\n",
    "        # --- Metadata ---\n",
    "        \"Run ID\": run_id,\n",
    "        \"Document Name\": doc_name,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(sep=\" \", timespec=\"seconds\"),\n",
    "        \"Model Name\": model_name,\n",
    "        \n",
    "        # --- Pipeline Artifacts (Placeholders) ---\n",
    "        \"Service Graph Hash\": \"N/A\",\n",
    "        \"SHACL Graph Hash\": \"N/A\",\n",
    "        \"SHACL Valid Syntax\": False,\n",
    "        \"SHACL Error Type\": \"N/A\",\n",
    "        \"SHACL Error Message\": \"N/A\",\n",
    "        \n",
    "        # --- Scenario Specifics (Will be overwritten per scenario) ---\n",
    "        \"Scenario ID\": \"N/A\",\n",
    "        \"Scenario Description\": \"N/A\",\n",
    "        \"Expected Violation Count\": 0,\n",
    "        \"Actual Violation Count\": 0,\n",
    "        \"Violated Shapes\": [],\n",
    "        \"Violation Messages\": [],\n",
    "        \"Raw Validation Report\": \"N/A\",\n",
    "        \n",
    "        # --- Execution Stats ---\n",
    "        \"Execution Time\": 0.0,\n",
    "        \"Successfully Executed\": False,\n",
    "    }\n",
    "    \n",
    "# We begin\n",
    "current_run_id = 1 # this will be part of the framework later\n",
    "ctx = initialize_run_context(current_run_id, document_name, gemini_model)\n",
    "execution_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed94713",
   "metadata": {},
   "source": [
    "## Phase 1: Public service modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c0ef0",
   "metadata": {},
   "source": [
    "### 1.1 Document → Preconditions Summary\n",
    "\n",
    "Use LLM to summarize the document into a list of preconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2fdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Housing allowance for students\n",
      "Conditions:\n",
      "- The student must be a citizen of Greece or another European Union country.\n",
      "- The student must be enrolled as an undergraduate at a Higher Education Institution (AEI) in Greece, pursuing their first degree.\n",
      "- The student's duration of study must not have exceeded the standard number of semesters required for their degree.\n",
      "- The student must have successfully passed exams in at least half of the courses from the previous academic year.\n",
      "- The annual family income must not exceed €30,000. This limit increases by €3,000 for each dependent child after the first one.\n",
      "- The student must be renting accommodation in a city other than that of their main family residence, and the lease must be valid for at least six months.\n",
      "- Neither the student nor their parents may have full ownership or usufruct of a residence in the city of study.\n",
      "- The total area of real estate (owner-occupied or rented out) owned by the student or their parents must not exceed 200 square meters. (This calculation excludes properties located in a municipality or community with a population of less than 3,000).\n"
     ]
    }
   ],
   "source": [
    "file_name = f\"Precondition documents/{document_name}.pdf\"\n",
    "\n",
    "prompt = read_txt('Prompts/summarization.txt')\n",
    "\n",
    "preconditions_summary = with_retries(call_gemini_pdf, prompt, file_name)\n",
    "print(preconditions_summary)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} preconditions summary.txt\", \"w\") as f:\n",
    "    f.write(preconditions_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5a4f3",
   "metadata": {},
   "source": [
    "### 1.2. Preconditions Summary + Citizen Schema (TTL) → Information Model (JSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8914de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditions_summary = read_txt(f\"Results/{document_name} preconditions summary.txt\")\n",
    "citizen_schema = read_txt(f\"Citizens/{document_name} schema.ttl\")\n",
    "\n",
    "class Paths(BaseModel):\n",
    "    path: List[str]\n",
    "    datatype: str\n",
    "    \n",
    "class InformationConcept(BaseModel):\n",
    "    name: str\n",
    "    related_paths: List[Paths]  # links the concept to citizen data available\n",
    "    \n",
    "class Constraint(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    constrains: List[InformationConcept]  \n",
    "\n",
    "schema = list[Constraint]\n",
    "\n",
    "# Formulate prompt content and call Gemini\n",
    "prompt = read_txt('Prompts/preconditions_to_JSON.txt')\n",
    "content = [prompt, preconditions_summary, citizen_schema]\n",
    "\n",
    "info_model = with_retries(call_gemini_json, content, schema)\n",
    "\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} information model.json\", \"w\") as f:\n",
    "    f.write(info_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e56db",
   "metadata": {},
   "source": [
    "### 1.3 Information Model (JSON) → Public Service Graph (TTL)\n",
    "\n",
    "Use deterministic code to turn the JSON into a knowledge graph using TTL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532c69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIXES = \"\"\"@prefix ex: <http://example.org/> .\n",
    "@prefix cccev: <http://data.europa.eu/m8g/> .\n",
    "@prefix cpsv: <http://purl.org/vocab/cpsv#> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON string\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "# Get service name. As per the prompt, it's in the first line of the preconditions summary file\n",
    "with open(f\"Results/{document_name} preconditions summary.txt\") as f:\n",
    "    line = f.readline()\n",
    "    service_name = re.findall(r'Title: (.+)', line)[0].strip().replace(\" \", \"_\")\n",
    "\n",
    "triples = [PREFIXES]\n",
    "triples.append(f\"ex:{service_name} a cpsv:PublicService .\\n\\n\")\n",
    "\n",
    "# Convert constraints + concepts into triples\n",
    "for constraint in info_model:\n",
    "    constraint_name = constraint[\"name\"]\n",
    "    constraint_desc = constraint[\"desc\"].replace('\"', '\\\\\"')\n",
    "\n",
    "    # Public service -> holdsRequirement -> constraint\n",
    "    triples.append(f\"ex:{service_name} cpsv:holdsRequirement ex:{constraint_name} .\\n\")\n",
    "\n",
    "    # Constraint node\n",
    "    triples.append(f'ex:{constraint_name} a cccev:Constraint ; dct:description \"{constraint_desc}\" .\\n')\n",
    "\n",
    "    # InformationConcept nodes\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        concept_name = concept[\"name\"]\n",
    "\n",
    "        # Link constraint to concept\n",
    "        triples.append(f\"ex:{constraint_name} cccev:constrains ex:{concept_name} .\\n\")\n",
    "\n",
    "        # Declare information concept\n",
    "        triples.append(f'ex:{concept_name} a cccev:InformationConcept .\\n')\n",
    "\n",
    "    triples.append(\"\\n\")  # spacing for readability\n",
    "\n",
    "triples_string = \"\".join(triples)\n",
    "# Save to a file too\n",
    "with open(f\"Results/{document_name} service graph.ttl\", \"w\") as f:\n",
    "    f.write(triples_string)   \n",
    "     \n",
    "# Log \n",
    "ctx[\"Service Graph Hash\"] = get_semantic_hash(triples_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cde916",
   "metadata": {},
   "source": [
    "### 1.4. Graph Visualization / Inspection\n",
    "\n",
    "Visualize part of the knowledge graph to more easily inspect correct structure and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c214e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render graph of the public service\n",
    "visualize_graph(f\"Results/{document_name} service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a786b99",
   "metadata": {},
   "source": [
    "## Phase 2: SHACL Rule Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df71800",
   "metadata": {},
   "source": [
    "### 2.1. Information Model (JSON) → SHACL-spec (JSON)\n",
    "\n",
    "Use deterministic code on the JSON from before to make a new intermediate JSON that contains only the necessary information to construct SHACL shapes, one for each constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a72ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the information model JSON\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "shacl_spec_json = []\n",
    "\n",
    "for constraint in info_model:\n",
    "    # 1. Rename for clarity downstream\n",
    "    shape_name = constraint[\"name\"].replace(\"_condition\", \"_shape\")\n",
    "    desc = constraint[\"desc\"]\n",
    "    \n",
    "    concepts = []\n",
    "    \n",
    "    # 2. Iterate concepts (e.g., family_income, residency_city)\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        related_paths = []\n",
    "        \n",
    "        paths_source = concept.get(\"related_paths\", []) \n",
    "        \n",
    "        for rp in paths_source:\n",
    "            # Capture the path AND the datatype (URI vs Literal)\n",
    "            related_paths.append({\n",
    "                \"path\": rp[\"path\"],\n",
    "                \"datatype\": rp[\"datatype\"] \n",
    "            })\n",
    "            \n",
    "        concepts.append({\n",
    "            \"name\": concept[\"name\"],\n",
    "            \"related_paths\": related_paths\n",
    "        })\n",
    "    \n",
    "    shacl_spec_json.append({\n",
    "        \"shape_name\": shape_name,\n",
    "        \"desc\": desc,\n",
    "        \"concepts\": concepts\n",
    "    })\n",
    "\n",
    "# Save to file\n",
    "with open(f\"Results/{document_name} shacl-spec.json\", \"w\") as f:\n",
    "    json.dump(shacl_spec_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d920d7",
   "metadata": {},
   "source": [
    "### 2.2. SHACL-spec (JSON) + Citizen Schema (TTL) → SHACL Shapes (TTL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON as string \n",
    "shacl_spec_json = read_json(f\"Results/{document_name} shacl-spec.json\")\n",
    "citizen_schema = read_txt(f\"Citizens/{document_name} schema.ttl\")\n",
    "\n",
    "prompt = read_txt('Prompts/shacl_spec_to_shacl_ttl.txt')\n",
    "content = [prompt, shacl_spec_json, citizen_schema]\n",
    "\n",
    "shacl_shapes = with_retries(call_gemini, content)\n",
    "\n",
    "# Cleanup gemini markdown formatting\n",
    "shacl_shapes = shacl_shapes.strip(\"`\").replace(\"turtle\", \"\").replace(\"ttl\", \"\").strip()\n",
    "\n",
    "# Save it to a file too\n",
    "with open(f\"Results/{document_name} shacl shapes.ttl\", \"w\") as f:\n",
    "    f.write(shacl_shapes)\n",
    "    \n",
    "# Log\n",
    "ctx[\"SHACL Graph Hash\"] = get_semantic_hash(shacl_shapes)\n",
    "\n",
    "is_valid, error_stage, error_message = validate_shacl_syntax(shacl_shapes)\n",
    "ctx[\"SHACL Valid Syntax\"] = is_valid\n",
    "ctx[\"SHACL Error Type\"] = error_stage\n",
    "ctx[\"SHACL Error Message\"] = error_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153df350",
   "metadata": {},
   "source": [
    "## Phase 3: Citizen - Service Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b18742",
   "metadata": {},
   "source": [
    "### 3.1 Public Service Graph (TTL) + Citizen Graph (TTL) + Information Model (JSON) → Citizen-Service Graph (TTL) \n",
    "\n",
    "We expand the Public Service Graph to include Citizen data, properly connected with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e4ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1cb68ebf0f6d4d28b11f2ce08cd1f491 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EX = Namespace(\"http://example.org/\")\n",
    "SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "# Load service and citizen ttl's and info model\n",
    "public_service_ttl = f\"Results/{document_name} service graph.ttl\"\n",
    "citizen_ttl = f\"Citizens/{document_name} eligible.ttl\"\n",
    "info_model = read_json(f\"Results/{document_name} information model.json\", raw=True)\n",
    "\n",
    "# Realize them into graphs\n",
    "g = Graph()\n",
    "g.parse(public_service_ttl, format=\"turtle\")\n",
    "citizen_g = Graph()\n",
    "citizen_g.parse(citizen_ttl, format=\"turtle\")\n",
    "\n",
    "# Merge citizen triples into main graph\n",
    "for t in citizen_g:\n",
    "    g.add(t)\n",
    "    \n",
    "# Automatically determine the root citizen node \n",
    "root_candidates = list(citizen_g.subjects(predicate=None, object=SC.Applicant))\n",
    "citizen_root = root_candidates[0]\n",
    "\n",
    "# Helper: resolve node paths (return nodes, not literals) \n",
    "def resolve_node_path(citizen_g, root_uri, path_list, datatype):\n",
    "    \n",
    "    # 1. Determine how deep to go\n",
    "    if datatype == \"URI\":\n",
    "        # For Identity logic (City, Person), the Value IS the Node.\n",
    "        traversal_parts = path_list\n",
    "    else:\n",
    "        # For Value logic (Income, Area), the Value is a Literal. Stop one step BEFORE the literal to get the Node holding it.\n",
    "        traversal_parts = path_list[:-1]\n",
    "\n",
    "    # 2. Traverse\n",
    "    current_nodes = {root_uri}\n",
    "    \n",
    "    for part in traversal_parts:\n",
    "        next_nodes = set()\n",
    "        pred = SC[part] # Assumes our schema matches the namespace\n",
    "        \n",
    "        for node in current_nodes:\n",
    "            # Find all objects connected by this predicate\n",
    "            for obj in citizen_g.objects(node, pred):\n",
    "                # Safety check: Ensure we don't accidentally traverse into a Literal \n",
    "                # (unless it's the final step of a URI path, but usually URIs point to URIs)\n",
    "                if isinstance(obj, Literal) and datatype == \"URI\":\n",
    "                     continue # Skip weird data errors\n",
    "                next_nodes.add(obj)\n",
    "        \n",
    "        current_nodes = next_nodes\n",
    "        \n",
    "        # Optimization: If dead end, stop early\n",
    "        if not current_nodes:\n",
    "            return set()\n",
    "\n",
    "    return current_nodes\n",
    "\n",
    "# Add mapsTo edges  \n",
    "for constraint in info_model:\n",
    "    for concept in constraint[\"constrains\"]:\n",
    "        concept_uri = EX[concept[\"name\"]]\n",
    "\n",
    "        for path_obj in concept[\"related_paths\"]: \n",
    "            path_list = path_obj[\"path\"]\n",
    "            dtype = path_obj[\"datatype\"] \n",
    "            \n",
    "            # Pass the datatype to the resolver\n",
    "            subject_nodes = resolve_node_path(citizen_g, citizen_root, path_list, dtype)\n",
    "\n",
    "            for subj in subject_nodes:\n",
    "                # Connect the Information Concept to the Data Node\n",
    "                g.add((concept_uri, EX.mapsTo, subj))\n",
    "\n",
    "# Serialize unified graph into ttl and save to file\n",
    "g.serialize(f\"Results/{document_name} citizen-service graph.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ec8ac",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the unified graph\n",
    "\n",
    "We reuse the same function from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7766b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(f\"Results/{document_name} citizen-service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb7ce6",
   "metadata": {},
   "source": [
    "## Phase 4: Citizen Validation and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8306f6",
   "metadata": {},
   "source": [
    "### SHACL Shape Validation\n",
    "\n",
    "Use deterministic code and a pre-made synthetic citizen graph, constructed to fulfil all conditions, and check it against the shape. If something went wrong, a list of violations and comments will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c2b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_validation_report(conforms, results_graph, results_text):\n",
    "    \"\"\"\n",
    "    Parses the SHACL validation graph into a flat dictionary for CSV logging.\n",
    "    \"\"\"\n",
    "    # If it passed, return a clean success record\n",
    "    if conforms:\n",
    "        return {\n",
    "            \"violation_count\": 0,\n",
    "            \"failed_shapes\": \"None\",\n",
    "            \"messages\": \"None\",\n",
    "            \"full_report\": \"Conforms: True\"\n",
    "        }\n",
    "\n",
    "    # If it failed, extract details from the graph\n",
    "    violations = []\n",
    "    failed_shapes = set()\n",
    "    messages = []\n",
    "\n",
    "    # Find all nodes of type sh:ValidationResult\n",
    "    for result_node in results_graph.subjects(RDF.type, SH.ValidationResult):\n",
    "        \n",
    "        # Extract the Shape Name (Source Shape) should return a URI like http://example.org/income_shape\n",
    "        source_shape = results_graph.value(result_node, SH.sourceShape)\n",
    "        if source_shape:\n",
    "            # Split to get just \"income_shape\"\n",
    "            shape_name = str(source_shape).split(\"/\")[-1].split(\"#\")[-1]\n",
    "            failed_shapes.add(shape_name)\n",
    "\n",
    "        # Extract the Message\n",
    "        message = results_graph.value(result_node, SH.resultMessage)\n",
    "        if message:\n",
    "            messages.append(str(message))\n",
    "\n",
    "    return {\n",
    "        \"violation_count\": len(messages),\n",
    "        \"failed_shapes\": \"; \".join(sorted(list(failed_shapes))), # Stringify for CSV\n",
    "        \"messages\": \" | \".join(messages), # Stringify for CSV\n",
    "        \"full_report\": results_text # Keep raw text just in case\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf047e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# those will be drawn from the scenario framework later\n",
    "ctx[\"Scenario ID\"] = 1\n",
    "ctx[\"Scenario Description\"] = \"Lease duration too short.\"\n",
    "ctx[\"Expected Violation Count\"] = 1\n",
    "\n",
    "# execute mutation scenario\n",
    "conforms, results_graph, results_text = validate(\n",
    "    data_graph=f\"Citizens/{document_name} not eligible.ttl\",\n",
    "    shacl_graph=f\"Results/{document_name} shacl shapes.ttl\",\n",
    "    inference='rdfs',\n",
    ")\n",
    "\n",
    "parse_result = parse_validation_report(conforms, results_graph, results_text)\n",
    "ctx[\"Actual Violation Count\"] = parse_result[\"violation_count\"]\n",
    "ctx[\"Violated Shapes\"] = parse_result[\"failed_shapes\"]\n",
    "ctx[\"Violation Messages\"] = parse_result[\"messages\"]\n",
    "\n",
    "ctx[\"Execution Time\"] = round(time.time() - execution_start_time)\n",
    "ctx[\"Successfully Executed\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b5b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Logged Run 1 to CSV.\n"
     ]
    }
   ],
   "source": [
    "# Write to csv\n",
    "CSV_FILE = \"Master_Results.csv\"\n",
    "\n",
    "def flush_context_to_csv(context_dict):\n",
    "    # Read headers from the existing file\n",
    "    with open(CSV_FILE, 'r', encoding='utf-8', newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader) # Grabs the first row (the headers)\n",
    "\n",
    "    # Align data to those headers\n",
    "    row_data = []\n",
    "    for h in headers:\n",
    "        value = context_dict.get(h, \"N/A\") # safe get with default\n",
    "        row_data.append(value)\n",
    "\n",
    "    # Write the row\n",
    "    with open(CSV_FILE, 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(row_data)\n",
    "        \n",
    "    print(f\"-> Logged Run {context_dict.get('Run ID', '?')} to CSV.\")\n",
    "\n",
    "\n",
    "flush_context_to_csv(ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cdaad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
