{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2121267f",
   "metadata": {},
   "source": [
    "# Experimental notebook for document structured knowledge extraction\n",
    "\n",
    "This is the fourth iteration of the pipeline, the first one to be pushed in the repo, and thus the first official version. Version history will now be handled by git.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from rdflib import Graph, Namespace, Literal\n",
    "from pyshacl import validate\n",
    "import datetime\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "# Local imports\n",
    "from src.llm_utils import initialize_gemini_client, call_gemini, call_gemini_pdf, call_gemini_json, with_retries\n",
    "from src.graph_utils import visualize_graph, get_semantic_hash, validate_shacl_syntax\n",
    "from src.parsing_utils import read_txt, read_json\n",
    "from src.testing_utils import parse_validation_report, apply_mutations, flush_context_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6751506",
   "metadata": {},
   "source": [
    "### Initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28f6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_MODEL = \"gemini-2.5-pro\"\n",
    "DOCUMENT_NAME = \"student_housing\"\n",
    "CSV_FILE = \"Master_Results.csv\"\n",
    "\n",
    "initialize_gemini_client(model_name=GEMINI_MODEL)\n",
    "\n",
    "current_run_id = 1 # TODO: this will be part of the framework later, fetched from the csv last entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d72fec",
   "metadata": {},
   "source": [
    "## Preparation: Get everything ready for logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac5d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a blank slate for a single run\n",
    "def initialize_run_context(run_id, doc_name, model_name):\n",
    "    return {\n",
    "        # --- Metadata ---\n",
    "        \"Run ID\": run_id,\n",
    "        \"Document Name\": doc_name,\n",
    "        \"Timestamp\": datetime.datetime.now().isoformat(sep=\" \", timespec=\"seconds\"),\n",
    "        \"Model Name\": model_name,\n",
    "        \n",
    "        # --- Pipeline Artifacts (Placeholders) ---\n",
    "        \"Service Graph Hash\": \"N/A\",\n",
    "        \"SHACL Graph Hash\": \"N/A\",\n",
    "        \"SHACL Valid Syntax\": False,\n",
    "        \"SHACL Error Type\": \"N/A\",\n",
    "        \"SHACL Error Message\": \"N/A\",\n",
    "        \n",
    "        # --- Scenario Specifics (Will be overwritten per scenario) ---\n",
    "        \"Scenario ID\": \"N/A\",\n",
    "        \"Scenario Description\": \"N/A\",\n",
    "        \"Expected Violation Count\": 0,\n",
    "        \"Actual Violation Count\": 0,\n",
    "        \"Violated Shapes\": [],\n",
    "        \"Violation Messages\": [],\n",
    "        \"Raw Validation Report\": \"N/A\",\n",
    "        \n",
    "        # --- Execution Stats ---\n",
    "        \"Execution Time\": 0.0,\n",
    "        \"Successfully Executed\": False,\n",
    "    }\n",
    "    \n",
    "ctx = initialize_run_context(current_run_id, DOCUMENT_NAME, GEMINI_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed94713",
   "metadata": {},
   "source": [
    "## Phase 1: Public service modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4446dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin the outer loop here\n",
    "# e.g. for current_run_id in range(last_run_id, last_run_id + N):\n",
    "\n",
    "execution_start_time = time.time()\n",
    "\n",
    "current_run_id = 999 # temporary override. TODO: this will be handleded by the core pipeine function\n",
    "\n",
    "# Create artifact directory for this run\n",
    "artifact_dir = f\"Testing Artifacts/RUN_{current_run_id}_{DOCUMENT_NAME}/\" \n",
    "if not os.path.exists(artifact_dir):\n",
    "    os.makedirs(artifact_dir)\n",
    "else:\n",
    "    raise FileExistsError(f\"Artifact directory {artifact_dir} already exists. Aborting to prevent overwriting.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c0ef0",
   "metadata": {},
   "source": [
    "### 1.1 Document → Preconditions Summary\n",
    "\n",
    "Use LLM to summarize the document into a list of preconditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a2fdc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Student Housing Allowance\n",
      "Conditions:\n",
      "- The student must be a Greek citizen or a citizen of another European Union country.\n",
      "- The student must be enrolled in an undergraduate program at a Higher Education Institution (AEI) to obtain their first degree.\n",
      "- The student must have successfully passed exams in at least half of the required courses for the preceding academic year.\n",
      "- The student must possess a valid academic ID.\n",
      "- The student's annual family income for the previous tax year must not exceed €30,000. This limit is increased by €3,000 for each dependent child after the first.\n",
      "- The student must be renting a property in a city other than their city of permanent residence due to their studies.\n",
      "- The student's rental lease must have a duration of at least six months.\n",
      "- In the student's city of permanent residence, neither the student nor their parents can have full ownership or usufruct of a property.\n",
      "- The total area of properties (owner-occupied or rented out) owned by the student or their parents must not exceed 200 square meters. (This calculation excludes properties located in municipalities with a population of less than 3,000).\n",
      "- If the student is cohabiting with another student to receive an increased allowance, the cohabiting student must also be an undergraduate student studying for their first degree, must not have exceeded the standard duration of their studies, and must be enrolled in an institution in the same city or regional unit.\n"
     ]
    }
   ],
   "source": [
    "file_path = f\"Precondition documents/{DOCUMENT_NAME}.pdf\"\n",
    "\n",
    "prompt = read_txt('Prompts/summarization.txt')\n",
    "\n",
    "preconditions_summary = with_retries(call_gemini_pdf, prompt, file_path)\n",
    "print(preconditions_summary)\n",
    "\n",
    "# Save artifact\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} preconditions summary.txt\", \"w\") as f:\n",
    "    f.write(preconditions_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5a4f3",
   "metadata": {},
   "source": [
    "### 1.2. Preconditions Summary + Citizen Schema (TTL) → Information Model (JSON)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preconditions_summary = read_txt(f\"{artifact_dir}{DOCUMENT_NAME} preconditions summary.txt\")\n",
    "citizen_schema = read_txt(f\"Citizens/{DOCUMENT_NAME} schema.ttl\")\n",
    "\n",
    "class Paths(BaseModel):\n",
    "    path: List[str]\n",
    "    datatype: str\n",
    "    \n",
    "class InformationConcept(BaseModel):\n",
    "    name: str\n",
    "    related_paths: List[Paths]  # links the concept to citizen data available\n",
    "    \n",
    "class Constraint(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    constrains: List[InformationConcept]  \n",
    "\n",
    "schema = list[Constraint]\n",
    "\n",
    "# Formulate prompt content and call Gemini\n",
    "prompt = read_txt('Prompts/preconditions_to_JSON.txt')\n",
    "content = [prompt, preconditions_summary, citizen_schema]\n",
    "\n",
    "info_model = with_retries(call_gemini_json, content, schema)\n",
    "\n",
    "# Save artifact\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} information model.json\", \"w\") as f:\n",
    "    f.write(info_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e56db",
   "metadata": {},
   "source": [
    "### 1.3 Information Model (JSON) → Public Service Graph (TTL)\n",
    "\n",
    "Use deterministic code to turn the JSON into a knowledge graph using TTL syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIXES = \"\"\"@prefix ex: <http://example.org/> .\n",
    "@prefix cccev: <http://data.europa.eu/m8g/> .\n",
    "@prefix cpsv: <http://purl.org/vocab/cpsv#> .\n",
    "@prefix dct: <http://purl.org/dc/terms/> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Parse JSON string\n",
    "info_model = read_json(f\"{artifact_dir}{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "# Get service name. As per the prompt, it's in the first line of the preconditions summary file\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} preconditions summary.txt\") as f:\n",
    "    line = f.readline()\n",
    "    service_name = re.findall(r'Title: (.+)', line)[0].strip().replace(\" \", \"_\")\n",
    "\n",
    "triples = [PREFIXES]\n",
    "triples.append(f\"ex:{service_name} a cpsv:PublicService .\\n\\n\")\n",
    "\n",
    "# Convert constraints + concepts into triples\n",
    "for constraint in info_model:\n",
    "    constraint_name = constraint[\"name\"]\n",
    "    constraint_desc = constraint[\"desc\"].replace('\"', '\\\\\"')\n",
    "\n",
    "    # Public service -> holdsRequirement -> constraint\n",
    "    triples.append(f\"ex:{service_name} cpsv:holdsRequirement ex:{constraint_name} .\\n\")\n",
    "\n",
    "    # Constraint node\n",
    "    triples.append(f'ex:{constraint_name} a cccev:Constraint ; dct:description \"{constraint_desc}\" .\\n')\n",
    "\n",
    "    # InformationConcept nodes\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        concept_name = concept[\"name\"]\n",
    "\n",
    "        # Link constraint to concept\n",
    "        triples.append(f\"ex:{constraint_name} cccev:constrains ex:{concept_name} .\\n\")\n",
    "\n",
    "        # Declare information concept\n",
    "        triples.append(f'ex:{concept_name} a cccev:InformationConcept .\\n')\n",
    "\n",
    "    triples.append(\"\\n\")  # spacing for readability\n",
    "\n",
    "triples_string = \"\".join(triples)\n",
    "\n",
    "# Save artifact\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} service graph.ttl\", \"w\") as f:\n",
    "    f.write(triples_string)   \n",
    "     \n",
    "# Log \n",
    "ctx[\"Service Graph Hash\"] = get_semantic_hash(triples_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cde916",
   "metadata": {},
   "source": [
    "### 1.4. Graph Visualization / Inspection\n",
    "\n",
    "Visualize part of the knowledge graph to more easily inspect correct structure and logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c214e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render graph of the public service\n",
    "visualize_graph(f\"{artifact_dir}{DOCUMENT_NAME} service graph.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a786b99",
   "metadata": {},
   "source": [
    "## Phase 2: SHACL Rule Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df71800",
   "metadata": {},
   "source": [
    "### 2.1. Information Model (JSON) → SHACL-spec (JSON)\n",
    "\n",
    "Use deterministic code on the JSON from before to make a new intermediate JSON that contains only the necessary information to construct SHACL shapes, one for each constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a72ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the information model JSON\n",
    "info_model = read_json(f\"{artifact_dir}{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "shacl_spec_json = []\n",
    "\n",
    "for constraint in info_model:\n",
    "    # 1. Rename for clarity downstream\n",
    "    shape_name = constraint[\"name\"].replace(\"_condition\", \"_shape\")\n",
    "    desc = constraint[\"desc\"]\n",
    "    \n",
    "    concepts = []\n",
    "    \n",
    "    # 2. Iterate concepts (e.g., family_income, residency_city)\n",
    "    for concept in constraint.get(\"constrains\", []):\n",
    "        related_paths = []\n",
    "        \n",
    "        paths_source = concept.get(\"related_paths\", []) \n",
    "        \n",
    "        for rp in paths_source:\n",
    "            # Capture the path AND the datatype (URI vs Literal)\n",
    "            related_paths.append({\n",
    "                \"path\": rp[\"path\"],\n",
    "                \"datatype\": rp[\"datatype\"] \n",
    "            })\n",
    "            \n",
    "        concepts.append({\n",
    "            \"name\": concept[\"name\"],\n",
    "            \"related_paths\": related_paths\n",
    "        })\n",
    "    \n",
    "    shacl_spec_json.append({\n",
    "        \"shape_name\": shape_name,\n",
    "        \"desc\": desc,\n",
    "        \"concepts\": concepts\n",
    "    })\n",
    "\n",
    "# Save artifact\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} shacl-spec.json\", \"w\") as f:\n",
    "    json.dump(shacl_spec_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d920d7",
   "metadata": {},
   "source": [
    "### 2.2. SHACL-spec (JSON) + Citizen Schema (TTL) → SHACL Shapes (TTL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3af767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON as string \n",
    "shacl_spec_json = read_json(f\"{artifact_dir}{DOCUMENT_NAME} shacl-spec.json\")\n",
    "citizen_schema = read_txt(f\"Citizens/{DOCUMENT_NAME} schema.ttl\")\n",
    "\n",
    "prompt = read_txt('Prompts/shacl_spec_to_shacl_ttl.txt')\n",
    "content = [prompt, shacl_spec_json, citizen_schema]\n",
    "\n",
    "shacl_shapes = with_retries(call_gemini, content)\n",
    "\n",
    "# Cleanup gemini markdown formatting\n",
    "shacl_shapes = shacl_shapes.strip(\"`\").replace(\"turtle\", \"\").replace(\"ttl\", \"\").strip()\n",
    "\n",
    "# Save artifact\n",
    "with open(f\"{artifact_dir}{DOCUMENT_NAME} shacl shapes.ttl\", \"w\") as f:\n",
    "    f.write(shacl_shapes)\n",
    "    \n",
    "# Log\n",
    "ctx[\"SHACL Graph Hash\"] = get_semantic_hash(shacl_shapes)\n",
    "is_valid, error_stage, error_message = validate_shacl_syntax(shacl_shapes)\n",
    "ctx[\"SHACL Valid Syntax\"] = is_valid\n",
    "ctx[\"SHACL Error Type\"] = error_stage\n",
    "ctx[\"SHACL Error Message\"] = error_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153df350",
   "metadata": {},
   "source": [
    "## Phase 3: Citizen - Service Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b18742",
   "metadata": {},
   "source": [
    "### 3.1 Public Service Graph (TTL) + Citizen Graph (TTL) + Information Model (JSON) → Citizen-Service Graph (TTL) \n",
    "\n",
    "We expand the Public Service Graph to include Citizen data, properly connected with edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4ac36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1b3b3494b4634305b57f0f1232329d47 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EX = Namespace(\"http://example.org/\")\n",
    "SC = Namespace(\"http://example.org/schema#\")\n",
    "\n",
    "# Load service and citizen ttl's and info model\n",
    "public_service_ttl = f\"{artifact_dir}{DOCUMENT_NAME} service graph.ttl\"\n",
    "citizen_ttl = f\"Citizens/{DOCUMENT_NAME} eligible.ttl\"\n",
    "info_model = read_json(f\"{artifact_dir}{DOCUMENT_NAME} information model.json\", raw=True)\n",
    "\n",
    "# Realize them into graphs\n",
    "g = Graph()\n",
    "g.parse(public_service_ttl, format=\"turtle\")\n",
    "citizen_g = Graph()\n",
    "citizen_g.parse(citizen_ttl, format=\"turtle\")\n",
    "\n",
    "# Merge citizen triples into main graph\n",
    "for t in citizen_g:\n",
    "    g.add(t)\n",
    "    \n",
    "# Automatically determine the root citizen node \n",
    "root_candidates = list(citizen_g.subjects(predicate=None, object=SC.Applicant))\n",
    "citizen_root = root_candidates[0]\n",
    "\n",
    "# Helper: resolve node paths (return nodes, not literals) \n",
    "def resolve_node_path(citizen_g, root_uri, path_list, datatype):\n",
    "    \n",
    "    # 1. Determine how deep to go\n",
    "    if datatype == \"URI\":\n",
    "        # For Identity logic (City, Person), the Value IS the Node.\n",
    "        traversal_parts = path_list\n",
    "    else:\n",
    "        # For Value logic (Income, Area), the Value is a Literal. Stop one step BEFORE the literal to get the Node holding it.\n",
    "        traversal_parts = path_list[:-1]\n",
    "\n",
    "    # 2. Traverse\n",
    "    current_nodes = {root_uri}\n",
    "    \n",
    "    for part in traversal_parts:\n",
    "        next_nodes = set()\n",
    "        pred = SC[part] # Assumes our schema matches the namespace\n",
    "        \n",
    "        for node in current_nodes:\n",
    "            # Find all objects connected by this predicate\n",
    "            for obj in citizen_g.objects(node, pred):\n",
    "                # Safety check: Ensure we don't accidentally traverse into a Literal \n",
    "                # (unless it's the final step of a URI path, but usually URIs point to URIs)\n",
    "                if isinstance(obj, Literal) and datatype == \"URI\":\n",
    "                     continue # Skip weird data errors\n",
    "                next_nodes.add(obj)\n",
    "        \n",
    "        current_nodes = next_nodes\n",
    "        \n",
    "        # Optimization: If dead end, stop early\n",
    "        if not current_nodes:\n",
    "            return set()\n",
    "\n",
    "    return current_nodes\n",
    "\n",
    "# Add mapsTo edges  \n",
    "for constraint in info_model:\n",
    "    for concept in constraint[\"constrains\"]:\n",
    "        concept_uri = EX[concept[\"name\"]]\n",
    "\n",
    "        for path_obj in concept[\"related_paths\"]: \n",
    "            path_list = path_obj[\"path\"]\n",
    "            dtype = path_obj[\"datatype\"] \n",
    "            \n",
    "            # Pass the datatype to the resolver\n",
    "            subject_nodes = resolve_node_path(citizen_g, citizen_root, path_list, dtype)\n",
    "\n",
    "            for subj in subject_nodes:\n",
    "                # Connect the Information Concept to the Data Node\n",
    "                g.add((concept_uri, EX.mapsTo, subj))\n",
    "\n",
    "# Serialize unified graph into ttl and save to file\n",
    "g.serialize(f\"{artifact_dir}{DOCUMENT_NAME} citizen-service graph.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ec8ac",
   "metadata": {},
   "source": [
    "### 3.2 Visualize the unified graph\n",
    "\n",
    "We reuse the same function from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(f\"{artifact_dir}{DOCUMENT_NAME} citizen-service graph.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This marks the end of the main pipeline. \n",
    "ctx[\"Execution Time\"] = round(time.time() - execution_start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb7ce6",
   "metadata": {},
   "source": [
    "## Phase 4: Citizen Validation and Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8306f6",
   "metadata": {},
   "source": [
    "### SHACL Shape Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6a2fc6",
   "metadata": {},
   "source": [
    "Begin the scenario loop, writing to csv after every scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Run 1 to CSV.\n"
     ]
    }
   ],
   "source": [
    "# Load the Golden Citizen (Baseline)\n",
    "golden_ttl = f\"Citizens/{DOCUMENT_NAME} eligible.ttl\"\n",
    "golden_graph = Graph()\n",
    "golden_graph.parse(golden_ttl, format=\"turtle\")\n",
    "\n",
    "# Load the Scenarios from YAML\n",
    "with open(f\"Citizens/{DOCUMENT_NAME} scenarios.yaml\", \"r\") as f:\n",
    "    scenarios = yaml.safe_load(f)\n",
    "\n",
    "# Iterate and Apply\n",
    "for scn in scenarios:\n",
    "    ctx[\"Scenario ID\"] = scn['id']\n",
    "    ctx[\"Scenario Description\"] = scn['description']\n",
    "    ctx[\"Expected Violation Count\"] = scn['expected_violation_count']\n",
    "    \n",
    "    # Apply mutations (Returns a NEW graph, leaving golden_graph untouched)\n",
    "    mutated_graph = apply_mutations(golden_graph, scn['actions'])\n",
    "\n",
    "    # Proceed to Validation \n",
    "    conforms, results_graph, results_text = validate(\n",
    "        data_graph=mutated_graph,\n",
    "        shacl_graph=f\"{artifact_dir}{DOCUMENT_NAME} shacl shapes.ttl\",\n",
    "        inference='rdfs',\n",
    "    )\n",
    "    \n",
    "    # Parse validation report\n",
    "    parse_result = parse_validation_report(conforms, results_graph, results_text)\n",
    "    ctx[\"Actual Violation Count\"] = parse_result[\"violation_count\"]\n",
    "    ctx[\"Violated Shapes\"] = parse_result[\"failed_shapes\"]\n",
    "    ctx[\"Violation Messages\"] = parse_result[\"messages\"]\n",
    "\n",
    "    # If we made it this far\n",
    "    ctx[\"Successfully Executed\"] = True\n",
    "    \n",
    "    flush_context_to_csv(ctx, CSV_FILE) #  TODO this will be outside the try except block as finally\n",
    "    \n",
    "# Report End of the run to console\n",
    "print(f\"Logged Run {ctx['Run ID']} to CSV.\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
