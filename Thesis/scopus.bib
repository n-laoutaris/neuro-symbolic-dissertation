Scopus
EXPORT DATE: 01 December 2025

@Article{AhmedKhan2026,
  author            = {Ahmed Khan, Junaid Ahmed and Molan, Martin and Bartolini, Andrea},
  journal           = {Future Generation Computer Systems},
  title             = {EXASAGE: The first data center operational data analysis assistant},
  year              = {2026},
  note              = {Cited by: 0; All Open Access; Hybrid Gold Open Access},
  volume            = {176},
  abstract          = {Data centers increasingly rely on Operational Data Analytics (ODA) for real-time insights from vast streams of telemetry data. They typically utilize NoSQL databases for scalability and to handle diverse data types, which results in unstructured data representations and poses significant challenges for data retrieval and interoperability. Indeed, the lack of standardization, combined with schema flexibility and complex data structures, makes it difficult for system administrators to write and execute queries, ultimately complicating the automation of data retrieval tasks. Pre-trained Large Language Models (LLMs), with their latent knowledge, promise a ready-to-use AI-driven data interoperability layer, enabling data retrieval through natural language input. However, they often generate inaccurate or hallucinated query code when handling heterogeneous data sources and complex data structures. In this paper, we present EXASAGE, the first operational data analysis assistant for ODA, which leverages a Knowledge Graph (KG)-based approach to provide an AI-driven interoperable layer that addresses LLM limitations and simplifies data retrieval tasks in data center facilities through a prototype implementation. EXASAGE employs an LLM-based query generator to convert natural language into SPARQL queries (native to KGs), executed at a graph database endpoint, along with a virtual KG approach that dynamically generates KGs with only the data relevant to the user’s input query, significantly reducing the storage overhead associated with a fully materialized KG in such large-scale telemetry systems. In evaluations on 1000 user input queries, EXASAGE achieved a 93.6 % accuracy in generating correct SPARQL code and retrieving correct answers, significantly outperforming the 25 % accuracy of NoSQL/SQLite queries, which frequently exhibited severe hallucinations. Furthermore, SPARQL queries were generally more concise and demonstrate shorter inference and execution times compared to NoSQL/SQLite queries. The average end-to-end time for a single execution cycle was 12.77s, making it suitable for interactive, non-critical operational data analysis tasks. The maximum observed storage overhead across all generated virtual KGs was just 52.62 MiB. © 2025 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).},
  author_keywords   = {Data centers; Knowledge Graph (KG); Large Language Models (LLMs); Natural language query generation; Operational Data Analytics (ODA) monitoring frameworks; Resource Description Language (RDF); Virtual Knowledge Graph (VKG)},
  doi               = {10.1016/j.future.2025.108185},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  keywords          = {Codes (symbols); Data centers; Data reduction; Data structures; Digital storage; Graph Databases; Information retrieval; Interoperability; Knowledge graph; Query languages; Query processing; Search engines; Software prototyping; Structured Query Language; Telemetering; Data analytics; Datacenter; Knowledge graphs; Language model; Large language model; Monitoring frameworks; Natural language queries; Natural language query generation; Operational data; Operational data analytic monitoring framework; Query generation; Resource description language (RDF); Resource description languages; Virtual knowledge; Virtual knowledge graph; Telemetering equipment},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020818559&doi=10.1016%2Fj.future.2025.108185&partnerID=40&md5=ef77e4685cb082fc463462a1fe67fdee},
}

@Article{Oranekwu2026,
  author            = {Oranekwu, Ikechukwu and Elluri, Lavanya and Yus, Roberto and Kotal, Anantaa},
  journal           = {Computers and Security},
  title             = {Scalable automation for IoT cyberSecurity compliance: Ontology-driven reasoning for real-time assessment},
  year              = {2026},
  note              = {Cited by: 0},
  volume            = {161},
  abstract          = {In recent years, the rapid expansion of the Internet of Things (IoT) has introduced significant cybersecurity challenges, requiring manufacturers to comply with various regulatory frameworks and cybersecurity standards. Hence, to protect user data and privacy, all organizations providing IoT devices must adhere to complex guidelines such as the National Institute of Standards and Technology Inter-Agency Report (NISTIR) 8259, which defines essential cybersecurity guidelines for IoT manufacturers. However, interpreting and applying these rules from these guidelines remains a significant challenge for companies. Previously, our Automated Knowledge Framework for IoT Cybersecurity Compliance, leveraged SWRL, SPARQL queries, Web Ontology Language and Visualization (OWL Viz), Semantic Web technologies, Large Language Models (LLMs), and Retrieval Augmented Generation (RAG) pipeline to automate compliance assessment of multiple Functional requirement documents (FRDs), while systematically cross-checking Business requirement documents (BRDs) against them [Oranekwu et al., 2024]. However, these efforts primarily focused on mapping NISTIR 8259 guidelines into a structured ontology laying the foundation for us to build, expand on, and then integrate the IoT Cybersecurity Improvement Act of 2020 into the compliance framework. Furthermore, exploring its big data capability, the Knowledge Graph (KG) has been expanded and populated with more than 800 manufacturer privacy policy instances, allowing direct comparison between manufacturer-defined data properties, object properties, and regulatory compliance expectations. The primary objective is to evaluate the effectiveness of this enhanced version of the framework in identifying policy non-compliance by comparing triples extracted from privacy policies against the structured knowledge representation. Through this approach, our goal is to automate compliance verification by examining the relationships between manufacturers, security requirements, and regulatory obligations, offering a scalable solution for the security governance of IoT. © 2025 Elsevier Ltd},
  author_keywords   = {Cybersecurity compliance; Governance; Guidelines; Internet of things; Knowledge graphs; Large language model; NISTIR; Ontology reasoning; Privacy policy analysis; Retrieval augmented generation; Security; Semantic web technologies; SPARQL; Standards; SWRL},
  doi               = {10.1016/j.cose.2025.104711},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  keywords          = {Big data; Compliance control; Cybersecurity; Data privacy; Knowledge management; Network security; Ontology; Public policy; Query languages; Regulatory compliance; Requirements engineering; Semantic Web; Cyber security; Cybersecurity compliance; Governance; Guideline; Knowledge graphs; Language model; Large language model; National institute of standard and technology inter-agency report; National Institute of Standards and Technology; Ontology reasonings; Policy analysis; Privacy policies; Privacy policy analyze; Retrieval augmented generation; Security; Semantic Web technology; SPARQL; SWRL; Internet of things},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021647823&doi=10.1016%2Fj.cose.2025.104711&partnerID=40&md5=f5c98d85516ba89ccb901516aa2a17ff},
}

@Article{Walter2026271,
  author            = {Walter, Sebastian and Bast, Hannah},
  journal           = {Lecture Notes in Computer Science},
  title             = {GRASP: Generic Reasoning And SPARQL Generation Across Knowledge Graphs},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {271 - 289},
  volume            = {16140 LNCS},
  abstract          = {We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Knowledge Graphs; Question Answering; SPARQL},
  doi               = {10.1007/978-3-032-09527-5_15},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Graph theory; Graphic methods; Knowledge graph; Natural language processing systems; Query languages; Query processing; Question answering; Fine tuning; Generic reasoning; Keyword queries; Knowledge graphs; Language model; Literals; Natural language questions; New approaches; Question Answering; SPARQL; Computational linguistics},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022015846&doi=10.1007%2F978-3-032-09527-5_15&partnerID=40&md5=f61594e55864029bb50e3d0d32503220},
}

@Article{Schmidt20263,
  author            = {Schmidt, David Maria and Schubert, Raoul and Cimiano, Philipp},
  journal           = {Lecture Notes in Computer Science},
  title             = {CompoST: A Benchmark for Analyzing the Ability of LLMs to Compositionally Interpret Questions in a QALD Setting},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {3 - 22},
  volume            = {16140 LNCS},
  abstract          = {Language interpretation is a compositional process, in which the meaning of more complex linguistic structures is inferred from the meaning of their parts. Large language models possess remarkable language interpretation capabilities and have been successfully applied to interpret questions by mapping them to SPARQL queries. An open question is how systematic this interpretation process is. Toward this question, in this paper, we propose a benchmark for investigating to what extent the abilities of LLMs to interpret questions are actually compositional. For this, we generate three datasets of varying difficulty based on graph patterns in DBpedia, relying on Lemon lexica for verbalization. Our datasets are created in a very controlled fashion in order to test the ability of LLMs to interpret structurally complex questions, given that they have seen the atomic building blocks. This allows us to evaluate to what degree LLMs are able to interpret complex questions for which they “understand” the atomic parts. We conduct experiments with models of different sizes using both various prompt and few-shot optimization techniques as well as fine-tuning. Our results show that performance in terms of macro F<inf>1</inf> degrades from 0.45 over 0.26 down to 0.09 with increasing deviation from the samples optimized on. Even when all necessary information was provided to the model in the input, the F<inf>1</inf> scores do not exceed 0.57 for the dataset of lowest complexity. We thus conclude that LLMs struggle to systematically and compositionally interpret questions and map them into SPARQL queries. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Compositionality; Large Language Models; Question Answering over Linked Data; Semantic Web},
  doi               = {10.1007/978-3-032-09527-5_1},
  keywords          = {Computational linguistics; Natural language processing systems; Query processing; Question answering; Statistical tests; Complex questions; Compositionality; Dbpedia; Graph patterns; Language model; Large language model; Linguistic structure; Question Answering; Question answering over linked data; Semantic-Web; Semantic Web},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021983881&doi=10.1007%2F978-3-032-09527-5_1&partnerID=40&md5=4e108dfbc9e33fc0c1ece6daaa4aa839},
}

@Article{2026,
  journal           = {Lecture Notes in Computer Science},
  title             = {9th International Joint Conference on Rules and Reasoning, RuleML+RR 2025},
  year              = {2026},
  note              = {Cited by: 0},
  volume            = {16144 LNCS},
  abstract          = {The proceedings contain 15 papers. The special focus in this conference is on Rules and Reasoning. The topics include: Specifying an Obligation Taxonomy in the Non-Markovian Situation Calculus; a Novel Concept Induction Approach for Explainable Quality 4.0; An Optimized Framework for DSPG Synthesis and Trust Network Analysis with Subjective Logic; when Does Naïve Evaluation Work for Datalog?; scalable Evaluation of Rule-Based Recommender Systems: Algorithms and Benchmarks; rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs; minimizing Side-Effects in Virtual Knowledge Graph Updates; Rule Extraction and Interaction-Aware Explainability for AI-Driven Malware Detection; probabilistic Answer Set Programming Driven Ranking of Dynamic Space-Time Belief Models; learning Interpretable Probabilistic Models and Schema Axioms for Knowledge Graphs; integrating Environmental Regulations into Autonomous Agricultural Robotics: A Case for Waterbody-Aware Fertilization; SPARQL in N3: SPARQL construct as a Rule Language for the Semantic Web; Positioning LLM-Enabled Agents as Legal Compliance Aides for Data Pipelines.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021042744&partnerID=40&md5=e17f42b2a89b9ad47c9c36b026b800be},
}

@Article{Nemtoc2026302,
  author            = {Nemtoc, Teodora Cristiana and Buchmann, Robert Andrei and Silaghi, Gheorghe Cosmin},
  journal           = {Lecture Notes in Computer Science},
  title             = {Comparative Experiments on Natural Language Querying of Knowledge Graphs Using a Graph RAG Approach},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {302 - 319},
  volume            = {16189 LNCS},
  abstract          = {Recent developments in the synergy between Large Language Models (LLMs) and Knowledge Graphs have introduced Graph Retrieval-Augmented Generation (Graph RAG) as an extension to traditional RAG. Graph RAG replaces the unstructured textual ‘knowledge base’ obtained in the retrieval phase of the RAG with Knowledge Graphs to improve entity identification and traceability. In this paper we present a customized Graph RAG framework for handling natural language queries over a knowledge graph with the help of Large Language Models. We conduct a comparative evaluation of several LLMs in responding to different query patterns on a domain-specific knowledge graph, employing four prompting levels defined by the TELeR taxonomy. The outputs are evaluated against ground truth results obtained by executing the corresponding SPARQL queries within a GraphDB triplestore. The content on which the experiments are performed is the Unified Medical Language System (UMLS) semantic network. The results summarize several strengths and weaknesses of the different LLMs relative to the complexity of selected query types, triple patterns, and prompting techniques involved in our Graph RAG setup. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Graph RAG; Knowledge Graphs; Large Language Models; Prompt Engineering; SPARQL Queries; UMLS},
  doi               = {10.1007/978-3-032-08623-5_16},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Computational linguistics; Graph theory; Graphic methods; Knowledge graph; Natural language processing systems; Query languages; Query processing; Semantic Web; Structured Query Language; Comparative experiments; Entity identification; Graph retrieval-augmented generation; Knowledge graphs; Language model; Large language model; Natural languages; Prompt engineering; SPARQL query; Unified medical language systems; Semantics},
  publication_stage = {Final},
  ranking           = {rank4},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020677100&doi=10.1007%2F978-3-032-08623-5_16&partnerID=40&md5=c1b18823896cc2f918b89d10b4e29311},
}

@Article{2026,
  journal           = {Lecture Notes in Computer Science},
  title             = {Satellite events held at the 22nd European Semantic Web Conference, ESWC 2025},
  year              = {2026},
  note              = {Cited by: 0},
  volume            = {15832 LNCS},
  abstract          = {The proceedings contain 49 papers. The special focus in this conference is on European Semantic Web. The topics include: SGF: SPARQL Updates over Decentralized Knowledge Graphs without Access Path Dependencies; a Decentralized Visual Interactive Tool to Analyze Entities in Wikidata; Making WebVOWL Great Again; entitySum: Entity Summarization Using Centrality Measures; Exploring the Underlying Questions of SPARQL Queries with LLMs; SPARQL Query Generation Using LLMs for Medical Information Retrieval; CiteGen: A Web Application for Citation Recommendation Powered by LLMs and Knowledge Graphs; Towards Extracting Triple-to-Text Alignments from Wikidata References Using LLMs; Demonstrating a Pragmatic Solution to Context Associations in RDF Using Blank Node Graphs; Representing and Querying Data Tensors in RDF and SPARQL; sampoSampo: A Portal for Studying Enriched Data and Semantic Connections on a Cultural Heritage Linked Open Data Cloud; ontological Modeling of Drug Trafficking in the Global South Using Newspaper Data; letterSampo Finland (1809–1917) Data Service and Portal: Searching, Exploring, and Analyzing Historical Letters and Their Underlying Networks; OniOn: An RGCN-Based Ontology Alignment Approach for Energy Data Integration; RDF-Based Structured Quality Assessment Representation of Multilingual LLM Evaluations; How Low Can We Go? Quantization Effects on LLM SPARQL Generation; SparqLLM: Retrieval-Augmented SPARQL Query Processing; Scaling NeuroSymbolic AI Integration for Seismic Event Detection; research Institute Knowledge Graph for Internal Organisation and Collaboration; MACS-KG: MAnufacturing CommonSense Knowledge Graph; GitLotus – Transforming Git-Based Project Data into RDF Representations; No-Code ML Pipeline Development: Leveraging Knowledge Graphs and Language Models; MYAM: LLM-Supported Mapping Generation for Semantic Manufacturing Retrieval; Hybrid Search with Multiple Full-Text Indexes over RDF Graphs; Bringing Modern IDE Features to Semantic Web Formats with the Semantic Web Language Server; taxonomy of Anomaly Types in Knowledge Graphs; PM-Sampo: Semantic Portal for Heritage Object Provenance Research; Testbed for Evaluating LLMs on Concept Naming Within Ontology Transformation.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020265435&partnerID=40&md5=160951c2efa8f242b2a592a495f336c7},
}

@Article{Both2026300,
  author            = {Both, Andreas and Herbst, Kai and Krieg, Rene and Landmann, Magdalena and Alef, Martin Raphael and Diettrich, Anton},
  journal           = {Lecture Notes in Computer Science},
  title             = {A Domain-Specific Question-Answering System for Railway Data: A Hybrid Approach},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {300 - 304},
  volume            = {15832 LNCS},
  abstract          = {This paper presents insights into a real-world railway ontology and a corresponding Knowledge Graph Question Answering (KGQA) approach within the domain of train and track operations, developed in collaboration with DB Systel GmbH (subsidiary of the main German railway company). Our solution enables seamless access to infrastructure elements, train schedules, and operational data via a question-answering system powered by Large Language Models (LLMs). To ensure high quality, cost efficiency, and runtime performance, LLMs are utilized exclusively for SPARQL query generation, striking a balance between flexibility and control. This approach significantly enhances the precision and efficiency of information retrieval, making railway data more accessible and actionable. We discuss the implementation, evaluation results, and key trade-offs of our approach. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Corporate Knowledge Graph; Large Language Models; Question Answering},
  doi               = {10.1007/978-3-031-99554-5_45},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Artificial intelligence; Data accuracy; Efficiency; Question answering; Railroad tracks; Railroad transportation; Railroads; Corporate knowledge; Corporate knowledge graph; Domain specific; Hybrid approach; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; Real-world; Economic and social effects},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020246038&doi=10.1007%2F978-3-031-99554-5_45&partnerID=40&md5=5981a505908942b94205970c24480feb},
}

@Article{Molli2026103,
  author            = {Molli, Pascal and Skaf-Molli, Hala and Ferré, Sébastien and Gaignard, Alban and Cellier, Peggy},
  journal           = {Lecture Notes in Computer Science},
  title             = {SparqLLM: Retrieval-Augmented SPARQL Query Processing},
  year              = {2026},
  note              = {Cited by: 0; All Open Access; Green Accepted Open Access; Green Open Access},
  pages             = {103 - 107},
  volume            = {15832 LNCS},
  abstract          = {SPARQL is essential for querying Knowledge Graphs (KGs), but much information exists in external sources rather than within KGs. To address this, we propose SparqLLM, a retrieval-augmented query processing approach that leverages user-defined functions (UDFs) and named graphs to augment SPARQL queries with diverse external sources, including search engines, large language models (LLMs), and vector search. By doing so, SparqLLM significantly enhances SPARQL’s capabilities, enabling a single query to access multiple heterogeneous sources while ensuring query provenance and explainability. This demonstration highlights the potential of SparqLLM to enrich query results with comprehensive, up-to-date information and showcases its application in a real-world use case. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Large Language Models; Search Engines; SPARQL},
  doi               = {10.1007/978-3-031-99554-5_19},
  keywords          = {Information retrieval; Knowledge graph; Knowledge management; Query languages; Query processing; Structured Query Language; External sources; Heterogeneous sources; Knowledge graphs; Language model; Large language model; Named graphs; Processing approach; Query results; SPARQL; User Defined Functions; Search engines},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020243258&doi=10.1007%2F978-3-031-99554-5_19&partnerID=40&md5=48397d1818a18e81b6eca06bd3b98bf7},
}

@Article{Piao202634,
  author            = {Piao, Guangyuan and Sonawane, Pournima and Gupta, Shraddha and Mahony, Aidan O.},
  journal           = {Lecture Notes in Computer Science},
  title             = {Exploring the Underlying Questions of SPARQL Queries with LLMs},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {34 - 39},
  volume            = {15832 LNCS},
  abstract          = {SPARQL queries play a crucial role in exploring knowledge graphs (KGs) and have been widely used in practice. However, understanding what questions are actually asked to KGs by exploring queries directly is a daunting task. In line with recent efforts to leverage Large Language Models (LLMs) for deriving underlying questions of SPARQL queries, we further investigate whether increasing the number of examples in prompting and Chain-of-Thought prompting can improve the performance. Additionally, we examine whether a fine-tuned LLM with one dataset can be used on another dataset to further improve performance. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Large Language Models; SPARQL Query},
  doi               = {10.1007/978-3-031-99554-5_7},
  keywords          = {Knowledge management; Query languages; Query processing; Improve performance; Knowledge graphs; Language model; Large language model; Performance; SPARQL query; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020242142&doi=10.1007%2F978-3-031-99554-5_7&partnerID=40&md5=3047a068c011069b6cd053dfe05956e7},
}

@Article{Marciniak202662,
  author            = {Marciniak, Piotr and Sowiński, Piotr and Ganzha, Maria S.},
  journal           = {Lecture Notes in Computer Science},
  title             = {Representing and Querying Data Tensors in RDF and SPARQL},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {62 - 66},
  volume            = {15832 LNCS},
  abstract          = {Embedding tensors in databases has recently gained in significance, due to the rapid proliferation of machine learning methods (including LLMs) which produce embeddings in the form of tensors. To support emerging use cases hybridizing machine learning with knowledge graphs, a robust and efficient tensor representation scheme is needed. We introduce a novel approach for representing data tensors as literals in RDF, along with an extension of SPARQL implementing specialized functionalities for handling such literals. The extension includes 36 SPARQL functions and four aggregates. To support this approach, we provide a thoroughly tested, open-source implementation based on Apache Jena, along with an exemplary knowledge graph and query set. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Data tensors; Embedding; Large Language Models; Neurosymbolic AI; RDF; SPARQL},
  doi               = {10.1007/978-3-031-99554-5_12},
  keywords          = {Knowledge graph; Machine learning; Modeling languages; Query processing; Tensors; Data tensor; Embeddings; Knowledge graphs; Language model; Large language model; Literals; Machine learning methods; Neurosymbolic AI; RDF; SPARQL},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020240980&doi=10.1007%2F978-3-031-99554-5_12&partnerID=40&md5=a4ac0ad15af55035a01edabdac1241b2},
}

@Article{Murtagh-White202699,
  author            = {Murtagh-White, Matt and Wall, Patrick J. and O'Sullivan, Declan},
  journal           = {Lecture Notes in Computer Science},
  title             = {How Low Can We Go? Quantization Effects on LLM SPARQL Generation},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {99 - 102},
  volume            = {15832 LNCS},
  abstract          = {SPARQL is a powerful but complex language for querying knowledge graphs, motivating research into natural language-to-SPARQL generation using large language models (LLMs). While large, proprietary LLMs excel at this task, their resource requirements can limit practical deployment. This paper evaluates smaller, open-source LLMs (0.5B–9B parameters) with quantization methods (8-bit and 4-bit compression) to balance computational efficiency and query generation performance. Our findings demonstrate that 8-bit quantization can maintain or enhance performance in smaller models, whereas 4-bit quantization leads to notable degradation, especially for larger models. This highlights the potential of quantized, smaller LLMs for SPARQL generation in resource-constrained scenarios and provides insights for optimizing specialized NLP tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Knowledge Graphs; Large Language Models; Quantization; Resource Efficiency; SPARQL},
  doi               = {10.1007/978-3-031-99554-5_18},
  keywords          = {Constrained optimization; Natural language processing systems; Quantization (signal); Query processing; Excel; Knowledge graphs; Language model; Large language model; Natural languages; Performance; Quantisation; Quantization effects; Resource efficiencies; SPARQL; Computational efficiency},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020237438&doi=10.1007%2F978-3-031-99554-5_18&partnerID=40&md5=e89f45a5abc4a7e9d0bc0be8a22c8612},
}

@Article{Doulaverakis202640,
  author            = {Doulaverakis, Charalampos and Vassiliou, Giannis and Batsakis, Sotiris and Papadakis, Nikos K. and Trouli, Georgia Eirini and Antoniou, Grigoris},
  journal           = {Lecture Notes in Computer Science},
  title             = {SPARQL Query Generation Using LLMs for Medical Information Retrieval},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {40 - 44},
  volume            = {15832 LNCS},
  abstract          = {Large Language Models (LLMs) have been the focus of Artificial Intelligence (AI) research recently but evaluation of their performance demonstrated their limitations in various tasks requiring reasoning capabilities. Responses of LLMs often contain erroneous answers and non existent facts, which is a major problem especially in critical tasks such as medical applications. In this work we propose a solution to this problem by making use of Linked Open Data as a source of reliable information. Specifically, we propose an approach that leverages Large Language Models (LLM) in order to allow for automatic SPARQL query generation from natural language by providing example entries of the dataset to the LLM so that it can analyze its structure. Preliminary results demonstrate the potential of our approach, and we provide an online demo so that users can experiment. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Knowledge graphs; LLM; Medical information retrieval; Natural language querying; SPARQL},
  doi               = {10.1007/978-3-031-99554-5_8},
  keywords          = {Artificial intelligence; Computational linguistics; Data handling; Information use; Knowledge management; Large datasets; Medical applications; Medical computing; Natural language processing systems; Open Data; Query languages; Query processing; Structured Query Language; Artificial intelligence research; Knowledge graphs; Language model; Large language model; Medical information; Medical information retrieval; Natural language querying; Natural languages; Query generation; SPARQL; Information retrieval},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020236933&doi=10.1007%2F978-3-031-99554-5_8&partnerID=40&md5=7bbf37a7853c2b04815dfa42631dad85},
}

@Article{2026,
  journal           = {Lecture Notes in Computer Science},
  title             = {25th International Conference on Web Engineering, ICWE 2025},
  year              = {2026},
  note              = {Cited by: 0},
  volume            = {15749 LNCS},
  abstract          = {The proceedings contain 39 papers. The special focus in this conference is on Web Engineering. The topics include: Leveraging LLMs for Conversational Data Access: A Human-Centred Perspective; A Graph-Based RAG for Energy Efficiency Question Answering; GoRS - A Neuro-Symbolic, User-Centric, and Goal-Oriented Recommendation System for DIY-Projects; autoS<sup>2</sup>earch: Unlocking the Reasoning Potential of Large Models for Web-Based Source Search; Enhancing the Aspect Robustness Score of the HAABSA++ Model Using Adversarial Training; applying Contrastive Learning to an Attention Neural Model in a Multilingual Context; OnToxKG: An Ontology-Based Knowledge Graph of Toxic Symbols and Their Manifestations; evaluating Locally Run Large Language Models on Toxic Meme Analysis; moralWeb: Reimagining the Web with Solid, Low-Code Tools, and Moral Codes for a Democratic and Equitable Future; a Web Crawling-Based Process and a Graph-Based Database for Mobile Vulnerability Analysis; multiWebFacts: A Modular Framework Using Multi-source Fusion for Fact-Checking; SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection; Web-SPARQL: Hybrid Querying over Knowledge Graphs, Web, and Microdata; ShEx2SPARQL: Translating Shape Expressions into SPARQL Queries; sciMantify - A Hybrid Approach for the Evolving Semantification of Scientific Knowledge; a Knowledge Graph Informing Soil Carbon Modeling; HORIZON: A Classification and Comparison Framework for Pricing-Driven Feature Toggling; From Mock-Ups to IFML-Like GUI Models: Using Large Language Models in Web Engineering; UIQLab: Automatic Web User Interface Assessment; Assessing the Migration from FaaS to IaaS: Cost, Performance, and Challenges in AWS; link Traversal over Decentralised Environments Using Restart-Based Query Planning; interoperable Cyber-Physical Multi-Agent Systems Through Web of Things; distributed Detection of Complex Events on Streams of Linked Data; LLM-MaGe: A Generative Mashup Planner for the Web of Things; the Efficiency of Rust and WebAssembly Compared to Plain JavaScript; KuBench: A Kubernetes-Based Environment for Standardized REST API Framework Performance Evaluation; Leveraging LLMs for Voice-Based form Filling on the Web: The ConWeb Approach; troubleshooting Microservices with Heterogeneous Graph Neural Network.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020045573&partnerID=40&md5=f8a5abd0528ec522d100ab8a8afdb7db},
}

@Article{Gashkov2026177,
  author            = {Gashkov, Aleksandr and Perevalov, Aleksandr and Eltsova, Maria and Both, Andreas},
  journal           = {Lecture Notes in Computer Science},
  title             = {SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {177 - 192},
  volume            = {15749 LNCS},
  abstract          = {Nowadays, the importance of software with natural-language user interfaces cannot be underestimated. In particular, in Question Answering (QA) systems, generating a SPARQL query for a given natural-language question (often named Query Building) from the information retrieved from the same question is the central task of QA systems working over Knowledge Graphs (KGQA). Due to the rise of Large Language Models (LLMs), they are considered a well-suited method to increase the quality of the question-answering functionality, as there is still a lot of room for improvement, aiming for enhanced quality and trustworthiness. However, LLMs are trained on web data, where researchers have no control over whether the benchmark or the knowledge graph was already included in the training data. In this paper, we introduce a novel method that evaluates the quality of LLMs by generating a SPARQL query from a natural-language question under various conditions: (1) zero-shot SPARQL generation, (2) with knowledge injection, and (3) with “anonymized” knowledge injection. This enables us, for the first time, to estimate the influence of the training data on the QA quality improved by LLMs. Ultimately, this will help to identify how portable a method is or whether good results might mostly be achieved because a benchmark was already included in the training data (cf. LLM memorization). The developed method is portable, robust, and supports any knowledge graph; therefore, it could be easily applied to any KGQA or LLM, s.t., generating consistent insights into the actual LLM capabilities is possible. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Knowledge Graph; Large Language Models; LLM memorization; Question Answering; SPARQL query generation},
  doi               = {10.1007/978-3-031-97207-2_14},
  keywords          = {Computational linguistics; Knowledge graph; Natural language processing systems; Query languages; Query processing; Question answering; Knowledge graphs; Language model; Large language model; Large language model memorization; Query generation; Question Answering; Question answering systems; SPARQL query generation; Training data; Search engines},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020007436&doi=10.1007%2F978-3-031-97207-2_14&partnerID=40&md5=5f00ac0dc558f52e7b0c7d5da5d39b27},
}

@Article{Li2026,
  author            = {Li, Mingchen and Wang, Zhe},
  journal           = {Building and Environment},
  title             = {BuildingGPT: Query building semantic data using large language models and vector-graph retrieval-augmented generation},
  year              = {2026},
  note              = {Cited by: 1},
  volume            = {287},
  abstract          = {Semantic web technologies offer a promising avenue for integrating heterogeneous building data across the entire Architecture, Engineering, Construction, and Operation (AECO) lifecycle. Yet querying such ontology-based data remains challenging, as it typically demands expertise in formal query languages like SPARQL Protocol and RDF Query Language (SPARQL). To address this, we present BuildingGPT, a novel framework that harnesses Large Language Models (LLMs) and a vector-graph retrieval-augmented generation (VG-RAG) pipeline. This approach empowers users to intuitively query building data grounded in semantic ontologies (e.g., the Brick Schema) using natural language. Evaluations on synthetic question types derived from 45 Brick Schema-based real building models—covering four complexities and six question types (18,555 samples)—demonstrate that VG-RAG outperforms baselines by 20–40 %, surpassing 90 % accuracy on four question types. By seamlessly integrating vector-based and graph-based retrieval to produce SPARQL queries, BuildingGPT simplifies data access for non-experts and enhances both reliability and responsiveness for complex, domain-specific inquiries. As a scalable, training-free solution compatible with diverse building ontologies, BuildingGPT significantly improves the accessibility and interoperability of semantic building data, ultimately fostering more informed decision-making and efficient asset management across the AECO industry. For a video demonstration, visit: https://www.youtube.com/watch?v=TtXVGVKuW8A © 2025 Elsevier Ltd},
  author_keywords   = {Brick schema; Knowledge graphs; Large language models; Ontology; Retrieval-Augmented generation; Semantic model},
  doi               = {10.1016/j.buildenv.2025.113855},
  keywords          = {Asset management; Brick; Buildings; Computational linguistics; Graphic methods; Information management; Information retrieval; Life cycle; Natural language processing systems; Query languages; Query processing; Semantic Web; Structured Query Language; Brick schema; Knowledge graphs; Language model; Large language model; Ontology's; Query building; Question type; Retrieval-augmented generation; Semantic modelling; Vector graphs; Ontology; accessibility; building; complexity; conceptual framework; data set; decision making; heterogeneity; language},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019101278&doi=10.1016%2Fj.buildenv.2025.113855&partnerID=40&md5=678ec47c8792afe2752b6fa21c16a107},
}

@Article{Chandra202698,
  author            = {Chandra, Ritesh and Agarwal, Sonali and Tiwari, Sadhana},
  journal           = {Lecture Notes in Computer Science},
  title             = {Ontology-Based Forest Fire Management Using Complex Event Processing and Large Language Models},
  year              = {2026},
  note              = {Cited by: 0},
  pages             = {98 - 112},
  volume            = {16046 LNCS},
  abstract          = {Forests sustain ecology, but wildfires are a significant threat. Fire weather indices help assess hazards but require constant real-time processing. To address this, we developed a Semantic Sensor Network (SSN) ontology model using data from Monesterial Natural Park, enhanced with Semantic Web Rules Language (SWRL). The system integrates Large Language Models (LLMs) and Complex Event Processing (CEP) engines for real-time fire detection. Sensor networks collect climate data (humidity, temperature, wind speed, etc.), which is processed via Spark Streaming and CEP to identify fire-related events. LLMs analyze detected events, while SPARQL queries retrieve relevant insights from the ontology. The results are combined to estimate the overall risk, allowing informed decision-making within a comprehensive Decision Support System (DSS) framework. It makes it easier to understand and deal with the risks of wildfires, as shown by tests that use ontology metrics, query-based testing, event alerts, and LLM performance (F1 score, precision, and recall). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {CEP; LLMs; Spark; SSN},
  doi               = {10.1007/978-3-032-02049-9_7},
  keywords          = {Deforestation; Fire hazards; Fires; Ontology; Risk assessment; Risk perception; Semantic Web; Sensor networks; Wind; Complex event processing; Complex events; Event Processing; Forest fire management; Language model; Large language model; Ontology-based; Semantic sensor network; Semantic sensors; Sensors network; Decision support systems},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017368541&doi=10.1007%2F978-3-032-02049-9_7&partnerID=40&md5=4e5aea6b063bc7b977e3d53129da1b2e},
}

@Article{Alekseev2026426,
  author            = {Alekseev, Artem and Chaichuk, Mikhail and Butko, Miron and Panchenko, Alexander I. and Tutubalina, Elena Viktorovna and Somov, Oleg D.},
  journal           = {Lecture Notes in Computer Science},
  title             = {The Benefits of Query-Based KGQA Systems for Complex and Temporal Questions in LLM Era},
  year              = {2026},
  note              = {Cited by: 0; All Open Access; Green Accepted Open Access; Green Open Access},
  pages             = {426 - 441},
  volume            = {15836 LNCS},
  abstract          = {Large language models excel in question-answering (QA) but struggle with multi-hop reasoning and temporal questions. Query-based knowledge graph QA (KGQA) offers a modular alternative by generating executable queries instead of direct answers. We explore multi-stage query-based framework for WikiData QA, proposing multi-stage approach that enhances performance on challenging multi-hop and temporal benchmarks. Through generalization and rejection studies, we evaluate robustness across multi-hop and temporal QA datasets. Additionally, we introduce a novel entity linking and predicate matching method using CoT reasoning. Our results demonstrate the potential of query-based multi-stage KGQA framework for improving multi-hop and temporal QA with small language models. Code: https://github.com/ar2max/NLDB-KGQA-System. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2026.},
  author_keywords   = {Generalization; KGQA; Rejection; SPARQL; WikiData},
  doi               = {10.1007/978-3-031-97141-9_29},
  keywords          = {Information management; Query languages; Query processing; Question answering; Search engines; Structured Query Language; Generalisation; Knowledge graph QA; Knowledge graphs; Multi-hops; Multi-temporal; Question Answering; Rejection; SPARQL; Temporal questions; Wikidata; Benchmarking},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010819182&doi=10.1007%2F978-3-031-97141-9_29&partnerID=40&md5=7c58d231a087a95ef5da1256ed58582e},
}

@Article{Haque20253147,
  author            = {Haque, Mohd Ariful and Kamal, Marufa and George, Roy and Gupta, Kishor Datta},
  journal           = {International Journal of Data Science and Analytics},
  title             = {Utilizing structural metrics from knowledge graphs to enhance the robustness quantification of large language models},
  year              = {2025},
  note              = {Cited by: 0},
  number            = {4},
  pages             = {3147 - 3167},
  volume            = {20},
  abstract          = {Knowledge graphs (KGs) play a critical role in organizing large stores of unstructured information into structured formats. This structured information is then accessible through SPARQL queries or graph libraries based on their structure. KGs enhance search, power AI systems, and facilitate knowledge discovery across domains. In this research, we explore the capabilities of different large language models (LLMs) like CodeLlama, Mistral, and Vicuna, which are recognized for text generation, in handling textual information tasks for constructing knowledge graphs with structured data. Utilizing these LLMs, we generate class descriptions for all the classes of well-known KGs like DBpedia, YAGO, and Google Knowledge Graph. Using these class descriptions, we have extracted RDF triples and used different preprocessing techniques for better refinement and extraction of the graph triples from the generated result. These extracted triples are used for the graph ontology creation. Highlighting the contribution of LLMs to structured graph formation, our study includes a comparison of the constructed KGs using the three LLMs with the existing Knowledge Graphs. Later, these KGs are evaluated using six structural quality metrics encompassing both class and property-related information crucial for KG formation. Our insights prove valuable for researchers exploring these domains, offering guidance on overcoming challenges and maximizing the potential of large language models in knowledge graph construction, text generation, and text extraction. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
  author_keywords   = {CodeLlama; Knowledge graph; LLM; Mistral; Structural metrics; Vicuna},
  doi               = {10.1007/s41060-024-00643-5},
  keywords          = {Domain Knowledge; Structured Query Language; Codellama; Knowledge graphs; Language model; Large language model; Mistral; Robustness quantifications; Structural metrics; Structured information; Text generations; Vicuna; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211953282&doi=10.1007%2Fs41060-024-00643-5&partnerID=40&md5=e9af36440f1cf8bc13db28e79bd28060},
}

@Article{Konstantinidis2025,
  author            = {Konstantinidis, Ioannis and Magnisalis, Ioannis and Peristeras, Vassilios},
  journal           = {Applied Sciences (Switzerland)},
  title             = {A Framework for a Public Service Recommender System Based on Neuro-Symbolic AI},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access},
  number            = {20},
  volume            = {15},
  abstract          = {Public service provision is still limited to document-centric procedures that require citizens to submit data and information needed for the execution of a service via documents. This, amongst others, is time-consuming, error-prone and hinders progress towards data-centricity. This study proposes a data-centric framework for a public service recommender system that combines knowledge graphs (KGs) and large language models (LLMs) in a neuro-symbolic AI architecture. The framework expresses public service preconditions as machine-readable rules based on data standards and provides dynamic recommendations for public services based on citizens’ profiles through automated reasoning. LLMs are utilized to extract preconditions from unstructured textual regulations and create RDF-based evidence models, while KGs provide validation of preconditions through SHACL rules and explainable reasoning towards semantic interoperability. A prototype use case on students applying for housing allowance showcases the feasibility of the proposed framework. The analysis indicates that combining KGs with LLMs for identifying relevant public services for different citizens’ profiles can improve the quality of public services and reduce administrative burdens. This work contributes and promotes the proactive “No-Stop Government” model, where services are recommended to users without explicit requests. The findings highlight the promising potential of employing neuro-symbolic AI to transform e-government processes, while also addressing challenges related to legal complexity, privacy and data fragmentation for large-scale adoption. © 2025 by the authors.},
  author_keywords   = {data-centric governance; knowledge graphs; large language models; neuro-symbolic AI; no-stop government; public service provision; recommender systems},
  doi               = {10.3390/app152011235},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  keywords          = {Artificial intelligence; Data privacy; e-government; Interoperability; Laws and legislation; Semantics; Citizen profile; Data centric; Data-centric governance; Knowledge graphs; Language model; Large language model; Neuro-symbolic AI; No-stop government; Public service provisions; Public services; Recommender systems},
  priority          = {prio1},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105020911060&doi=10.3390%2Fapp152011235&partnerID=40&md5=f4bdd4c183c3b9bf9f0468a5bc8d4651},
}

@Article{Yang2025,
  author            = {Yang, Zhijie and Weng, Liyuan and Zhang, Liang and Tong, Ruojia and Xie, Jianyu and Zeng, Zhuo and Chen, Duanbing},
  journal           = {PLOS ONE},
  title             = {KGMP: Augmenting retrieval knowledge graph with multi-hop perceptron},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access},
  number            = {10 October},
  volume            = {20},
  abstract          = {The core challenge of Knowledge Base Question Answering (KBQA), as a bridge between natural language and structured knowledge, is to accurately map complex semantic queries into Graph Query Language (GQL). Compared with the traditional Text-to-SQL task, KBQA faces a dual challenge: the structural differences between GQL and SQL and the lack of high-order subgraph information in multi-hop inference of knowledge graphs. While existing approaches such as ChatKBQA have made progress, the limitation of subgraph scalability severely constrains multi-hop query performance. To this end, this study proposes Knowledge Graph Multi-hop Perceptron (KGMP) - a retrieval-generation framework fine-tuned based on open-source large language models, whose innovativeness is reflected in three aspects: 1. Dynamic Graph Traversal Mechanism: Through an iterative subgraph expansion strategy, KGMP effectively achieves dynamic traversal of problem oriented graphs with progressive reasoning. 2. Structured Interaction Protocol: Based on SparQL syntax, KGMP designs a lightweight interaction instruction set to build an efficient communication interface between LLM and knowledge graph. 3. Graph Structure Optimization Technique: Develop subgraph reordering algorithms and pruning strategies based on the reranker model to ensure that the subgraphs input to the LLM are both compact and semantically complete. By integrating KGMP as a retrieval module into the ChatKBQA framework and providing it with optimised multi-hop subgraph input, the experimental results show a performance improvement of 6.2% and 5.3% on the WebQSP and CWQ datasets, respectively. This study provides a new technical paradigm for deep collaboration between LLM and knowledge graph. © 2025 Yang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  doi               = {10.1371/journal.pone.0333037},
  keywords          = {algorithm; article; complication; human; information retrieval; knowledge base; knowledge graph; large language model; open access publishing; perceptron; protocol; reasoning; artificial neural network; procedures; semantics; Algorithms; Humans; Information Storage and Retrieval; Knowledge Bases; Neural Networks, Computer; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017760712&doi=10.1371%2Fjournal.pone.0333037&partnerID=40&md5=ff8ee4a4813f7c4d198daff2f2e3570a},
}

@Article{Spyropoulos2025,
  author            = {Spyropoulos, Alexandros Z. and Tsiantos, Vasilios D.},
  journal           = {Computers},
  title             = {Interoperable Semantic Systems in Public Administration: AI-Driven Data Mining from Law-Enforcement Reports},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access},
  number            = {9},
  volume            = {14},
  abstract          = {The digitisation of law-enforcement archives is examined with the aim of moving from static analogue records to interoperable semantic information systems. A step-by-step framework for optimal digitisation is proposed, grounded in archival best practice and enriched with artificial-intelligence and semantic-web technologies. Emphasis is placed on semantic data representation, which renders information actionable, searchable, interlinked, and automatically processed. As a proof of concept, a large language model—OpenAI ChatGPT, version o3—was applied to a corpus of narrative police reports, extracting and classifying key entities (metadata, persons, addresses, vehicles, incidents, fingerprints, and inter-entity relationships). The output was converted to Resource Description Framework triples and ingested into a triplestore, demonstrating how unstructured text can be transformed into machine-readable, interoperable data with minimal human intervention. The approach’s challenges—technical complexity, data quality assurance, information-security requirements, and staff training—are analysed alongside the opportunities it affords, such as accelerated access to records, cross-agency interoperability, and advanced analytics for investigative and strategic decision-making. Combining systematic digitisation, AI-driven data extraction, and rigorous semantic modelling ultimately delivers a fully interoperable information environment for law-enforcement agencies, enhancing efficiency, transparency, and evidentiary integrity. © 2025 by the authors.},
  author_keywords   = {archive digitization; artificial intelligence; digital transformation; interoperability; knowledge representation; law-enforcement authorities; ontologies; semantic web; SPARQL queries},
  doi               = {10.3390/computers14090376},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  keywords          = {Advanced Analytics; Data mining; Decision making; Information use; Law enforcement; Metadata; Personnel training; Public administration; Quality assurance; Security of data; Semantic Web; Archive digitization; Digital transformation; Digitisation; Enforcement authorities; Knowledge-representation; Law-enforcement authority; Ontology's; Semantic systems; Semantic-Web; SPARQL query; Interoperability; Knowledge representation; Ontology},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017422163&doi=10.3390%2Fcomputers14090376&partnerID=40&md5=f28d98bcb53908e1117d3290e875a156},
}

@Article{Perevalov2025563,
  author            = {Perevalov, Aleksandr and Gashkov, Aleksandr and Eltsova, Maria and Both, Andreas},
  journal           = {Journal of Web Engineering},
  title             = {SPARQL Query Candidate Filtering for Improving the Quality of Multilingual Question Answering over Knowledge Graphs using Language Models},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access},
  number            = {4},
  pages             = {563 - 592},
  volume            = {24},
  abstract          = {Question answering is an approach to retrieving information from a knowledge base using natural language. Within question answering systems that work over knowledge graphs (KGQA), a ranked list of SPARQL query candidates is typically computed for the given natural-language input, where the top-ranked query should reflect the intention and semantics of the given user’s question. This article follows our long-term research agenda of providing trustworthy KGQA systems by presenting an approach for filtering incorrect queries. Here, we employ (large) language models (LMs/LLMs) to distinguish between correct and incorrect queries. The main difference to the previous work is that we address here multilingual questions represented in major languages (English, German, French, Spanish, and Russian), and confirm the generalizability of the approach by also evaluating it on some low-resource languages (Ukrainian, Armenian, Lithuanian, Belarusian, and Bashkir). The considered LMs (BERT, DistilBERT, Mistral, Zephyr, GPT-3.5, and GPT-4) were applied to the KGQA systems – QAnswer (real-world system) and MemQA (idealized system) – as SPARQL query filters. The approach was evaluated on the multilingual dataset QALD-9-plus, which is based on the Wikidata knowledge graph. The experimental results imply that the considered KGQA systems achieve quality improvements for all languages when using our query-filtering approach. © 2025 River Publishers.},
  author_keywords   = {query candidate filtering; query validation; Question answering over knowledge graphs; question answering quality; trustworthiness},
  doi               = {10.13052/jwe1540-9589.2444},
  file              = {:Perevalov2025563 - SPARQL Query Candidate Filtering for Improving the Quality of Multilingual Question Answering Over Knowledge Graphs Using Language Models.pdf:PDF:https\://journals.riverpublishers.com/index.php/JWE/article/download/27721/22171;:Perevalov2025563 - SPARQL Query Candidate Filtering for Improving the Quality of Multilingual Question Answering Over Knowledge Graphs Using Language Models.pdf:PDF:https\://journals.riverpublishers.com/index.php/JWE/article/download/27721/22171},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  publication_stage = {Final},
  ranking           = {rank4},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012939108&doi=10.13052%2Fjwe1540-9589.2444&partnerID=40&md5=d9a1b7b35d79f3936cabc77c92baaf79},
}

@Article{Adam2025,
  author            = {Adam, Daniel and Kliegr, Tomáš},
  journal           = {Information Processing and Management},
  title             = {Traceable LLM-based validation of statements in knowledge graphs},
  year              = {2025},
  note              = {Cited by: 1},
  number            = {4},
  volume            = {62},
  abstract          = {This article presents a method for verifying RDF triples using LLMs, with an emphasis on providing traceable arguments. Because the LLMs cannot currently reliably identify the origin of the information used to construct the response to the user prompt, our approach is to avoid using internal LLM factual knowledge altogether. Instead, verified RDF statements are compared to chunks of external documents retrieved through a web search or Wikipedia. To assess the possible application of this retrieval augmented generation (RAG) workflow on biosciences content, we evaluated 1,719 positive statements from the BioRED dataset and the same number of newly generated negative statements. The resulting precision is 88 %, and recall is 44 %. This indicates that the method requires human oversight. We also evaluated the method on the SNLI dataset which allowed us to compare our approach with models specifically tuned for the natural language inference task. We demonstrate the method on Wikidata, where a SPARQL query is used to automatically retrieve statements needing verification. Overall, the results suggest that LLMs could be used for large-scale verification of statements in KGs, a task previously unfeasible due to human annotation costs. © 2025 Elsevier Ltd},
  author_keywords   = {Error detection; KGs; LLMs; Quality control; Retrieval-augmented generation; Verification},
  doi               = {10.1016/j.ipm.2025.104128},
  file              = {:Adam2025 - Traceable LLM Based Validation of Statements in Knowledge Graphs.pdf:PDF:https\://arxiv.org/pdf/2409.07507v2;:Adam2025 - Traceable LLM Based Validation of Statements in Knowledge Graphs.pdf:PDF:https\://arxiv.org/pdf/2409.07507v2},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  keywords          = {Factual knowledge; KG; Knowledge graphs; LLM; RDF statements; RDF triples; Retrieval-augmented generation; Web searches; Wikipedia; Work-flows; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000816346&doi=10.1016%2Fj.ipm.2025.104128&partnerID=40&md5=60bfc60d0a904ddabba9ac43a2b172c3},
}

@Article{Ataeva20252723,
  author            = {Ataeva, Olga M. and Tuchkova, Natalia P.},
  journal           = {Lobachevskii Journal of Mathematics},
  title             = {Navigation with Large Language Models in Subject Domain of Ordinary Differential Equation},
  year              = {2025},
  note              = {Cited by: 0},
  number            = {6},
  pages             = {2723 - 2735},
  volume            = {46},
  abstract          = {Abstract: The work is devoted to the problem of adaptation of language models to a local mathematical subject area. On the example of ontology and knowledge graph for ordinary differential equations, queries in natural language are formed. The knowledge graph is created by means of intelligent data analysis in the semantic library of subject areas LibMeta. Adaptation is achieved by limiting a large language model when integrating with the knowledge graph of the subject area. The goal of the work is to create an environment for using a digital assistant in Russian when mastering scientific knowledge in a local subject area and scientific research. The limitations of the language model for the subject area of ordinary differential equations are realized by creating a set of templates and checking the truth of the answers based on them. Applications of the research results are expected to be implemented in systems of mathematical knowledge. © Pleiades Publishing, Ltd. 2025.},
  author_keywords   = {knowledge graph; knowledge graph question answering; LLMs; ODE; ontology design; prompt engineering; RDF; semantic relationships; SPARQL; subject ontology},
  doi               = {10.1134/S1995080225608227},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019221414&doi=10.1134%2FS1995080225608227&partnerID=40&md5=c8aca7e4aa6cf2e011f0f525ca315c63},
}

@Article{Hernandez-Camero2025,
  author            = {Hernandez-Camero, Ines Virginia and García-López, Eva and Garcia-Cabot, Antonio and Caro-Alvaro, Sergio},
  journal           = {Machine Learning and Knowledge Extraction},
  title             = {Context-Aware Few-Shot Learning SPARQL Query Generation from Natural Language on an Aviation Knowledge Graph},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access},
  number            = {2},
  volume            = {7},
  abstract          = {Question answering over domain-specific knowledge graphs implies several challenges. It requires sufficient knowledge of the world and the domain to understand what is being asked, familiarity with the knowledge graph’s structure to build a correct query, and knowledge of the query language. However, mastering all of these is a time-consuming task. This work proposes a prompt-based approach that enables natural language to generate SPARQL queries. By leveraging the advanced language capabilities of large language models (LLMs), we constructed prompts that include a natural-language question, relevant contextual information from the domain-specific knowledge graph, and several examples of how the task should be executed. To evaluate our method, we applied it to an aviation knowledge graph containing accident report data. Our approach improved the results of the original work—in which the aviation knowledge graph was first introduced—by 6%, demonstrating its potential for enhancing SPARQL query generation for domain-specific knowledge graphs. © 2025 by the authors.},
  author_keywords   = {knowledge graphs; large language models; prompting; query generation; SPARQL},
  doi               = {10.3390/make7020052},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009274532&doi=10.3390%2Fmake7020052&partnerID=40&md5=ffd907b25c2673db1f81c51dad2b8adc},
}

@Article{Avila2025223,
  author            = {Avila, Caio Viktor S. and Vidal, Vânia Maria Ponte and Franco, Wellington and Casanova, Marco Antonio},
  journal           = {International Journal of Semantic Computing},
  title             = {An Autonomous Domain-Independent Framework Based on LLMs for Text-to-SPARQL},
  year              = {2025},
  note              = {Cited by: 0},
  number            = {02},
  pages             = {223 - 246},
  volume            = {19},
  abstract          = {Large language models (LLMs) currently are the state of the art for pre-trained language models. LLMs have been applied to many tasks, including question and answering over Knowledge Graphs (KGs) and text-to-SPARQL, that is, the translation of Natural Language questions to SPARQL queries. With such motivation, this paper first describes preliminary experiments to evaluate the ability of ChatGPT to answer Natural Language questions over KGs. Based on these experiments, the paper introduces Auto-KGQA, an autonomous domain-independent framework based on LLMs for text-to-SPARQL. The framework selects fragments of the KG, which the LLM uses to translate the user’s Natural Language question to a SPARQL query on the KG. The paper describes preliminary experiments with Auto-KGQA with ChatGPT that indicate that the framework substantially reduced the number of tokens passed to ChatGPT without sacrificing performance. Finally, the paper includes an evaluation of Auto-KGQA in a publicly available benchmark, which showed that the framework is competitive, achieving an improvement of 13.2% in accuracy with respect to the state of the art and a reduction of 51.12% in the number of tokens passed to the LLM. © 2025 World Scientific Publishing Company.},
  author_keywords   = {ChatGPT; knowledge graphs; Large Language Models; Question answering},
  doi               = {10.1142/S1793351X25420048},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Query languages; Autonomous domains; ChatGPT; Domain independents; Graph-based; Knowledge graphs; Language model; Large language model; Natural language questions; Question Answering; State of the art; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003837025&doi=10.1142%2FS1793351X25420048&partnerID=40&md5=1f6eac9454a8731dc58905c3e6a79a05},
}

@Conference{Antoniou2025287,
  author            = {Antoniou, Christina and Bassiliades, Nick},
  title             = {Utilizing LLMs and ontologies to query educational knowledge graphs},
  year              = {2025},
  note              = {Cited by: 1; All Open Access; Gold Open Access},
  pages             = {287 - 295},
  abstract          = {Knowledge Graphs (KGs) provide knowledge and data in a structured format with content from various fields. But the access to the knowledge graphs is done by experienced users, that is, users who know the syntax of the SPARQL language and the KG vocabulary (either in RDF Schema or in OWL) in order to be able to ask questions to exploit the knowledge graphs. However, this requires a lot of time and effort for most of the users, which makes KGs inaccessible to a large number of users. Large Language Models (LLMs) that have appeared recently can provide an alternative way to query knowledge graphs without the need to learn SPARQL and/or know the schema and vocabulary of them, eliminating the time and effort that ordinary users need to spend in order to use them. In this article, we present some experiments and their results illustrating how ChatGPT can help ordinary users to generate SPARQL queries, without knowing SPARQL, to effectively use knowledge graphs and exploit their wealth of data. We experimented with ChatGPT to explore whether it can generate SPARQL queries based on user's natural language input and a given vocabulary (ontology) about an educational knowledge graph. To this end we have devised a specific prompt template. Results indicate that LLMs can indeed help in this direction, given the fact that they are prompted properly, using good English language. We have also discussed some practical lessons learned through this experiment. © 2024 Copyright held by the owner/author(s).},
  author_keywords   = {AI application; ChatGPT; knowledge graphs; large language model use cases; RDF},
  doi               = {10.1145/3716554.3716598},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  keywords          = {Computational linguistics; Knowledge graph; Natural language processing systems; Query languages; Query processing; Structured Query Language; AI applications; ChatGPT; Educational knowledge; Knowledge graphs; Language model; Large language model use case; Model use; Ontology's; RDF; RDF schemas; Graphic methods},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010772666&doi=10.1145%2F3716554.3716598&partnerID=40&md5=8b67385f81e02dcf1b4c2fc5a7ff002d},
}

@Article{Sequeda2025,
  author            = {Sequeda, Juan Federico and Allemang, Dean and Jacob, Bryon},
  journal           = {Journal of Web Semantics},
  title             = {Knowledge Graphs as a source of trust for LLM-powered enterprise question answering},
  year              = {2025},
  note              = {Cited by: 4; All Open Access; Gold Open Access},
  volume            = {85},
  abstract          = {Generative AI provides an innovative and exciting way to manage knowledge and data at any scale; for small projects, at the enterprise level, and even at a world wide web scale. It is tempting to think that Generative AI has made other knowledge-based technologies obsolete; that anything we wanted to do with knowledge-based systems, Knowledge Graphs or even expert systems can instead be done with Generative AI. Our position is counter to that conclusion. Our practical experience on implementing enterprise question answering systems using Generative AI has shown that Knowledge Graphs support this infrastructure in multiple ways: they provide a formal framework to evaluate the validity of a query generated by an LLM, serve as a foundation for explaining results, and offer access to governed and trusted data. In this position paper, we share our experience, present industry needs, and outline the opportunities for future research contributions. © 2025 The Authors},
  author_keywords   = {Generative AI; Knowledge engineering; Knowledge Graph; Large Language Model; LLM; OWL; Question answering; R2RML; SPARQL; SQL},
  doi               = {10.1016/j.websem.2024.100858},
  keywords          = {Expert systems; Generative adversarial networks; Question answering; Structured Query Language; Generative AI; Knowledge graphs; Knowledge-based technology; Language model; Large language model; LLM; OWL; Question Answering; R2RML; SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216449491&doi=10.1016%2Fj.websem.2024.100858&partnerID=40&md5=c9883b2a91e5b1ae03215ea33b114b5d},
}

@Article{Mountantonakis2025,
  author            = {Mountantonakis, Michalis and Tzitzikas, Yannis},
  journal           = {Journal on Computing and Cultural Heritage},
  title             = {Generating SPARQL Queries over CIDOC-CRM Using a Two-Stage Ontology Path Patterns Method in LLM Prompts},
  year              = {2025},
  note              = {Cited by: 5; All Open Access; Hybrid Gold Open Access},
  number            = {1},
  volume            = {18},
  abstract          = {In this article, we focus on the task of exploiting the capabilities of Large Language Models (LLMs) to generate SPARQL Queries for answering natural questions over cultural Knowledge Graphs (KGs) expressed according to the ISO standard ontology CIDOC-CRM. Since CIDOC-CRM is an event-based model, usually we have to follow long paths for answering a question, thereby, the challenge is how to construct the prompt for aiding the LLM to produce the right SPARQL query. We propose and comparatively evaluate methods based on the creation of ontology path patterns of a configurable path radius (or length). Then, we construct a new dedicated benchmark that includes 100 natural questions and the corresponding SPARQL queries over two real KGs from the cultural domain describing artworks. Finally, we present comparative results about the effectiveness and efficiency over the benchmark by using ChatGPT-3.5. The most effective method follows a two-stage process that predicts and uses the most appropriate path patterns of r ≤ 4. This method achieves 3.5 higher accuracy than the baseline method (0.66 versus 0.19), that includes in the prompt only the list of properties and classes of the KG. © 2025 Copyright held by the owner/author(s).},
  author_keywords   = {CIDOC-CRM; Cultural Heritage; LLM; Prompt Engineering; Question Answering},
  doi               = {10.1145/3708326},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  keywords          = {Benchmarking; Knowledge graph; Natural language processing systems; Ontology; Query languages; Query processing; Structured Query Language; CIDOC CRM; Cultural heritages; Cultural knowledge; ISO standards; Knowledge graphs; Language model; Large language model; Ontology's; Prompt engineering; Question Answering; ISO Standards},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002771319&doi=10.1145%2F3708326&partnerID=40&md5=9099b12317a52f5a5d39a71decdd61c1},
}

@Article{Brei202554,
  author            = {Brei, Felix and Meyer, Lars Peter and Martin, Michael},
  journal           = {IT - Information Technology},
  title             = {Queryfy: From knowledge graphs to questions using open Large Language Models Enabling finetuning by question generation on given knowledge},
  year              = {2025},
  note              = {Cited by: 1; All Open Access; Hybrid Gold Open Access},
  number            = {1},
  pages             = {54 - 61},
  volume            = {67},
  abstract          = {When we look at the global knowledge graph landscape, we quickly find that there are billions of interconnected facts that have the potential to answer all kinds of questions. However, a persistent challenge lies in finding corresponding questions that align with these facts. The availability of these questions along with matching SPARQL queries is an important prerequisite for fine-tuning Large Language Models for domain-specific query generation, which is why we propose Queryfy, a novel framework that leverages Large Language Models to automate the task of deriving questions and queries from knowledge graphs, empowering users to harness their full potential. © 2025 the author(s), published by De Gruyter, Berlin/Boston.},
  author_keywords   = {dataset generation; KGQA; Large Language Models; semantic web; SPARQL},
  doi               = {10.1515/itit-2024-0079},
  keywords          = {Query languages; Question answering; Semantics; Structured Query Language; Dataset generation; Fine tuning; Global knowledge; KGQA; Knowledge graphs; Language model; Large language model; Matchings; Semantic-Web; SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000167681&doi=10.1515%2Fitit-2024-0079&partnerID=40&md5=4791c74b3b71d65a7c159ab859005471},
}

@Article{Nuzhat2025242,
  author            = {Nuzhat, Faiza and Shivashankar, Kanchan and Steinmetz, Nadine},
  journal           = {Lecture Notes in Computer Science},
  title             = {Enhancing Question Answering Systems with Generative AI: A Study of LLM Performance and Error Analysis},
  year              = {2025},
  note              = {Cited by: 1},
  pages             = {242 - 258},
  volume            = {15459 LNCS},
  abstract          = {Generative AI powered by Large Language Model (LLM) can produce creative content including programming languages but is constrained by the training data. On the other hand, Question Answering Systems (QASs) are not limited by data biases or quality, but cannot detect human errors or ambiguities. Hence, integrating Generative AI in QASs can transform the functionality and user experience for better. Our work presents a comprehensive evaluation of the performance of four prominent Large Language Models (LLMs)–ChatGPT, Claude, Gemini and Llama3 - on the task of converting Natural Language Questions (NLQs) to SPARQL queries. We created a novel sample dataset by merging LC-QuAD 2.0 and QALD 10 datasets to ensure a diverse representation of question types, knowledge domains, and complexity levels. We evaluated the performance of each LLM and conducted an in-depth error analysis to understand capabilities and identify weaknesses for NLQ-to-SPARQL conversion, which can guide future research and development in this exciting field. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {ChatGPT; Claude; Gemini; Generative artificial intelligence (AI); Hallucination; Knowledge Graphs; Large Language Models; LC-QuAD; Llama3; QALD; Question Answering; Semantic Web; SPARQL; Wikidata},
  doi               = {10.1007/978-3-031-81221-7_17},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Generative adversarial networks; Modeling languages; Semantics; ChatGPT; Claude; Geminus; Generative artificial intelligence; Hallucination; Knowledge graphs; Language model; Large language model; LC-QuAD; Llama3; QALD; Question Answering; Semantic-Web; SPARQL; Wikidata; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218972344&doi=10.1007%2F978-3-031-81221-7_17&partnerID=40&md5=cbb6f07fd4e1d5a9a05afb9c1bd4712d},
}

@Article{Frey202551,
  author            = {Frey, Johannes and Meyer, Lars Peter and Brei, Felix and Grunder-Fahrer, Sabine and Martin, Michael},
  journal           = {Lecture Notes in Computer Science},
  title             = {Assessing the Evolution of LLM Capabilities for Knowledge Graph Engineering in 2023},
  year              = {2025},
  note              = {Cited by: 6},
  pages             = {51 - 60},
  volume            = {15344 LNCS},
  abstract          = {In this article, we evaluate the evolution of LLM capabilities w.r.t. the RDF Turtle and SPARQL language as foundational skills to assist with various KGE tasks. We measure the LLM response quality using 6 LLM-KG-Bench tasks for a total of 15 LLM versions available over the course of 2023, covering 5 different “major version” LLM classes (GPT-3.5 Turbo, GPT-4, Claude 1.x, Claude 2.x, and Claude Instant 1.x). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {evolution of llms; knowledge graph engineering; large language models; LLM benchmarking; RDF},
  doi               = {10.1007/978-3-031-78952-6_5},
  keywords          = {Benchmarking; Evolution of llms; Knowledge graph engineering; Knowledge graphs; Language model; Large language model; LLM benchmarking; RDF; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218464294&doi=10.1007%2F978-3-031-78952-6_5&partnerID=40&md5=a0e1bbc3327eb215e0f46a4389ee6341},
}

@Article{Tufek202592,
  author            = {Tufek, Nilay and Thuluva, Aparna Saisree and Just, Valentin Philipp and Ekaputra, Fajar J. and Bandyopadhyay, Tathagata and Sabou, Marta and Hanbury, Allan},
  journal           = {Lecture Notes in Computer Science},
  title             = {Validating Semantic Artifacts with Large Language Models},
  year              = {2025},
  note              = {Cited by: 4},
  pages             = {92 - 101},
  volume            = {15344 LNCS},
  abstract          = {As part of knowledge engineering workflows, semantic artifacts, such as ontologies, knowledge graphs or semantic descriptions based on industrial standards, are often validated in terms of their compliance with requirements expressed in natural language (e.g., ontology competency questions, standard specifications). Key to this process is the translation of the requirements in machine-actionable queries (e.g., SPARQL) that can automate the validation process. This manual translation process is time-consuming, error-prone and challenging, especially in areas where domain experts might lack knowledge of semantic technologies. In this paper, we propose a Large Language Models (LLMs) based approach to translate requirements texts into SPARQL queries and test it in validation use cases related to SAREF and OPC UA Robotics. F1 scores of 88–100% indicate the feasibility of the approach and its potential impact on ensuring high quality semantic artifacts and further uptake of the semantic technologies (industrial) domains. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {LLM; OPC UA; Semantic Artifacts; Validation},
  doi               = {10.1007/978-3-031-78952-6_9},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Knowledge graph; Latent semantic analysis; Machine translation; Modeling languages; Query languages; Requirements engineering; Semantics; Engineering workflows; Knowledge graphs; Language model; Large language model; Ontology's; OPC UA; Semantic artifact; Semantic descriptions; Semantic technologies; Validation; Ontology},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218443416&doi=10.1007%2F978-3-031-78952-6_9&partnerID=40&md5=787f0b08362a57f58754faf9bf31875b},
}

@Article{Avila2025168,
  author            = {Avila, Caio Viktor S. and Casanova, Marco Antonio and Vidal, Vânia Maria Ponte},
  journal           = {Lecture Notes in Computer Science},
  title             = {A Framework for Question Answering on Knowledge Graphs Using Large Language Models},
  year              = {2025},
  note              = {Cited by: 2},
  pages             = {168 - 172},
  volume            = {15344 LNCS},
  abstract          = {Currently, large language models (LLMs) are the state of the art for pre-trained language models. LLMs have been applied to many tasks, including question and answering over Knowledge Graphs (KGs) and text-to-SPARQL, that is, the translation of Natural Language (NL) questions to SPARQL queries. This paper introduces Auto-KGQA, an autonomous domain-independent framework based on LLMs for text-to-SPARQL. The framework uses as context, fragments of the KG, which the LLM uses to translate the user’s NL question to a SPARQL query on the KG. Finally, it generates a natural language response for the user, based upon the result of the execution of SPARQL query over the KG. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {Knowledge Graph; Large Language Model; Question Answering},
  doi               = {10.1007/978-3-031-78952-6_20},
  keywords          = {Structured Query Language; Autonomous domains; Domain independents; Knowledge graphs; Language model; Large language model; Model use; Natural language questions; Natural languages; Question Answering; State of the art; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218442989&doi=10.1007%2F978-3-031-78952-6_20&partnerID=40&md5=c84a55069e7c53884d96663cb2d52ba6},
}

@Conference{Mecharnia202569,
  author            = {Mecharnia, Thamer and d'Aquin, Mathieu},
  title             = {Performance and Limitations of Fine-Tuned LLMs in SPARQL Query Generation},
  year              = {2025},
  note              = {Cited by: 5},
  pages             = {69 - 77},
  volume            = {2025-January},
  abstract          = {Generative AI has simplified information access by enabling natural language-driven interactions between users and automated systems. In particular, Question Answering (QA) has emerged as a key application of AI, facilitating efficient access to complex information through dialogue systems and virtual assistants. The Large Language Models (LLMs) combined with Knowledge Graphs (KGs) have further enhanced QA systems, allowing them to not only correctly interpret natural language but also retrieve precise answers from structured data sources such as Wikidata and DBpedia. However, enabling LLMs to generate machine-readable SPARQL queries from natural language questions (NLQs) remains challenging, particularly for complex questions. In this study, we present experiments in fine-tuning LLMs for the task of NLQ-to-SPARQL transformation. We rely on benchmark datasets for training and testing the fine-tuned models, generating queries directly from questions written in English (without further processing of the input or output). By conducting an analytical study, we examine the effectiveness of each model, as well as the limitations associated with using fine-tuned LLMs to generate SPARQL. ©2025 International Committee on Computational Linguistics (ICCL)},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  journal           = {Proceedings - International Conference on Computational Linguistics, COLING},
  keywords          = {Benchmarking; Computational linguistics; Natural language processing systems; Query languages; Translation (languages); Applications of AI; Automated systems; Complex information; Information access; Language model; Natural language questions; Natural languages; Performance; Query generation; Question Answering; Structured Query Language},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217674325&partnerID=40&md5=5f9386261de14244dddf7fcba3fbca67},
}

@Conference{2025,
  title             = {Workshop on Generative AI and Knowledge Graphs, GenAIK 2025 - Proceedings of the Workshop},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {2025-January},
  abstract          = {The proceedings contain 15 papers. The topics discussed include: effective modeling of generative framework for document-level relational triple extraction; learn together: joint multitask finetuning of pretrained KG-enhanced LLM for downstream tasks; on reducing factual hallucinations in graph-to-text generation using large language models; GraphRAG: leveraging graph-based efficiency to minimize hallucinations in LLM-driven RAG for finance data; structured knowledge meets GenAI: a framework for logic-driven language models; performance and limitations of fine-tuned LLMs in SPARQL query generation; refining noisy knowledge graph with large language models; and style knowledge graph: augmenting text style transfer with knowledge graphs.},
  groups            = {Records Excluded},
  journal           = {Proceedings - International Conference on Computational Linguistics, COLING},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217667532&partnerID=40&md5=37ba42220fa19d6f67561cd2dd5e4328},
}

@Article{Allemang2025324,
  author            = {Allemang, Dean and Sequeda, Juan Federico},
  journal           = {Lecture Notes in Computer Science},
  title             = {Increasing the Accuracy of LLM Question-Answering Systems with Ontologies},
  year              = {2025},
  note              = {Cited by: 3},
  pages             = {324 - 339},
  volume            = {15233 LNCS},
  abstract          = {There is increasing evidence that question-answering (QA) systems with Large Language Models (LLMs), which employ a knowledge graph representation of an enterprise SQL database (Text-to-SPARQL), achieve higher accuracy compared to systems that answer questions directly on SQL databases (Text-to-SQL). The objective of this research is to further improve the accuracy of these LLM Question Answering systems. Our approach, Ontology-based Query Check (OBQC), is to check the LLM generated SPARQL query against the semantics specified by the ontology. A query will be flagged as incorrect and prevented from execution if it does not align with the ontological semantics. The study also explores the LLM’s capability in repairing a SPARQL query given an explanation of the error (LLM Repair). Our methods are evaluated using the chat with the data benchmark. The primary finding is our method further increases the accuracy overall by 21.59% thus pushing the overall accuracy level to 65.63%. These results provide further evidence that investing knowledge graphs, namely the ontology, provides higher accuracy for LLM powered question answering systems. Our method is a component of the data.world AI Context Engine which is being widely used by customers in Generative AI production use cases that enable business users to chat with SQL databases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  doi               = {10.1007/978-3-031-77847-6_18},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Database systems; Knowledge graph; Ontology; Semantics; Structured Query Language; Graph representation; High-accuracy; Knowledge graphs; Language model; Model questions; Model repair; Ontology's; Ontology-based query; Question answering systems; SQL database},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211242388&doi=10.1007%2F978-3-031-77847-6_18&partnerID=40&md5=011d5b3e2c19429c9fc323157efa90ac},
}

@Article{Vollmers2025174,
  author            = {Vollmers, Daniel and Srivastava, Nikit and Zahera, Hamada M. and Moussallem, Diego and Ngonga-Ngomo, Axel Cyrille},
  journal           = {Lecture Notes in Computer Science},
  title             = {UniQ-Gen: Unified Query Generation Across Multiple Knowledge Graphs},
  year              = {2025},
  note              = {Cited by: 2},
  pages             = {174 - 189},
  volume            = {15370 LNAI},
  abstract          = {Generating SPARQL queries is crucial for extracting relevant information from diverse knowledge graphs. However, the structural and semantic differences among these graphs necessitate training or fine-tuning a tailored model for each one. In this paper, we propose UniQ-Gen, a unified query generation approach to generate SPARQL queries across various knowledge graphs. UniQ-Gen integrates entity recognition, disambiguation, and linking through a BERT-NER model and employs cross-encoder ranking to align questions with the Freebase ontology. We conducted several experiments on different benchmark datasets such as LC-QuAD 2.0, GrailQA, and QALD-10. The evaluation results demonstrate that our approach achieves performance equivalent to or better than models fine-tuned for individual knowledge graphs. This finding suggests that fine-tuning a unified model on a heterogeneous dataset of SPARQL queries across different knowledge graphs eliminates the need for separate models for each graph, thereby reducing resource requirements. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {KGQA; Large Language Models; Question Answering over Knowledge Graphs; SPARQL Generation},
  doi               = {10.1007/978-3-031-77792-9_11},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Query languages; Question answering; Semantics; Structured Query Language; Fine tuning; KGQA; Knowledge graphs; Language model; Large language model; Query generation; Question Answering; Question answering over knowledge graph; SPARQL generation; Structural differences; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210886308&doi=10.1007%2F978-3-031-77792-9_11&partnerID=40&md5=95ad88964325e8ec5cd899466dc35219},
}

@Conference{Pan2025123,
  author            = {Pan, Xueli and de Boer, Victor and Van Ossenbruggen, Jacco},
  title             = {FIRESPARQL: A LLM-Based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {123 - 134},
  volume            = {1},
  abstract          = {Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and execution result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set. © © 2025 by SCITEPRESS – Science and Technology Publications, Lda.},
  author_keywords   = {Finetuning LLM; Scholarly Knowledge Graph; SPARQL Query Generation},
  doi               = {10.5220/0013774000004000},
  journal           = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
  keywords          = {Benchmarking; Distributed computer systems; Graphic methods; Information systems; Information use; Knowledge management; Natural language processing systems; Query languages; Query processing; Structured Query Language; Systems analysis; Fine tuning; Finetuning large language model; Knowledge graphs; Language model; Model-based OPC; Natural language questions; Performance; Query generation; Scholarly knowledge graph; SPARQL query generation; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022502571&doi=10.5220%2F0013774000004000&partnerID=40&md5=72cc2f0409d0e051e0dfed4806bd65d3},
}

@Conference{Hanuragav2025,
  author            = {Hanuragav, Muthiah Giri and Gopinath, Viswanathan},
  title             = {Graph-Driven Validation of CSR (TFLs) Using Semantic Technologies},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4085},
  abstract          = {Regulators require that every number printed in a clinical-study report (CSR) be internally consistent across its TFLs and traceable to underlying observations. Scripted Quality Assurance around rich-text outputs (RTF) is brittle under schema drift and provides weak provenance. We present an ontology-centered workflow that converts RTF to JSON, maps JSON to RDF using compact YAML mappers read by a deterministic translator, enforces structure with SHACL, and applies SPARQL rule suites for content checks. Large-language models (LLMs) assist only in drafting YAML; the converter is deterministic and auditable. A pilot across three studies reduced manual TFL QC by up to 75% while surfacing discrepancies earlier. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Clinical Study Report; ETL; Knowledge Graphs; SHACL; SPARQL; TFL; YAML},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Clinical research; Knowledge graph; Ontology; Semantic Web; Semantics; Verification; Clinical study; Clinical study report; Deterministics; ETL; Knowledge graphs; Semantic technologies; SHACL; SPARQL; TFL; YAML; Quality assurance},
  priority          = {prio1},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022496705&partnerID=40&md5=4ac8705e0300af5b63d9ec5ad9b6d0db},
}

@Conference{Taghzouti2025,
  author            = {Taghzouti, Yousouf and Michel, Franck and Jiang, Tao and Nothias, Louis Félix and Gandon, Fabien L.},
  title             = {Building Questions and Queries Datasets for Knowledge Graphs: a Demo of Q2Forge},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4085},
  abstract          = {In this paper, we present a demo of how Q<sup>2</sup>Forge addresses the challenge of generating competency questions and corresponding SPARQL queries for any target Knowledge Graph. It iteratively validates those queries with human feedback and LLM as a judge. Q<sup>2</sup>Forge is open source, generic, extensible and modular. The demo shows the complete pipeline from competency question formulation to query evaluation, supporting the creation of reference question-query sets. © 2025 Copyright for this paper by its authors.},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Information management; Open systems; Query processing; Question answering; Structured Query Language; Undirected graphs; Knowledge graphs; Modulars; Open-source; Query evaluation; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022468926&partnerID=40&md5=8475ad56f41df80079d20ba667b05183},
}

@Conference{Hu2025,
  author            = {Hu, Yujia and Nguyen, Tuan Phong and Ghosh, Shrestha and Müller, Moritz and Razniewski, Simon},
  title             = {Introducing GPTKB to the Semantic Web},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4085},
  abstract          = {Knowledge bases (KBs) are a cornerstone of the Semantic Web, yet they still struggle with scale and scope, and their construction and curation still involve a lot of manual effort. Large language models (LLMs) have recently emerged as powerful tools for a range of tasks, yet their potential for automated KB construction is still poorly understood. In this demonstrator, we showcase GPTKB, a methodology and KB entirely built from GPT-4.1. GPTKB is constructed by massive-recursive LLM knowledge materialization [1], using over 9M API calls for $14,000 to construct a 100M-triple knowledge base with over 6M entities. Our demonstration focuses on two use cases: (i) Link-based KG exploration and (ii) SPARQL-based analysis and comparison to Wikidata. The GPTKB demonstrator is accessible at https://gptkb.org. © 2025 Copyright for this paper by its authors.},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Knowledge based systems; API calls; Curation; Knowledge-base construction; Language model; Link-based; Model knowledge; Scale and scope; Semantic-Web; Semantic Web},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105022424846&partnerID=40&md5=2214807f990b81b056733e0995d8f202},
}

@Conference{Ahmed2025107,
  author            = {Ahmed, Umair and Polini, Andrea and Ferranti, Nicolas},
  title             = {From Speech to Semantics: Enabling Conversational Access to Scholarly Knowledge Graph},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {107 - 119},
  volume            = {4079},
  abstract          = {Recent advancements in the representation of knowledge via knowledge graphs have paved an intuitive way to build scholarly knowledge for users and for artificial agents. Despite the expressiveness of knowledge graphs, accessing these knowledge graphs requires proficiency in a query language such as SPARQL, presenting a barrier for a multitude of users. In this study, we present a hybrid, end-to-end framework that (i) interprets user questions expressed in natural language, (ii) classifies each query into one of four target categories (conferences, authors, organizations, or papers) using a fine-tuned RoBERTa-Large model, (iii) synthesizes candidate SPARQL queries via a large language model (GPT-4o-mini) augmented with few-shot examples, and (iv) refines the raw query results by reranking either the SPARQL output or, when necessary, fallback candidate items retrieved through vector-space embeddings (indexed with FAISS). On a testbed of 92 manually crafted “gold-standard” SPARQL queries, our automated pipeline achieved over 96% overlap with expert results (≥ 70% overlap in 89/92 cases), with perfect consistency on conference, author, and organization queries and 90% coverage on paper queries given the semantic nature of queries. Moreover, our query-type classifier achieved 99% accuracy, demonstrating the reliability of schema selection. These results indicate that combining LLM-driven query synthesis with embeddings-based reranking delivers a robust, user-centric interface to scholarly knowledge graphs, enabling complex information retrieval without SPARQL expertise. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Automated Query Generation; GPT; Knowledge Graphs; Large LanguageL Models; Natural Language Queries; Semantic Search; SPARQL},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Computer hardware description languages; Embeddings; Graphic methods; Information retrieval; Intelligent agents; Knowledge graph; Knowledge transfer; Natural language processing systems; Query languages; Query processing; Semantic Web; Semantics; Structured Query Language; Artificial agents; Automated query generation; GPT; Knowledge graphs; Large languagel model; Natural language queries; Query generation; Re-ranking; Semantic search; SPARQL; Vector spaces},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021834918&partnerID=40&md5=ae164153be53bfcd9ff20ca510a2387a},
}

@Conference{Taghzouti2025153,
  author            = {Taghzouti, Yousouf and Michel, Franck and Jiang, Tao and Nothias, Louis Félix and Gandon, Fabien L.},
  title             = {User Interface and Agent Interface for Online Generation of Knowledge Graph's Competency Questions and Question-Query Training Sets},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {153 - 159},
  volume            = {4079},
  abstract          = {Few question-query datasets exist for fine-tuning large language models on tasks such as translating natural language questions into SPARQL queries. While it is often recommended that competency questions and their corresponding SPARQL queries accompany a knowledge graph (KG), this is rarely the case in practice. In this paper, we introduce Q<sup>2</sup>Forge, a web application designed to support the creation of question-query pairs for any KG. The tool enables users to generate, test, and refine competency questions and their SPARQL counterparts directly within the interface. It employs a retrieval-augmented generation architecture to support a wide range of KGs efficiently. The result is an open-source solution for building reusable question-query datasets applicable to any KG. We also present recent developments around the Model Context Protocol, moving toward the agentification of Q<sup>2</sup>Forge-enabling natural language interactions in addition to traditional UI-based workflows. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Competency Question; LLM; MCP; SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computer software reusability; Knowledge graph; Natural language processing systems; Open systems; Query languages; Query processing; Structured Query Language; Competency question; Fine tuning; Knowledge graphs; Language model; LLM; MCP; Natural language questions; On-line generation; SPARQL; Training sets; User interfaces},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021821647&partnerID=40&md5=5a0f2181842776357e063b9147d5a2d3},
}

@Conference{Vossebeld202519,
  author            = {Vossebeld, Floris and Wang, Shenghui},
  title             = {Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {19 - 32},
  volume            = {4079},
  abstract          = {Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Agentic Language Models; Iterative Query; Knowledge Graph Question Answering; Reinforcement Learning; SPARQL Query Generation},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational methods; Construction; Graph theory; Information use; Iterative methods; Knowledge graph; Query languages; Query processing; Structured Query Language; Agentic language model; Iterative query; Knowledge graph question answering; Knowledge graphs; Language model; Learn+; Query generation; Question Answering; Reinforcement learnings; SPARQL query generation; Reinforcement learning},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021821392&partnerID=40&md5=197ac19518e140f971ed91acebcbad2b},
}

@Conference{2025,
  title             = {RAGE-KG 2025 - Proceedings of the 2nd International Workshop on Retrieval-Augmented Generation Enabled by Knowledge Graphs, co-located with the 24th International Semantic Web Conference, ISWC 2025},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4079},
  abstract          = {The proceedings contain 15 papers. The topics discussed include: HubLink: a novel question answering retrieval approach over knowledge graphs; learning to refine: an agentic RL approach for iterative SPARQL query construction; RETROFIT-CQ revisited: leveraging ontology triples and context in few-shot LLM prompting; HyP-KGRAG: hypothetical path-based knowledge graph retrieval augmented generation with DeepSeek; RecipeRAG: a knowledge graph-driven approach to personalized recipe retrieval and generation; benchmarking KG-based RAG systems: a case study of legal documents; and beyond the metrics: an investigation into the reliability of evaluation metrics for domain specific graph-based question answering.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021812318&partnerID=40&md5=482696e98f4ece9735efca5b26ef42de},
}

@Conference{Caruso2025160,
  author            = {Caruso, Mario and Lodi, Giorgia and Macis, Carlo and Persiani, Simone and Presutti, Valentina},
  title             = {Boosting Knowledge Graph Question Answering with Open Source Lightweight Large Language Models and RAG techniques},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {160 - 168},
  volume            = {4079},
  abstract          = {The Linked Open Data (LOD) ecosystem provides a vast potential for structuring and sharing knowledge. However, accessing and querying this data remains challenging, particularly in contexts like the public sector, where technical capabilities are often limited. To bridge this gap, we introduce a Knowledge Graph Question Answering (KGQA) system that leverages open-source and lightweight Large Language Models (LLMs), along with Retrieval-Augmented Generation (RAG) techniques, to automatically produce SPARQL queries. Our experiments demonstrate the effectiveness of RAG-enhanced few-shot learning and Low-Rank Adaptation (LoRA) fine-tuning for generating precise, ontology-specific SPARQL queries. The presented results are obtained by employing our system within the cultural heritage domain, using ArCo, the Italian Ministry of Culture's open knowledge graph of cultural properties. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graph; Linked Open Data; Question Answering; Retrieval Augmented Generation},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Graph theory; Information retrieval; Knowledge graph; Knowledge management; Knowledge transfer; Linked data; Open Data; Open systems; Query languages; Query processing; Question answering; Generation techniques; In contexts; Knowledge graphs; Language model; Linked open data; Open-source; Question Answering; Retrieval augmented generation; Sharing knowledge; Structuring knowledge; Search engines},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021799004&partnerID=40&md5=f36245145e2bdca73bc06447d979e0f1},
}

@Conference{BarisMulayim2025660,
  author            = {Baris Mulayim, Ozan and Krishnan Prakash, Anand and Paul, Lazlo and Pritoni, Marco},
  title             = {Extraction and Analysis of Time Series Data from Building Automation Systems Using Large Language Models},
  year              = {2025},
  note              = {Cited by: 0},
  number            = {Pt2},
  pages             = {660 - 669},
  volume            = {131},
  abstract          = {Semantic schemas like Haystack 4, Brick and ASHRAE standard 223 enable the structured, standardized, and machine-readable representation of building data, facilitating interoperability, data integration, and advanced analytics. However, extracting information from these models requires specialized expertise in SPARQL and other programming languages, skills that are not commonly found among building professionals. Recent advancements in Large Language Models (LLMs), such as ChatGPT, enable the construction of queries using natural language, making it easier for individuals to interact with these systems in a manner that resembles everyday speech. However, these methods have not yet been tested on building semantic ontologies. This paper introduces a novel workflow and tool for enabling users to ask questions about a specific building's data, using natural language and receive answers automatically generated by GPT-4o. Our approach integrates semantic ontologies with advanced LLM capabilities to automate three critical steps: (1) generating SPARQL queries to retrieve time series references from ontological models, (2) extracting the corresponding time series data from the Building Automation System, and (3) performing computations and visualizations tailored to the user's query. The proposed method simplifies access to BAS data, allowing both domain experts and non-specialists to conduct sophisticated analyses without needing extensive technical knowledge of semantic web technologies. By demonstrating this pipeline, we facilitate more accessible and scalable data-driven decision-making in building operations and management. © 2025 U.S. Government.},
  doi               = {10.63044/s25ext76},
  journal           = {ASHRAE Transactions},
  keywords          = {Advanced Analytics; Automation; Building Information Model; Computational linguistics; Data integration; Data mining; Decision making; Information management; Intelligent buildings; Natural language processing systems; Ontology; Query processing; Semantic Web; Time series; ASHRAE standards; Building automation systems; Building professionals; Extracting information; Language model; Natural languages; Semantic ontology; Semantic schemata; Time-series data; Work-flows; Time series analysis},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105021340012&doi=10.63044%2Fs25ext76&partnerID=40&md5=95528f83e5e5b07ab85e0f19ea2cd2c2},
}

@Conference{Mahony2025,
  author            = {Mahony, Aidan O. and Sonawane, Pournima and Gupta, Shraddha},
  title             = {Semantic-Aware Orchestration and Energy-Optimized Data Management across the Edge–Cloud Continuum: The GLACIATION Approach},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4064},
  abstract          = {The rapid growth of data-intensive applications across the edge-cloud continuum presents a dual challenge: immense energy consumption and complex data governance. This paper presents the GLACIATION project, which tackles these issues through a platform for energy-efficient and privacy-preserving data operations. We showcase an integrated approach that combines a Distributed Knowledge Graph (DKG) with AI-driven orchestration to automate and optimize data management. Key innovations include the Green Index, a real-time metric for sustainable energy-aware workload shifting; a bio-inspired scheduling engine using Ant Colony Optimization; and a lightweight, zero-shot Large Language Model (LLM) interface that enables semantic exploration of the DKG via natural language. The effectiveness of this framework is demonstrated through its validation in real-world industrial and public sector pilot deployments. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {AI Scheduling; Data Placement; Distributed Knowledge Graphs; Edge-Cloud Systems; SPARQL with LLMs; Workload Orchestration},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Data privacy; Energy conservation; Energy utilization; Green computing; Information management; Knowledge graph; Power management; Semantic Web; Semantics; AI scheduling; Cloud systems; Data placement; Distributed knowledge; Distributed knowledge graph; Edge clouds; Edge-cloud system; Knowledge graphs; SPARQL with LLM; Workload orchestration; Ant colony optimization},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019647262&partnerID=40&md5=f87afee35d48c933e25038e288af9ec0},
}

@Conference{Todorovikj2025,
  author            = {Todorovikj, Sara and Meyer, Lars Peter and Martin, Michael},
  title             = {Characterizing Knowledge Graph Tasks in LLM Benchmarks Using Cognitive Complexity Frameworks},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4064},
  abstract          = {Large Language Models (LLMs) are increasingly used for tasks involving Knowledge Graphs (KGs), whose evaluation typically focuses on accuracy and output correctness. We propose a complementary task characterization approach using three complexity frameworks from cognitive psychology. Applying this to the LLM-KG-Bench framework, we highlight value distributions, identify underrepresented demands and motivate richer interpretation and diversity for benchmark evaluation tasks. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Benchmark evaluation; Knowledge Graph; LLM; RDF; SPARQL; Task characterization},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Benchmarking; Graph theory; Psychophysiology; Benchmark evaluation; Cognitive complexity; Cognitive psychology; Knowledge graphs; Language model; Large language model; Model knowledge; RDF; SPARQL; Task characterization; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105019644790&partnerID=40&md5=83767021b746fc579fd827eb4f462e1e},
}

@Article{Demir2025,
  author            = {Demir, Caglar and Baci, Alkid and Kouagou, N'Dah Jean and Sieger, Leonie Nora and Heindorf, Stefan and Bin, Simon and Blübaum, Lukas and Bigerl, Alexander and Ngomo, Axel Cyrille Ngonga},
  journal           = {Journal of Machine Learning Research},
  title             = {Ontolearn—A Framework for Large-scale OWL Class Expression Learning in Python},
  year              = {2025},
  note              = {Cited by: 3},
  volume            = {26},
  abstract          = {In this paper, we present Ontolearn—a framework for learning OWL class expressions over large knowledge graphs. Ontolearn contains efficient implementations of recent state-of-the-art symbolic and neuro-symbolic class expression learners including EvoLearner and DRILL. A learned OWL class expression can be used to classify instances in the knowledge graph. Furthermore, Ontolearn integrates a verbalization module based on an LLM to translate complex OWL class expressions into natural language sentences. By mapping OWL class expressions into respective SPARQL queries, Ontolearn can be easily used to operate over a remote triplestore. The source code of Ontolearn is available at https://github.com/dice-group/Ontolearn. ©2025 Caglar Demir, Alkid Baci, N’Dah Jean Kouagou, Leonie Nora Sieger, Stefan Heindorf, Simon Bin, Lukas Blübaum, Alexander Bigerl, and Axel-Cyrille Ngonga Ngomo.},
  author_keywords   = {description logics; knowledge graphs; machine learning; machine reasoning},
  keywords          = {Birds; Data description; Formal languages; Graph theory; Knowledge graph; Natural language processing systems; Query processing; Description logic; Efficient implementation; Knowledge graphs; Large-scales; Machine reasoning; Machine-learning; Module-based; Natural languages; Recent state; State of the art; Learning systems},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018574592&partnerID=40&md5=ee57ab6d6fa04f0e3498358a5f1b92b0},
}

@Conference{2025,
  title             = {TEXT2KG 2025 and BIKE 2025 - Joint Proceedings of the 4th International Workshop on LLM-Integrated Knowledge Graph Generation from Text and the 2nd International BiKE Challenge, co-located with the Extended Semantic Web Conference, ESWC 2025},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4020},
  abstract          = {The proceedings contain 15 papers. The topics discussed include: large language models ensemble for biochemical properties detection in scientific articles; SPHOTA: knowledge graph structure prediction with a hybrid orientation of textual alignment using K-BERT; SAMMCopilot: bootstrapping semantic models with the eclipse semantic modeling framework from domain data in JSON using large language models; PrO-KGC: prompt optimization for LLM-based knowledge graph completion; semantic enrichment of the quantum cascade laser properties in text - a knowledge graph generation approach; enhancing Text2Cypher with schema filtering; Wikidata hierarchy for named entity type discovery in the climate change domain; and instruction-tuned language models as judges for SPARQL query correctness in knowledge graph question answering.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017135233&partnerID=40&md5=5780703ee87fc7be26b2bff9739de521},
}

@Conference{Mashhaditafreshi202536,
  author            = {Mashhaditafreshi, Nazanin and Textor, Andreas and Rubel, Pascal and Moarefvand, Nastaran and Wagner, Achim},
  title             = {SAMM Copilot: Bootstrapping Semantic Models with the Eclipse Semantic Modeling Framework from Domain Data in JSON Using Large Language Models},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {36 - 52},
  volume            = {4020},
  abstract          = {The Semantic Aspect Meta Model (SAMM) is a modeling formalism for describing semantic models of parts of a Digital Twin - so-called Aspect Models. It is an open specification developed as part of the Eclipse Semantic Modeling Framework (ESMF). With SAMM being based on the Resource Description Framework (RDF) and Shapes Constraint Language (SHACL), Aspect Models are usually created and edited manually using a suitable textual editor or the graphical Aspect Model Editor. A well-defined mapping exists between Aspect Models and the JSON data they describe, enabling new bottom-up modeling approaches. In this way, instead of having a manual process for semantic modeling, Aspect Models can be automatically or semi-automatically derived from existing domain data in JSON format, making the modeling process more accessible and reducing manual effort. The proposed workflow translates JSON data into Aspect Models automatically using Large Language Models (LLMs). Our results demonstrate that LLMs can effectively bootstrap semantic models, and preliminary human evaluation suggests the feasibility and usefulness of this method in practice. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Large Language Models; Semantic Aspect Meta Model; Text-to-Knowledge Graph},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Latent semantic analysis; Resource Description Framework (RDF); Semantics; Aspect model; Knowledge graphs; Language model; Large language model; Meta model; Metamodeling; Modelling framework; Semantic aspect meta model; Semantic modelling; Text-to-knowledge graph; Modeling languages},
  publication_stage = {Final},
  ranking           = {rank4},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017128160&partnerID=40&md5=8c04b4b8be5a1d8edd1e20cd87777acb},
}

@Conference{Ongris2025116,
  author            = {Ongris, Jaycent Gunawan and Tjitrahardja, Eduardus and Darari, Fariz and Ekaputra, Fajar J.},
  title             = {FrOG: Framework of Open GraphRAG},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {116 - 134},
  volume            = {4020},
  abstract          = {The rise of large language models (LLMs) has advanced information retrieval, yet issues like limited knowledge updating, lack of transparency and interpretability, as well as hallucinations persist. Retrieval-augmented generation (RAG) addresses these problems, though it still lacks interpretability due to reliance on opaque vector-based representations. Our work presents a RAG framework using a knowledge graph (KG) as the primary knowledge base to address this problem, relying solely on open-source components to enable user customization. Our pipeline comprises multiple stages: (i) a translation module for multilingual support, (ii) entity linking, (iii) knowledge retrieval through verbalized triples or SPARQL query generation, and (iv) answer generation, which incorporates ontology (properties and classes) retrieval. We evaluate our system on Wikidata, DBpedia, and a domain-specific KG. With the optimal configuration determined through an ablation study, the system achieves Jaccard similarity scores of 0.458, 0.517, and 0.976 for each respective KG. The ablation study further reveals that ontology retrieval is the most crucial component in providing context to the LLM in generating SPARQL queries. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {GraphRAG; Knowledge Graphs; Large Language Models; Retrieval-Augmented Generation},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Computational methods; Graph theory; Information retrieval; Knowledge graph; Ontology; Open systems; Query processing; Advanced informations; Graphrag; Interpretability; Knowledge graphs; Knowledge updating; Language model; Large language model; Ontology's; Retrieval-augmented generation; Vector-based representations; Ablation},
  publication_stage = {Final},
  ranking           = {rank4},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017116638&partnerID=40&md5=fdae2ea8884ef0e03c866796d59acbc9},
}

@Conference{Gashkov2025177,
  author            = {Gashkov, Aleksandr and Eltsova, Maria and Perevalov, Aleksandr and Both, Andreas},
  title             = {Instruction-Tuned Language Models as Judges for SPARQL Query Correctness in Knowledge Graph Question Answering},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {177 - 194},
  volume            = {4020},
  abstract          = {Nowadays, the research community pays increasing attention to the challenge of trustworthy Knowledge Graph Question Answering (KGQA) systems due to the expectation of returning a high-quality and correct answer to the given natural-language question from continuously growing Knowledge Graphs (KGs). However, modern KGQA systems still generate a lot of incorrect SPARQL queries, leading to many incorrect answers presented to users. In this paper, we follow our long-term research agenda of providing an approach that advances the trustworthiness of KGQA systems while filtering out the incorrect query candidates (following the principle: no answer is better than a wrong answer). The approach presented in this paper is based on the use of LLMs that help to distinguish between correct and incorrect query candidates. Here, we aim to create a general approach that is, firstly, independent of the used (a) language(s), (b) KGs, (c) LLMs, and, secondly, can improve the answer quality of any KGQA system. For our experiments, we used LLMs from the following families: DeepSeek, Llama, Mistral, OpenAI, and Qwen. The LLMs were applied to the two state-of-the-art multilingual KGQA systems - QAnswer and MST5 - as post-processing SPARQL query filters. The approach was evaluated using the multilingual Wikidata-based dataset QALD-9-plus. The experimental results indicate reasonable quality improvement for all languages when using the approach presented in this paper. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Large Language Models; Multilingual Approach; Question Answering over Knowledge Graphs; SPARQL Validation; Trustworthiness},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Knowledge graph; Natural language processing systems; Query languages; Query processing; Question answering; Structured Query Language; Undirected graphs; Knowledge graphs; Language model; Large language model; Multilingual approach; Question Answering; Question answering over knowledge graph; Question answering systems; Research communities; SPARQL validation; Trustworthiness; Search engines},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017113291&partnerID=40&md5=99f7657fd1bb0dd6beac4a3f956dc5c8},
}

@Conference{Büschelberger2025,
  author            = {Büschelberger, Matthias and Tsitseklis, Konstantinos and Morand, Lukas and Zafeiropoulos, Anastasios and Nahshon, Yoav and Papavassiliou, Symeon and Helm, D.},
  title             = {Digital Products Based on Large Language Models for the Exploration of Graph-Databases in Materials Science and Manufacturing},
  year              = {2025},
  note              = {Cited by: 0},
  abstract          = {Semantic technologies are gaining traction in materials science and manufacturing. Specifically, the integration of graph databases with ontologies facilitates the harmonization of typically heterogeneous materials and process data, as well as the representation of complex workflows in the field (e.g., processing experimental and simulation data or transferring and tracking data along process chains). This approach enables previously inaccessible data for scientists and engineers to be made available in a FAIR (findable, accessible, interoperable, reusable) manner. On this basis, both science and industry, anticipate a significant boost in materials and process innovation, leading to a more resilient and sustainable production. Nevertheless, one of the main challenges in making semantic technologies usable for engineers is enabling navigation and exploration of the typically complex and flexible graph-based data structures. This work presents two approaches for data exploration in graph-databases using large language models (LLMs), namely LLM-CypherGen and SPARQL-Agent, and their application in two digital products developed within the EU research project DiMAT demonstrated across different use cases in materials science and manufacturing. © 2025 IEEE.},
  author_keywords   = {AI; Cypher; Knowledge Graph; LLM; Material Science; Ontology; SPARQL},
  doi               = {10.1109/ICE/ITMC65658.2025.11106608},
  keywords          = {Computer software reusability; Data handling; Engineering research; Graph Databases; Graph structures; Graphic methods; Interoperability; Semantic Web; Semantics; Cipher; Digital products; Graph database; Knowledge graphs; Language model; Large language model; Material science; Materials manufacturing; Ontology's; SPARQL; Industrial research},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015503120&doi=10.1109%2FICE%2FITMC65658.2025.11106608&partnerID=40&md5=c8596a356fef9b42983b45912cb3c973},
}

@Conference{Maldonado-RodrÃŋguez2025,
  author            = {Maldonado-RodrÃŋguez, Jose and Graciotti, Arianna and Presutti, Valentina and Pianzola, Federico},
  title             = {Natural Language Querying for Humanities Knowledge Graphs: A Case Study on the GOLEM Knowledge Graph},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {4009},
  abstract          = {Large-scale Knowledge Graphs (KGs) are increasingly relevant for humanities research, yet querying them via SPARQL poses challenges for non-technical users. While Text-to-SPARQL studies predominantly target popular KGs such as Wikidata or DBpedia, domain-specific KGs remain underexplored. This paper introduces a bilingual (English-Spanish) dataset designed for evaluating automatic text-to-SPARQL translation on GOLEM, a humanities KG containing metadata and extracted features from fanfiction stories hosted on Archive of Our Own (AO3). The dataset includes 477 manually crafted natural language questions paired with gold SPARQL queries, augmented to 1,895 questions through automatic paraphrasing. We benchmark several Large Language Models (LLMs) with prompt-based approaches, particularly examining in-context learning methods that select prompt examples based on semantic similarity, which yield the best results. Error analysis highlights entity linking as essential for improving query generation. This work provides practical insights and opens pathways for future research on natural language interfaces for querying domain-specific KGs in Digital Humanities. The dataset and output of our experiments are available at: https://github.com/GOLEM-lab/GOLEM_Text-to-SPARQL. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Humanities Knowledge Graphs; In-context learning; Large Language Models; Text-to-SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Graphic methods; Knowledge graph; Learning systems; Natural language processing systems; Query processing; Context learning; Domain-specific knowledge; Humanity knowledge graph; In contexts; In-context learning; Knowledge graphs; Language model; Large language model; Natural languages; Text-to-SPARQL; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013458675&partnerID=40&md5=88b4322c14bda76fe72658df6af0c25d},
}

@Article{Sadeghi2025136626,
  author            = {Sadeghi, Farzaneh and Degbelo, Auriol and Keßler, Carsten and Zolnouri, Reza},
  journal           = {IEEE Access},
  title             = {Applying the FAIR Principles to Open Educational Resources: A Semantic Similarity Approach to Improve Resource Discovery},
  year              = {2025},
  note              = {Cited by: 0; All Open Access; Gold Open Access},
  pages             = {136626 - 136642},
  volume            = {13},
  abstract          = {Open educational resources (OER) are teaching, learning, or research resources freely available for use and reuse. Despite their potential, OER uptake in existing education systems remains low, primarily due to challenges in locating suitable resources. This study addresses this challenge by proposing and implementing a workflow applying the FAIR (Findable, Accessible, Interoperable, and Reusable) principles to OER. We demonstrated this framework within the Earth System Sciences as an application domain. We constructed a knowledge graph of approximately 500 FAIR OER, each annotated with structured metadata using the Schema.org vocabulary and made accessible through a SPARQL endpoint. To bridge the gap between making resources queryable and enabling their practical reuse, we employed a transformer-based language model (Sentence-BERT). The model was fine-tuned using few-shot learning on a domain-specific dataset of course-description pairs. This specialized model was then used to map the OER collection against over 200 university courses across five academic programs at a German university, based on semantic similarity between OER descriptions and university course descriptions. Expert evaluation of the model’s recommendations demonstrated 74% accuracy in identifying reusable OER for university courses. Notably, even with limited training data, fine-tuning the Sentence-BERT model significantly improved performance, resulting in a 16% reduction in mean squared error compared to the base model. This study provides both a generalizable methodology and a practical demonstration of how FAIR principles can streamline OER discovery, potentially accelerating OER uptake in higher education. © 2013 IEEE.},
  author_keywords   = {FAIR principles; higher education; knowledge graph; LLM; metadata; open educational resources; reusability},
  doi               = {10.1109/ACCESS.2025.3594963},
  keywords          = {Computer software reusability; Curricula; Knowledge graph; Mean square error; Semantics; Teaching; Findable, accessible, interoperable, and reusable principle; High educations; Knowledge graphs; LLM; Open educational resources; Resource discovery; Reuse; Semantic similarity approaches; Teaching researches; University course; Metadata; Reusability},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012356300&doi=10.1109%2FACCESS.2025.3594963&partnerID=40&md5=565e8fe49d7b5c196726211b58b68438},
}

@Article{Kosten20258,
  author            = {Kosten, Catherine and Lanti, Davide and Cudre-Mauroux, Philippe and Stockinger, Kurt},
  journal           = {Proceedings - Swiss Conference on Data Science, SDS},
  title             = {Bootstrapping Text-to-SQL Resources for Knowledge Graph Question Answering},
  year              = {2025},
  note              = {Cited by: 0},
  number            = {2025},
  pages             = {8 - 15},
  abstract          = {As Large Language Models continue to grow in size and sophistication, more benchmarks are needed to assess their capabilities. Benchmarks are crucial for measuring progress and pushing the scientific community forward. However, they are often expensive and exploitative to build. In this paper, we demonstrate how to translate the rich and complex existing resources for SQL and relational databases that have been used by the database community, for SPARQL and Knowledge Graph Question Answering (KGQA). We describe how we bootstrapped the largest and most complex KGQA benchmark to date, explore the complexities of converting a relational database into a knowledge graph and describe the methods used to learn rich schema information in the KG from its relational counterpart using a query workload-based analysis. In addition, we show how this method can be used to bootstrap any existing SQL benchmark for KGQA by translating the newly created ScienceBenchmark dataset into a KGQA dataset. © 2025 IEEE.},
  author_keywords   = {knowledge graph question answering; Knowledge graphs; language models; natural language processing; Text-to-SQL},
  doi               = {10.1109/SDS66131.2025.00009},
  keywords          = {Computational linguistics; Knowledge graph; Query languages; Query processing; Question answering; Relational database systems; Undirected graphs; Knowledge graph question answering; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Question Answering; Relational Database; Text-to-SQL; Natural language processing systems},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012253855&doi=10.1109%2FSDS66131.2025.00009&partnerID=40&md5=7696124669fb57f4e2da05b482e0674d},
}

@Conference{Dorsch202529,
  author            = {Dorsch, Rene and Henselmann, Daniel and Harth, Andreas},
  title             = {COMPASS: A Process Mining-based Methodology for Prompt Optimization of Large Language Model Agents},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {29 - 37},
  volume            = {3996},
  abstract          = {Exploring and optimizing the behavior of LLM agents in complex environments is challenging. We present COMPASS, a methodology that systematically applies Process Mining to discover, analyze, and refine agent behavior. COMPASS consists of five phases: planning the project, extracting data from the LLM agent, transforming data into event logs, exploring and analyzing agent behavior, and providing feedback through conformance checking or prompt design guidelines. We evaluate COMPASS in a case study with an LLM agent that uses three tools to generate SPARQL queries while exploring a complex knowledge graph. Through COMPASS, we identified ineffective behavior patterns and optimized prompts to improve performance. Our methodology supports data-driven prompt optimization with interpretable behavioral models, enhancing explainability and reliability in complex environments. This ongoing research aims to systematically improve agent performance through exploratory behavioral analysis that increases transparency in agents’ decision-making processes. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Agent; Explainability; Large Language Model; Process Mining; Prompt Optimization},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Behavioral research; Data mining; Decision making; Information systems; Information use; Agent behavior; COMPASSs; Complex environments; Explainability; Language model; Large language model; Model agents; Optimisations; Process mining; Prompt optimization; Agents},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011041521&partnerID=40&md5=08fb297c757c27f3c7d62268efcd42f5},
}

@Conference{Avila202576,
  author            = {Avila, Caio Viktor S. and Vidal, Vânia Maria Ponte and Franco, Wellington and Casanova, Marco Antonio},
  title             = {Few-Shot Learning or RAG in LLM-Based Text-to-SPARQL? Why Not Both?},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {76 - 79},
  abstract          = {This paper introduces a hybrid approach for the text-to-SPARQL task involving Large Language Models (LLMs) by integrating Retrieval-Augmented Generation (RAG) with fewshot learning techniques. The approach enhances the AutoKGQA framework by incorporating query examples into the LLM while selecting minimal knowledge graph (KG) subgraphs as context, thereby improving its ability to interpret and answer natural language queries. Experimental results on the SciQA benchmark indicate that this integration increased the F1-score by 0.16. Notably, the framework excelled in the zero-shot setting with an F1-score of 0.73, significantly outperforming the prior score of 0.26. Additionally, the paper introduces an automated procedure to extract a minimal T-Box from KGs lacking an explicit schema, optimizing query processing by limiting deep neighborhood exploration. These findings suggest that combining KG context with query examples is an effective strategy, particularly for developing generalizable systems. © 2025 IEEE.},
  author_keywords   = {knowledge graph; large language model; question answering},
  doi               = {10.1109/ICSC64641.2025.00016},
  journal           = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
  keywords          = {Computational linguistics; Knowledge graph; Learning systems; Natural language processing systems; Query languages; Query processing; Question answering; Structured Query Language; F1 scores; Hybrid approach; Knowledge graphs; Language model; Large language model; Learning techniques; Model-based OPC; Natural language queries; Question Answering; Subgraphs; Search engines},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009509450&doi=10.1109%2FICSC64641.2025.00016&partnerID=40&md5=7f5b225d5cce912144fe7d53db275258},
}

@Conference{Jiang202528,
  author            = {Jiang, Longquan and Huang, Junbo and Moller, Cedric and Usbeck, Ricardo},
  title             = {Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {28 - 35},
  abstract          = {Most existing Knowledge Graph Question Answering (KGQA) approaches are designed for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the heterogeneity of the underlying graph schema, topology and assertions, most KGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without resource-intensive training data. We present OntoSCPrompt, a novel Large Language Model (LLM)-based KGQA approach with a two-stage architecture that separates semantic parsing from KG-dependent interactions. OntoSCPrompt first generates a SPARQL query structure (including SPARQL keywords such as SELECT, ASK, WHERE and placeholders for missing tokens) and then fills them with KG-specific information. To enhance the understanding of the underlying KG, we present an ontology-guided, hybrid prompt learning strategy that integrates KG ontology into the learning process of hybrid prompts (e.g., discrete and continuous vectors). We also present several task-specific decoding strategies to ensure the correctness and executability of generated SPARQL queries in both stages. Experimental results demonstrate that OntoSCPrompt performs as well as SOTA approaches without retraining on a number of KGQA datasets such as CWQ, WebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well to unseen domain-specific KGs like DBLP-QuAD and CoyPu KG <sup>1</sup><sup>1</sup>Code: https://github.com/LongquanJiang/OntoSCPrompt. © 2025 IEEE.},
  author_keywords   = {Generalization; KGQA; LLM; QA},
  doi               = {10.1109/ICSC64641.2025.00010},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
  keywords          = {Knowledge graph; Knowledge transfer; Learning systems; Ontology; Query processing; Question answering; Dbpedia; Generalisation; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Ontology's; QA; Question Answering; Specific knowledge; Semantics},
  publication_stage = {Final},
  ranking           = {rank3},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009456479&doi=10.1109%2FICSC64641.2025.00010&partnerID=40&md5=19916ad8cf2702f3905c9c621d6d8ec4},
}

@Conference{Heim2025,
  author            = {Heim, Desiree and Meyer, Lars Peter and Schröder, Markus and Frey, Johannes and Dengel, Andreas R.},
  title             = {How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {3977},
  abstract          = {When using Large Language Models (LLMs) to support Knowledge Graph Engineering (KGE), one of the first indications when searching for an appropriate model is its size. According to the scaling laws, larger models typically show higher capabilities. However, in practice, resource costs are also an important factor and thus it makes sense to consider the ratio between model performance and costs. The LLM-KG-Bench framework enables the comparison of LLMs in the context of KGE tasks and assesses their capabilities of understanding and producing KGs and KG queries. Based on a dataset created in an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the model size scaling laws specific to KGE tasks. In our analyses, we assess how benchmark scores evolve between different model size categories. Additionally, we inspect how the general score development of single models and families of models correlates to their size. Our analyses revealed that, with a few exceptions, the model size scaling laws generally also apply to the selected KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e., the task performance did not change much between a model and the next larger model. In these cases, smaller models could be considered to achieve high cost-effectiveness. Regarding models of the same family, sometimes smaller models performed worse than larger models of the same family. These effects occurred only locally. Hence it is advisable to additionally test the next smallest and largest model of the same family. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graph; Knowledge Graph Engineering; LLM; LLM Evaluation; RDF; Scaling Laws; SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Cost effectiveness; Graph theory; Information management; Knowledge graph; Knowledge graph engineering; Knowledge graphs; Language model; Large language model; Large language model evaluation; Model evaluation; RDF; Scalings; SPARQL; Scaling laws},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008490484&partnerID=40&md5=2a5b7bd5d6f42eb23691f39e81a2f990},
}

@Article{Meyer2025280,
  author            = {Meyer, Lars Peter and Frey, Johannes and Heim, Desiree and Brei, Felix and Stadler, Claus R. and Junghanns, Kurt and Martin, Michael},
  journal           = {Lecture Notes in Computer Science},
  title             = {LLM-KG-Bench 3.0: A Compass for Semantic Technology Capabilities in the Ocean of LLMs},
  year              = {2025},
  note              = {Cited by: 1; All Open Access; Green Accepted Open Access; Green Open Access},
  pages             = {280 - 296},
  volume            = {15719 LNCS},
  abstract          = {Current Large Language Models (LLMs) can assist developing program code beside many other things, but can they support working with Knowledge Graphs (KGs) as well? Which LLM is offering the best capabilities in the field of Semantic Web and Knowledge Graph Engineering (KGE)? Is this possible to determine without checking many answers manually? The LLM-KG-Bench framework in Version 3.0 is designed to answer these questions. It consists of an extensible set of tasks for automated evaluation of LLM answers and covers different aspects of working with semantic technologies. In this paper the LLM-KG-Bench framework is presented in Version 3 along with a dataset of prompts, answers and evaluations generated with it and several state-of-the-art LLMs. Significant enhancements have been made to the framework since its initial release, including an updated task API that offers greater flexibility in handling evaluation tasks, revised tasks, and extended support for various open models through the vllm library, among other improvements. A comprehensive dataset has been generated using more than 30 contemporary open and proprietary LLMs, enabling the creation of exemplary model cards that demonstrate the models’ capabilities in working with RDF and SPARQL, as well as comparing their performance on Turtle and JSON-LD RDF serialization tasks. Resource type:evaluation benchmark framework License: MPL 2.0 DOI:DOI:10.5281/zenodo.15100803 URL:https://github.com/AKSW/LLM-KG-Bench © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {Knowledge Graph; LLM; LLM Evaluation; RDF; SPARQL},
  doi               = {10.1007/978-3-031-94578-6_16},
  keywords          = {Computer software selection and evaluation; Model checking; Knowledge graphs; Language model; Large language model; Large language model evaluation; Model evaluation; Model knowledge; RDF; Semantic technologies; SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007797144&doi=10.1007%2F978-3-031-94578-6_16&partnerID=40&md5=ad1c443c0ac6456112d13449361ad054},
}

@Article{Milanese2025192,
  author            = {Milanese, Gian Carlo and Peikos, Giorgos and Pasi, Gabriella and Viviani, Marco},
  journal           = {Lecture Notes in Computer Science},
  title             = {Fact-Driven Health Information Retrieval: Integrating LLMs and Knowledge Graphs to Combat Misinformation},
  year              = {2025},
  note              = {Cited by: 1},
  pages             = {192 - 200},
  volume            = {15574 LNCS},
  abstract          = {Aiming to reduce health misinformation in Web search, we present a system for Health Information Retrieval (HIR) that ranks documents according to both their topical relevance and correctness (i.e., factuality). The system first segments documents into passages and then employs a Large Language Model (LLM) to identify and extract claims from each passage. For each claim, we formulate corresponding SPARQL queries and execute them against a Knowledge Graph (KG) extracted from a subset of DBpedia, allowing us to estimate the correctness of claims and, hence, a correctness score for documents. Topical relevance is estimated with the BM25 algorithm, which is used to produce the initial ranking of documents. To generate the final ranking, the system combines each document’s pre-computed correctness score with its topical relevance score. While existing approaches rely on machine learning or LLMs to verify correctness, our KG-based methodology enables transparent fact-checking by grounding its assessments in structured knowledge. Our approach is empirically evaluated using three TREC Health Misinformation collections (2020–2022). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
  author_keywords   = {Fact-checking; Health information retrieval; Health misinformation; Knowledge graphs; Large language models},
  doi               = {10.1007/978-3-031-88714-7_17},
  keywords          = {Content based retrieval; Knowledge graph; Learning to rank; Query languages; Recommender systems; Structured Query Language; Dbpedia; Fact-checking; Health information retrieval; Health informations; Health misinformation; Knowledge graphs; Language model; Large language model; Relevance score; Web searches; Online searching},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006633727&doi=10.1007%2F978-3-031-88714-7_17&partnerID=40&md5=818229ebc88f4876ec089fae58602938},
}

@Conference{Meloni2025,
  author            = {Meloni, Antonello and Reforgiato Recupero, Diego and Osborne, Francesco and Salatino, Angelo Antonio and Motta, Enrico and Vahadati, Sahar and Lehmann, Jens F.},
  title             = {Assessing Large Language Models for SPARQL Query Generation in Scientific Question Answering},
  year              = {2025},
  note              = {Cited by: 1},
  volume            = {3953},
  abstract          = {Scientific question answering remains a significant challenge for the current generation of large language models (LLMs) due to the requirement of engaging with highly specialised concepts. A promising solution is to integrate LLMs with knowledge graphs of research concepts, ensuring that responses are grounded in structured, verifiable information. One effective approach involves using LLMs to translate questions posed in natural language into SPARQL queries, enabling the retrieval of relevant data. In this paper, we analyse the performance of several LLMs on this task using two scientific question-answering benchmarks: SciQA and DBLP-QuAD. We explore both few-shot learning and fine-tuning strategies, investigate error patterns across different models, and propose directions for future research. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graphs; Large Language Models; Machine Translation; SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational grammars; Computer aided language translation; Modeling languages; Neural machine translation; Query languages; Structured Query Language; Current generation; Effective approaches; Knowledge graphs; Language model; Large language model; Machine translations; Natural languages; Query generation; Question Answering; SPARQL; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003734281&partnerID=40&md5=e6bddf3a1751aec881bb0e25888c3aa4},
}

@Conference{2025,
  title             = {HGAIS 2024 - Proceedings of the Special Session on Harmonising Generative AI and Semantic Web Technologies, co-located with the 23rd International Semantic Web Conference, ISWC 2024},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {3953},
  abstract          = {The proceedings contain 14 papers. The topics discussed include: LLM-based SPARQL query generation from natural language over federated knowledge graphs; a benchmark for the detection of metalinguistic disagreements between LLMs and knowledge graphs; assessing large language models for SPARQL query generation in scientific question answering; benchmarking ontology validation capabilities of LLMs; ontology corpora for LLM-based knowledge engineering research; information for conversation generation: proposals utilizing knowledge graphs; OAEI-LLM: a benchmark dataset for understanding large language model hallucinations in ontology matching; a comprehensive benchmark for evaluating LLM-generated ontologies; and hybrid evaluation of Socratic dialogue for teaching.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003726476&partnerID=40&md5=5eaae429353e70e72793e075a58a61bc},
}

@Conference{Emonet2025,
  author            = {Emonet, Vincent and Bolleman, Jerven Tjalling and Duvaud, Séverine and de Farias, Tarcisio Mendes and Sima, Ana Claudia},
  title             = {LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {3953},
  abstract          = {We introduce a Retrieval-Augmented Generation (RAG) system for translating user questions into accurate federated SPARQL queries over bioinformatics knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance accuracy and reduce hallucinations in query generation, our system utilises metadata from the KGs, including query examples and schema information, and incorporates a validation step to correct generated queries. The system is available online at chat.expasy.org. © 2025 Copyright for this paper by its authors.},
  author_keywords   = {Federated SPARQL query; Knowledge Graph Question Answering; Large Language Models; Retrieval-Augmented Generation; SPARQL query generation},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Query languages; Structured Query Language; Federated SPARQL query; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Model-based OPC; Query generation; Question Answering; Retrieval-augmented generation; SPARQL query generation; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003725579&partnerID=40&md5=b4f921224527cdda4878a73c92235b62},
}

@Conference{Yano2025975,
  author            = {Yano, Kosuke and Kitamura, Yoshinobu and Kuwabara, Kazuhiro},
  title             = {Natural Language Interface for Goal-Oriented Knowledge Graphs Using Retrieval-Augmented Generation},
  year              = {2025},
  note              = {Cited by: 0},
  pages             = {975 - 982},
  volume            = {3},
  abstract          = {A search method leveraging Retrieval-Augmented Generation (RAG) for goal-oriented knowledge graphs is proposed, with a specific focus on function decomposition trees. A function decomposition tree represents hierarchically functions of artifacts or actions of human with explicit descriptions of purposes and goals. We developed a schema to convert the trees into RDF, enabling structured and efficient searches. Through RAG technology, a natural language interface converts user’s inputs into SPARQL queries, retrieving relevant data and subsequently presenting them in an accessible and chat-based format. Such a flexible, and purposedriven searches enhance usability in complex knowledge graphs. We demonstrate the tool effectively retrieves actions, intentions, and dependencies using an illustrative and a real-world example of function decomposition trees. © 2025 by SCITEPRESS – Science and Technology Publications, Lda.},
  author_keywords   = {Function Decomposition Tree; Large Language Model; Retrieval-Augmented Generation},
  doi               = {10.5220/0013245700003890},
  journal           = {International Conference on Agents and Artificial Intelligence},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001924223&doi=10.5220%2F0013245700003890&partnerID=40&md5=5320fa1b9dee84457ccf69cf06981573},
}

@Conference{Zhang20243300,
  author            = {Zhang, Zhiqiang and Wen, Liqiang and Zhao, Wen},
  title             = {A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering},
  year              = {2024},
  note              = {Cited by: 1},
  pages             = {3300 - 3309},
  abstract          = {Recent studies on knowledge graph question answering (KGQA) have focused on tackling complex inquiries to enhance the applicability of models in real-life settings. Unfortunately, KGQA models encounter significant challenges due to the lack of high-quality annotated data, making it difficult to accurately answer the diverse range of complex natural language questions posed by users. Inspired by the recent success of Large Language Models (LLMs), the burden associated with manual annotation can be mitigated by utilizing LLMs. However, the data generated directly by LLMs may exhibit a potential distribution discrepancy with real user queries. In this paper, we present an enhancement framework that utilizes Generative Adversarial Imitation Learning (GAIL) to fine-tune LLMs, which can address the challenges inherent in the low-resource KGQA task. Specifically, based on GAIL, the LLMs act as the generator aiming to output samples resembling expert demonstrations. Meanwhile, we utilize a paired discriminator to assess the authenticity of generated sequences and their relevance to the input SPARQL queries. Additionally, proximal policy optimization is leveraged to stabilize the training of the generator. Furthermore, we employ an automated algorithm to controllably sample various SPARQL queries from the knowledge graph, subsequently transforming them into corresponding natural language questions using fine-tuned LLMs. The synthetic dataset can serve as supplementary data for training lightweight KGQA models in real-world scenarios. Experimental results on the WebQuestionsSP, ComplexWebQuestions, and GrailQA show that our framework achieves state-of-the-art performance in a low-resource setting, even approaching the performance of supervised models. © 2024 ACM.},
  author_keywords   = {generative adversarial imitation learning; knowledge graph; large language model; question answering},
  doi               = {10.1145/3627673.3679753},
  journal           = {International Conference on Information and Knowledge Management, Proceedings},
  keywords          = {Adversarial machine learning; Contrastive Learning; Generative adversarial networks; Structured Query Language; Diverse range; Generative adversarial imitation learning; High quality; Imitation learning; Knowledge graphs; Language model; Large language model; Manual annotation; Natural language questions; Question Answering; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210010094&doi=10.1145%2F3627673.3679753&partnerID=40&md5=a230c4cbb4f8800cbe3bb48f7d377737},
}

@Article{Monka20244665,
  author            = {Monka, Sebastian and Grangel-González, Irlán and Schmid, Stefan and Halilaj, Lavdim and Rickart, Marc and Rudolph, Oliver and Dias, Rui},
  journal           = {Frontiers in Artificial Intelligence and Applications},
  title             = {Enhancing Manufacturing Knowledge Access with LLMs and Context-Aware Prompting},
  year              = {2024},
  note              = {Cited by: 1; All Open Access; Hybrid Gold Open Access},
  pages             = {4665 - 4672},
  volume            = {392},
  abstract          = {Knowledge graphs (KGs) have transformed data management within the manufacturing industry, offering effective means for integrating disparate data sources through shared and structured conceptual schemas. However, harnessing the power of KGs can be daunting for non-experts, as it often requires formulating complex SPARQL queries to retrieve specific information. With the advent of Large Language Models (LLMs), there is a growing potential to automatically translate natural language queries into the SPARQL format, thus bridging the gap between user-friendly interfaces and the sophisticated architecture of KGs. The challenge remains in adequately informing LLMs about the relevant context and structure of domain-specific KGs, e.g., in manufacturing, to improve the accuracy of generated queries. In this paper, we evaluate multiple strategies that use LLMs as mediators to facilitate information retrieval from KGs. We focus on the manufacturing domain, particularly on the Bosch Line Information System KG and the I40 Core Information Model. In our evaluation, we compare various approaches for feeding relevant context from the KG to the LLM and analyze their proficiency in transforming real-world questions into SPARQL queries. Our findings show that LLMs can significantly improve their performance on generating correct and complete queries when provided only the adequate context of the KG schema. Such context-aware prompting techniques help LLMs to focus on the relevant parts of the ontology and reduce the risk of hallucination. We anticipate that the proposed techniques help LLMs to democratize access to complex data repositories and empower informed decision-making in manufacturing settings. © 2024 The Authors.},
  doi               = {10.3233/FAIA241062},
  keywords          = {Data integration; Information management; Knowledge graph; Manufacturing data processing; Modeling languages; Natural language processing systems; Query languages; Smart manufacturing; Translation (languages); Conceptual schemas; Context-aware prompting; Data-source; Knowledge graphs; Language model; Manufacturing industries; Manufacturing knowledge; Natural language queries; Power; Specific information; Structured Query Language},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216677054&doi=10.3233%2FFAIA241062&partnerID=40&md5=d7e19bae8d68aba6382f30c1f316dafa},
}

@Article{Kondinski20242070,
  author            = {Kondinski, Aleksandar and Rutkevych, Pavlo P. and Pascazio, Laura and Tran, Dan N. and Farazi, Feroz and Ganguly, Srishti and Kraft, Markus},
  journal           = {Digital Discovery},
  title             = {Knowledge graph representation of zeolitic crystalline materials},
  year              = {2024},
  note              = {Cited by: 9; All Open Access; Gold Open Access},
  number            = {10},
  pages             = {2070 - 2084},
  volume            = {3},
  abstract          = {Zeolites are complex and porous crystalline inorganic materials that serve as hosts for a variety of molecular, ionic and cluster species. Formal, machine-actionable representation of this chemistry presents a challenge as a variety of concepts need to be semantically interlinked. This work demonstrates the potential of knowledge engineering in overcoming this challenge. We develop ontologies OntoCrystal and OntoZeolite, enabling the representation and instantiation of crystalline zeolite information into a dynamic, interoperable knowledge graph called The World Avatar (TWA). In TWA, crystalline zeolite instances are semantically interconnected with chemical species that act as guests in these materials. Information can be obtained via custom or templated SPARQL queries administered through a user-friendly web interface. Unstructured exploration is facilitated through natural language processing using the Marie System, showcasing promise for the blended large language model - knowledge graph approach in providing accurate responses on zeolite chemistry in natural language. © 2024 RSC.},
  doi               = {10.1039/d4dd00166d},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205728208&doi=10.1039%2Fd4dd00166d&partnerID=40&md5=9aa22f05a71e9ba9bdca274e3e0310f1},
}

@Article{Ghajari2024271,
  author            = {Ghajari, Adrián and Ros, Salvador Cador and Pérez, Alvaro},
  journal           = {Procesamiento del Lenguaje Natural},
  title             = {Querying the Depths: Unveiling the Strengths and Struggles of Large Language Models in SPARQL Generation; Explorando las Profundidades: Revelando las Fortalezas y Desafíos de los Modelos de Lenguaje de Gran Escala en la Generación de SPARQL},
  year              = {2024},
  note              = {Cited by: 1},
  number            = {73},
  pages             = {271 - 281},
  abstract          = {The emergence of the Semantic Web has precipitated a proliferation of structured data manifested in the form of knowledge graphs, underscoring the imperative of natural language interfaces to enhance accessibility to these repositories of information. The capacity to articulate queries in natural language and subsequently retrieve data through SPARQL queries assumes paramount importance. In the present investigation, we have scrutinized the efficacy of in-context learning based on an agent-based architecture in facilitating the construction of SPARQL queries. Contrary to initial expectations, the augmentation of in-context learning prompts through agent-based mechanisms has been found to diminish the efficacy of Language Model-based Systems (LLMS), as it is perceived as extraneous”noise,” thereby delineating the constraints inherent in this approach. The results highlight the need to delve deeper into the intricacies of model training and fine-tuning, focusing on the relational aspects of ontology schemas. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
  author_keywords   = {Agents; Knowledge Retrieval; Prompt Engineering; SPARQL Queries},
  doi               = {10.26342/2024-73-20},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206510658&doi=10.26342%2F2024-73-20&partnerID=40&md5=8cb9a9b1380cf379a5c5a43896866c23},
}

@Conference{Oranekwu20246336,
  author            = {Oranekwu, Ikechukwu and Elluri, Lavanya and Batra, Gunjan},
  title             = {Automated Knowledge Framework for IoT Cybersecurity Compliance},
  year              = {2024},
  note              = {Cited by: 2},
  pages             = {6336 - 6345},
  abstract          = {Rapid expansion in the manufacture and use of Internet of Things (IoT) devices has introduced significant challenges in ensuring compliance with cybersecurity standards. To protect user data and privacy, all organizations providing IoT devices must adhere to complex guidelines such as the National Institute of Standards and Technology Inter agency Report (NIST IR) 8259, which defines essential cybersecurity guidelines for IoT manufacturers. However, interpreting and applying these rules from these guidelines and the privacy policies remains a significant challenge for companies. Thus, this project presents a novel approach to extract knowledge from NIST 8259 for creating semantically rich ontology mappings. Our ontology captures key compliance rules, which are stored in a knowledge graph (KG) that allows organizations to crosscheck and update privacy policy documents with ease. The KG also enables real-time querying using SPARQL and offers a transparent view of regulatory adherence for IoT manufacturers and users. By automating the process of verifying cybersecurity compliance, the framework ensures that companies remain aligned with NIST standards, eliminating manual checks and reducing the risk of non-compliance. We also demonstrate that compared to the baseline Large Language Models (LLMs), our proposed framework has more compliance accuracy, and is more efficient and scalable. © 2024 IEEE.},
  author_keywords   = {automated compliance; Cybersecurity; IoT; KGs; LLMs; NIST 8259 standards; privacy policies; regulatory compliance; SPARQL},
  doi               = {10.1109/BigData62323.2024.10825755},
  keywords          = {Knowledge graph; Regulatory compliance; Automated compliance; Cyber security; KG; Knowledge frameworks; Knowledge graphs; Language model; Large language model; NIST 8259 standard; Privacy policies; SPARQL; Ontology},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218064800&doi=10.1109%2FBigData62323.2024.10825755&partnerID=40&md5=a3faa0751cd49dee16c06424344db196},
}

@Conference{Mitsuji2024144,
  author            = {Mitsuji, Fumiya and Chakraborty, Sudesna and Morita, Takeshi and Egami, Shusaku and Ugai, Takanori and Fukuda, Ken},
  title             = {Entity Linking for Wikidata using Large Language Models and Wikipedia Links},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {144 - 149},
  abstract          = {Entity Linking (EL), a task that maps named entities in text to corresponding entities in a knowledge base, has gained attention as a fundamental technology in knowledge processing and natural language processing. Conventional EL methods typically tokenize input text and utilize multiple features such as word embeddings and knowledge graph embeddings. Adapting these conventional EL methods to specific languages requires modifying language-dependent modules like tokenizers and word embedding models for the target language. In this study, we propose an EL method targeting Wikidata, based on Large Language Models (LLMs) and links from Wikidata to Wikipedia. Our method prompts LLMs to extract entity names from the input text and generate the corresponding Wikipedia URLs. Furthermore, it queries the Wikidata SPARQL endpoint to obtain Wikidata IDs from the Wikipedia URLs, outputting the entity names and their Wikidata IDs. This method can be applied to various languages by modifying the prompts. To evaluate, we compared the proposed method with conventional EL methods (PNEL and Japanese PNEL) on Japanese and English datasets from LC-QuAD2.0, SimpleQuestions, and WebQSP; using GPT-3.5, GPT-4, and Llama 2 as LLMs. The results showed that our method using GPT-4 outperformed conventional EL methods in recall and F-scores on datasets except for Japanese SimpleQuestions. © 2024 IEEE.},
  author_keywords   = {Entity Linking; Knowledge Graph; Large Language Model; Wiki-data; Wikipedia},
  doi               = {10.1109/CANDARW64572.2024.00030},
  keywords          = {Graph embeddings; Natural language processing systems; Structured Query Language; Embeddings; Entity linking; Knowledge graphs; Knowledge processing; Language model; Large language model; Named entities; Natural languages; Wiki-data; Wikipedia; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216878267&doi=10.1109%2FCANDARW64572.2024.00030&partnerID=40&md5=8062304e81f547066e578f143a2c429b},
}

@Article{Kosten2024,
  author            = {Kosten, Catherine and Nooralahzadeh, Farhad and Stockinger, Kurt},
  journal           = {Frontiers in Artificial Intelligence},
  title             = {Evaluating the effectiveness of prompt engineering for knowledge graph question answering},
  year              = {2024},
  note              = {Cited by: 4; All Open Access; Gold Open Access; Green Accepted Open Access; Green Open Access},
  volume            = {7},
  abstract          = {Many different methods for prompting large language models have been developed since the emergence of OpenAI's ChatGPT in November 2022. In this work, we evaluate six different few-shot prompting methods. The first set of experiments evaluates three frameworks that focus on the quantity or type of shots in a prompt: a baseline method with a simple prompt and a small number of shots, random few-shot prompting with 10, 20, and 30 shots, and similarity-based few-shot prompting. The second set of experiments target optimizing the prompt or enhancing shots through Large Language Model (LLM)-generated explanations, using three prompting frameworks: Explain then Translate, Question Decomposition Meaning Representation, and Optimization by Prompting. We evaluate these six prompting methods on the newly created Spider4SPARQL benchmark, as it is the most complex SPARQL-based Knowledge Graph Question Answering (KGQA) benchmark to date. Across the various prompting frameworks used, the commercial model is unable to achieve a score over 51%, indicating that KGQA, especially for complex queries, with multiple hops, set operations and filters remains a challenging task for LLMs. Our experiments find that the most successful prompting framework for KGQA is a simple prompt combined with an ontology and five random shots. © © 2025 Kosten, Nooralahzadeh and Stockinger.},
  author_keywords   = {knowledge graph question answering; LLMs; prompt engineering; RDF; SPARQL},
  doi               = {10.3389/frai.2024.1454258},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216184385&doi=10.3389%2Ffrai.2024.1454258&partnerID=40&md5=6daf2b7c501d6e2fa5a622db2d279159},
}

@Conference{Rangel202436,
  author            = {Rangel, Julio C. and de Farias, Tarcisio Mendes and Sima, Ana Claudia and Kobayashi, Norio},
  title             = {SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {36 - 45},
  volume            = {3890},
  abstract          = {The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic”clues” in the queries, such as meaningful variable names and inline comments. Finally, we evaluate our approach over the real-world Bgee gene expression knowledge graph and we show that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graphs; Large Language Models; Question Answering; SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Gene expression; Knowledge graph; Structured Query Language; Fine tuning; Knowledge graphs; Language model; Large language model; Life-sciences; Natural language processing applications; Question Answering; Question answering systems; SPARQL; Training data; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214895238&partnerID=40&md5=eff3a35e1b7573c2785409cde4fb76f8},
}

@Conference{Huang202415787,
  author            = {Huang, Wenyu and Zhou, Guancheng and Wang, Hongru and Vougiouklis, Pavlos and Lapata, Mirella and Pan, Jeff Z.},
  title             = {Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA},
  year              = {2024},
  note              = {Cited by: 4},
  pages             = {15787 - 15803},
  abstract          = {Retrieval-Augmented Generation (RAG) is widely used to inject external non-parametric knowledge into large language models (LLMs). Recent works suggest that Knowledge Graphs (KGs) contain valuable external knowledge for LLMs. Retrieving information from KGs differs from extracting it from document sets. Most existing approaches seek to directly retrieve relevant subgraphs, thereby eliminating the need for extensive SPARQL annotations, traditionally required by semantic parsing methods. In this paper, we model the subgraph retrieval task as a conditional generation task handled by small language models. Specifically, we define a subgraph identifier as a sequence of relations, each represented as a special token stored in the language models. Our base generative subgraph retrieval model, consisting of only 220M parameters, achieves competitive retrieval performance compared to state-of-the-art models relying on 7B parameters, demonstrating that small language models are capable of performing the subgraph retrieval task. Furthermore, our largest 3B model, when plugged with an LLM reader, sets new SOTA end-to-end performance on both the WebQSP and CWQ benchmarks. Our model and data will be made available online: https://github.com/hwy9855/GSR. © 2024 Association for Computational Linguistics.},
  doi               = {10.18653/v1/2024.findings-emnlp.927},
  keywords          = {Benchmarking; Computational linguistics; Knowledge graph; Modeling languages; Online searching; Document sets; External knowledge; Knowledge graphs; Language model; Less is mores; Multi-hops; Nonparametrics; Parsing methods; Semantic parsing; Subgraphs; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214729630&doi=10.18653%2Fv1%2F2024.findings-emnlp.927&partnerID=40&md5=94912f3dd1e6e0b4870a3fd28edc6b9f},
}

@Conference{Meyer202435,
  author            = {Meyer, Lars Peter and Frey, Johannes and Brei, Felix and Arndt, Natanael},
  title             = {Assessing SPARQL Capabilities of Large Language Models},
  year              = {2024},
  note              = {Cited by: 3},
  pages             = {35 - 53},
  volume            = {3874},
  abstract          = {The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs) offers significant synergistic potential for knowledge-driven applications. One possible integration is the interpretation and generation of formal languages, such as those used in the Semantic Web, with SPARQL being a core technology for accessing KGs. In this paper, we focus on measuring out-of-the box capabilities of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries applying a quantitative approach. We implemented various benchmarking tasks in the LLM-KG-Bench framework for automated execution and evaluation with several LLMs. The tasks assess capabilities along the dimensions of syntax, semantic read, semantic create, and the role of knowledge graph prompt inclusion. With this new benchmarking tasks, we evaluated a selection of GPT, Gemini, and Claude models. Our findings indicate that working with SPARQL SELECT queries is still challenging for LLMs and heavily depends on the specific LLM as well as the complexity of the task. While fixing basic syntax errors seems to pose no problems for the best of the current LLMs evaluated, creating semantically correct SPARQL SELECT queries is difficult in several cases. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graph; LLM; LLM benchmarking; LLMs for Knowledge Graphs; RDF; SPARQL},
  file              = {:Meyer202435 - Assessing SPARQL Capabilities of Large Language Models.pdf:PDF:https\://arxiv.org/pdf/2409.05925v2;:Meyer202435 - Assessing SPARQL Capabilities of Large Language Models.pdf:PDF:https\://arxiv.org/pdf/2409.05925v2},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Benchmarking; Query languages; Semantics; Structured Query Language; Syntactics; Knowledge graphs; Language model; Large language model; Large language model benchmarking; Large language model for knowledge graph; Model benchmarking; RDF; SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214238211&partnerID=40&md5=a095b424bdc2ffe8fbeee2f16006d42e},
}

@Conference{2024,
  title             = {NLP4KGC 2024 - Proceedings of the 3rd International Workshop on Natural Language Processing for Knowledge Graph Creation, co-located with 20th International Conference on Semantic Systems, SEMANTiCS 2024},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3874},
  abstract          = {The proceedings contain 11 papers. The topics discussed include: on the pertinence of LLMs for ontology learning; towards the automation of knowledge graph construction using large language models; assessing SPARQL capabilities of large language models; breaking down financial news impact: a novel ai approach with geometric hypergraphs; ontology learning from text: an analysis on LLM performance; accessing the capabilities of KGs and LLMs in mapping indicators within sustainability reporting standards; converting fire safety regulations to SHACL shapes using natural language processing; ontology-based dataset discovery in the BUILDSPACE data management platform; pruning cycles in UMLS Metathesaurus: a neuro symbolic ai approach; and automated generation of competency questions using large language models and knowledge graphs.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214203615&partnerID=40&md5=dd68a799fc0ffdd80b02ba49c9de8999},
}

@Conference{Schiese2024267,
  author            = {Schiese, Dennis and Perevalov, Aleksandr and Both, Andreas},
  title             = {TOWARDS LLM-GENERATED EXPLANATIONS FOR COMPONENT-BASED KNOWLEDGE GRAPH QUESTION ANSWERING SYSTEMS},
  year              = {2024},
  note              = {Cited by: 1},
  pages             = {267 - 276},
  abstract          = {Over time, software systems have reached a level of complexity that makes it difficult for their developers and users to explain particular decisions made by them. In this paper, we focus on the explainability of component-based systems for Question Answering (QA). These components often conduct processes driven by AI methods, in which behavior and decisions cannot be clearly explained or justified, s.t., even for QA experts interpreting the executed process and its results is hard. To address this challenge, we present an approach that considers the components’ input and output data flows as a source for representing the behavior and provide explanations for the components, enabling users to comprehend what happened. In the QA framework used here, the data flows of the components are represented as SPARQL queries (inputs) and RDF triples (outputs). Hence, we are also providing valuable insights on verbalization regarding these data types. In our experiments, the approach generates explanations while following template-based settings (baseline) or via the use of Large Language Models (LLMs) with different configurations (automatic generation). Our evaluation shows that the explanations generated via LLMs achieve high quality and mostly outperform template-based approaches according to the users’ ratings. Therefore, it enables us to automatically explain the behavior and decisions of QA components to humans while using RDF and SPARQL as a context for explanations. © 2024 Proceedings of the International Conferences on Applied Computing and WWW/Internet 2024. All rights reserved.},
  author_keywords   = {Explainable AI; Knowledge Graphs; Large Language Models; Question Answering; RDF; SPARQL},
  keywords          = {Data flow graphs; Knowledge graph; Component based; Dataflow; Explainable AI; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; RDF; SPARQL; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214139110&partnerID=40&md5=30e9ddf31d473f9d2fb153d7d1c4839e},
}

@Conference{Wahid2024,
  author            = {Wahid, Abdul and Yahya, Muhammad and Zaman, Farooq and Zhou, Baifan and Breslin, John G. and Intizar, Muhammad Ali and Kharlamov, Evgeny},
  title             = {Integrating I4.0 Knowledge Graphs with Large Language Models Beyond SPARQL Endpoints},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3830},
  abstract          = {Industry 4.0 (I4.0) knowledge graphs are a common way to represent industrial information models. Conventional SPARQL querying systems require the users to be familiar with the data schema and SPARQL syntax. However, this is often very difficult for many users in industrial production, who have mostly an engineering background, instead of a semantic web. Recent developments in large language models (LLMs) make it possible for non-semantic experts to use natural language to query knowledge graphs (KG). In this work, we present a framework and preliminary results of integrating Industry 4.0 KGs with LLMs to improve how data is represented, reasoned, and processed in manufacturing contexts, facilitating user interaction with KGs and contributing to operational efficiency. Our technique enhances Language Models (LLMs) by utilising the semantic complexity and interdependence of Knowledge Graphs (KGs). This allows us to incorporate domain-specific knowledge. We used the FAISS library and LLaMA2 to optimise the storage and retrieval of vectors, which improved the system’s performance and scalability. This integration allows for advanced fault detection, proactive maintenance, and process optimisation, resulting in decreased periods of inactivity and improved productivity. We introduce the framework’s architecture, implementation strategy, and possible advantages while also discussing the difficulties associated with data integration and scalability. The results of our study show that the integration of KG-LLM surpasses traditional approaches in terms of operational efficiency, as evidenced by enhanced fault detection, proactive maintenance, and process optimisation, thereby opening up possibilities for the advancement of more intelligent and resilient production systems. © 2022 Copyright for this paper by its authors.},
  author_keywords   = {Deep Learning; Knowledge Graphs; Large Language Model (LLM); LLaMa; SPARQL},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Query languages; Scalability; Semantics; Structured Query Language; Deep learning; Faults detection; Knowledge graphs; Language model; Large language model; LLaMa; Operational efficiencies; Proactive maintenance; Proactive process; SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210885367&partnerID=40&md5=84f44fce68aee092a8964af6520465d5},
}

@Conference{2024,
  title             = {SOFLIM2KG-SEMIIM 2024 - Joint Proceedings of the 1st Software Lifecycle Management for Knowledge Graphs Workshop and the 3rd International Workshop on Semantic Industrial Information Modelling, co-located with 23th International Semantic Web Conference, ISWC 2024},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3830},
  abstract          = {The proceedings contain 7 papers. The topics discussed include: RDF-Connect: A declarative framework for streaming and cross-environment data processing pipelines; generating transparent and query-based RDF layers; vision of knowledge graph lifecycle management within hybrid artificial intelligence solutions; knowledge representation and engineering for smart diagnosis of cyber physical systems; SPARQL-based relaxed rules for learning over knowledge graphs; Integrating I4.0 knowledge graphs with large language models beyond SPARQL endpoints; and towards an ontology for procedural knowledge in Industry 5.0.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210832346&partnerID=40&md5=9d6432eea269e88e41d16c348919b682},
}

@Article{Lan20241157,
  author            = {Lan, Mingjing and Xia, Yi and Zhou, Gang and Huang, Ningbo and Li, Zhufeng and Wu, Hao},
  journal           = {Journal of Advances in Information Technology},
  title             = {LLM4QA: Leveraging Large Language Model for Efficient Knowledge Graph Reasoning with SPARQL Query},
  year              = {2024},
  note              = {Cited by: 13; All Open Access; Gold Open Access},
  number            = {10},
  pages             = {1157 - 1162},
  volume            = {15},
  abstract          = {As one of the core technologies of general artificial intelligence, knowledge graph reasoning aims to infer new knowledge from existing knowledge in the knowledge base, providing decision support for knowledge-driven intelligent information services such as information retrieval, question answering, and recommendation systems. However, there are still some issues, such as poor interpretability and low reasoning efficiency, always decrease the current knowledge reasoning performance. To tackle the challenges, this paper proposes a knowledge graph reasoning method LLM4QA, which leverages fine-tuned large language models with chain-of-thought to generate graph query languages SPARQL (i.e., SPARQL Protocol and RDF Query Language) for reasoning. Firstly, an efficient instruction fine-tuning method is applied to fine-tune open-source large language models with chain-of-thought. Then, the fine-tuned open-source large model is used to convert natural language questions into logical forms. Finally, we utilize unsupervised entity relationship retrieval to generate graph database query languages, real-izing a natural language knowledge graph question-answering framework. Experimental results demonstrate that this method achieves well performance in terms of inference accuracy and significantly improves model retrieval efficiency. © 2024 by the authors.},
  author_keywords   = {chain of thought; knowledge graph; Large Language Model (LLM); question answering system},
  doi               = {10.12720/jait.15.10.1157-1162},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Article},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208203144&doi=10.12720%2Fjait.15.10.1157-1162&partnerID=40&md5=c34dff7ae10e4e933fffea6cb6b44646},
}

@Conference{Reif2024,
  author            = {Reif, Jonathan T. and Jeleniewski, Tom and Gill, Milapji Singh and Gehlhoff, Felix and Fay, Alexander},
  title             = {Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards},
  year              = {2024},
  note              = {Cited by: 1},
  abstract          = {The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research. © 2024 IEEE.},
  author_keywords   = {Cyber-Physical Systems; Industry 4.0; Large Language Models; Ontologies; Semantic Web},
  doi               = {10.1109/ETFA61755.2024.10711065},
  journal           = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
  keywords          = {Ontology; Query languages; Semantics; Chatbots; Cybe-physical systems; Cyber-physical systems; Domain specific; Language model; Large language model; Natural languages; Ontology's; Query generation; Semantic-Web; Structured Query Language},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207845394&doi=10.1109%2FETFA61755.2024.10711065&partnerID=40&md5=6e55dc21dbf2c13a30448996fcb6cb63},
}

@Conference{Ŝváb-Zamazal2024,
  author            = {Ŝváb-Zamazal, Ondr̂ej Ř.Ej},
  title             = {Towards Pattern-based Complex Ontology Matching using SPARQL and LLM},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3759},
  abstract          = {Complex ontology matching is a process to match complex structures in ontologies.While many matching tools tackle simple ontology matching, complex ontology matching is still rare.However, one entity in one ontology can be similar to a complex structure (1-to-n) or even complex structures can be on both sides (m-to-n).Therefore, the application, e.g., data integration, must consider complex correspondences within ontology alignment.Our poster paper presents a pattern-based approach where particular SPARQL queries correspond to a specific pattern, e.g., Class by Attribute Type (CAT), for its detection.SPARQL queries are anchored to entities from simple correspondences on input.Detected complex correspondence candidates are verbalized to be validated by the Large Language Model (LLM).Further, we provide a zero-shot prompting preliminary experiment and evaluation.The poster paper is equipped with the Jupyter notebook for automation of the pipeline and the full report of the experiment at: https://github.com/OndrejZamazal/ComplexOntologyMatching-SEMANTiCS2024. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {Complex Ontology Matching; Knowledge Graph; Large Language Model; Ontology; Ontology Matching},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Knowledge graph; Modeling languages; Ontology; Structured Query Language; Complex correspondences; Complex ontology matching; Complexes structure; Knowledge graphs; Language model; Large language model; Ontology matching; Ontology's; Simple++; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204733796&partnerID=40&md5=5f38b3109696be1d51c0bc9e2ef0d2c3},
}

@Conference{Piao2024,
  author            = {Piao, Guangyuan and Mountantonakis, Michalis and Papadakos, Panagiotis and Sonawane, Pournima and Mahony, Aidan O.},
  title             = {Toward Exploring Knowledge Graphs with LLMs},
  year              = {2024},
  note              = {Cited by: 1},
  volume            = {3759},
  abstract          = {Interacting with knowledge graphs (KGs) is challenging for non-technical users with information needs who are unfamiliar with KG-specific query languages such as SPARQL and the underlying KG schema.Previous KG question answering systems require ground-truth pairs of questions and queries or fine tuning (Large) Language Models (LLMs) for a specific KG, which is time-consuming and demands deep expertise.In this poster, we present a framework for exploring KGs for question answering using LLMs in a zero-shot setting for non-technical end users, without the need for ground-truth pairs of questions and queries or fine-tuning LLMs.Additionally, we evaluate an example implementation in a simple yet challenging setting using LLMs exclusively based on the framework, without the extra effort of maintaining the embeddings or indexes of entities from KG for retrieving relevant ones to a given question.We share preliminary experimental results indicating that exploring a KG using LLM-generated SPARQL queries with reasonable complexity is possible in such a challenging setting. © 2022 Copyright for this paper by its authors.},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Modeling languages; Query languages; Question answering; Structured Query Language; End-users; Fine tuning; Ground truth; Knowledge graphs; Language model; Non-technical users; Question Answering; Question answering systems; Simple++; Specific knowledge; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204692476&partnerID=40&md5=4367f805d3a6eeb92ce9a1c69435a842},
}

@Conference{2024,
  title             = {SEMANTiCS-PDWT 2024 - Joint Proceedings of Posters, Demos, Workshops, and Tutorials of the 20th International Conference on Semantic Systems, co-located with 20th International Conference on Semantic Systems, SEMANTiCS 2024},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3759},
  abstract          = {The proceedings contain 31 papers. The topics discussed include: facilitating learning analytics in histology courses with knowledge graphs; 8-star linked open data model: extending the 5-star model for better reuse, quality, and trust of data; continuous knowledge graph quality assessment through comparison using ABECTO; ORKG ASK: a neuro-symbolic scholarly search and exploration system; towards pattern-based complex ontology matching using SPARQL and LLM; data-sovereign enterprise collaboration using the solid protocol; the Helmholtz digitization ontology: representing digital assets in the Helmholtz digital ecosystem; and facilitating search of the virtual record treasury of Ireland knowledge graph using ChatGPT.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204683099&partnerID=40&md5=966a950f145c2afc591f922a8de34ec7},
}

@Conference{Shah2024125,
  author            = {Shah, Mili and Cahoon, Joyce Y. and Milletari, Mirco and Tian, Jing and Psallidas, Fotis and Mueller, Andreas and Litombe, Nicholas E.},
  title             = {Improving LLM-based KGQA for multi-hop Question Answering with implicit reasoning in few-shot examples},
  year              = {2024},
  note              = {Cited by: 2},
  pages             = {125 - 135},
  abstract          = {Large language models (LLMs) have shown remarkable capabilities in generating natural language texts for various tasks. However, using LLMs for question answering on knowledge graphs still remains a challenge, especially for questions requiring multi-hop reasoning. In this paper, we present a novel planned query guidance approach that improves large language model (LLM) performance in multi-hop question answering on knowledge graphs (KGQA). We do this by designing few-shot examples that implicitly demonstrate a systematic reasoning methodology to answer multi-hop questions. We evaluate our approach for two graph query languages, Cypher and SPARQL, and show that the queries generated using our strategy outperform the queries generated using a baseline LLM and typical few-shot examples by up to 24.66% and 7.7% in execution match accuracy for the MetaQA and the Spider benchmarks respectively. We also conduct an ablation study to analyze the incremental effects of the different techniques of designing few-shot examples. Our results suggest that our approach enables the LLM to effectively leverage the few-shot examples to generate queries for multi-hop KGQA. ©2024 Association for Computational Linguistics.},
  file              = {:Shah2024125 - Improving LLM Based KGQA for Multi Hop Question Answering with Implicit Reasoning in Few Shot Examples.pdf:PDF:https\://aclanthology.org/2024.kallm-1.13.pdf;:Shah2024125 - Improving LLM Based KGQA for Multi Hop Question Answering with Implicit Reasoning in Few Shot Examples.pdf:PDF:https\://aclanthology.org/2024.kallm-1.13.pdf},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  keywords          = {Benchmarking; Computational linguistics; Knowledge graph; Modeling languages; Natural language processing systems; Query languages; Query processing; Structured Query Language; Graph query language; Knowledge graphs; Language model; Model-based OPC; Modeling performance; Multi-hops; Natural languages texts; Question Answering; Two-graphs; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204490189&partnerID=40&md5=97b2ea49f05c354246701e26d8c61462},
}

@Conference{Agarwal202410119,
  author            = {Agarwal, Prerna and Kumar, Nishant and Bedathur, Srikanta J.},
  title             = {SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution},
  year              = {2024},
  note              = {Cited by: 4},
  pages             = {10119 - 10140},
  volume            = {1},
  abstract          = {Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent advances in the capabilities of Large Language Models (LLMs) has led towards generating low-level LFs such as SPARQL and S-Expression in a few-shot setting. Unfortunately, these methods: (1) are limited to the knowledge of underlying LLM about the LF, (2) performs inferior for the harder complex benchmarks such as KQA Pro, (3) suffers while grounding the generated LF to a specific Knowledge Graph. Recently, a new LF called KoPL (Cao et al., 2022a) has been introduced that explicitly models complex reasoning process step-by-step in a symbolic manner and has shown SOTA on KQA Pro in fully-supervised setting. Inspired by this, we propose SymKGQA framework that generates step-by-step Symbolic LF i.e., KoPL in a few-shot in-context learning setting using LLM. Our framework is not dependent on pre-trained knowledge of LLM about KoPL. We further build a Retrieval-Augmented Generation based Question-Aware Contextual KoPL (QUACK) resolver to ground the generated LF. Our experiments with different LLMs and few-shot settings demonstrate that SymKGQA outperforms all other few-shot and even many of the fully-supervised KGQA approaches. © 2024 Association for Computational Linguistics.},
  doi               = {10.18653/v1/2024.acl-long.545},
  file              = {:Agarwal202410119 - SymKGQA_ Few Shot Knowledge Graph Question Answering Via Symbolic Program Generation and Execution.pdf:PDF:https\://aclanthology.org/2024.acl-long.545.pdf;:Agarwal202410119 - SymKGQA_ Few Shot Knowledge Graph Question Answering Via Symbolic Program Generation and Execution.pdf:PDF:https\://aclanthology.org/2024.acl-long.545.pdf},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  keywords          = {Benchmarking; Computational linguistics; Natural language processing systems; Semantics; Zero-shot learning; Executables; Knowledge graphs; Language model; Logical forms; Natural language questions; Program execution; Program generation; Question Answering; Semantic parsing; State-of-the-art performance; Knowledge graph},
  publication_stage = {Final},
  ranking           = {rank3},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481424&doi=10.18653%2Fv1%2F2024.acl-long.545&partnerID=40&md5=93c4e7a0f459385882f7290cf2fe0245},
}

@Conference{Dobriy202418,
  author            = {Dobriy, Daniil},
  title             = {Employing RAG to Create a Conference Knowledge Graph from Text},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {18},
  volume            = {3747},
  abstract          = {In this paper, we present Semantic Observer, a platform that 1) defines a FAIR Conference Ontology for describing academic conferences, 2) presents an RAG architecture that constructs a Conference Knowledge Graph based on this ontology, 3) evaluates the architecture on a corpus of latest available CORE conference websites. The Conference Ontology models key entities such as conferences, workshops and challenges, organizer and programme committees, calls for papers and proposals as well as major deadlines and relevant topics. In the evaluation, we compare the performance of three leading Large Language Models: GPT-4 Turbo and Claude 3 Opus - in supporting the Knowledge Graph construction from text. The best-performing RAG architecture is then implemented in Semantic Observer and available in a SPARQL endpoint to make up-to-date conference information FAIR: findable, accessible, interoperable and reusable. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {Knowledge Graph; Ontology Engineering; Research Ecosystem; Retrieval-Augmented Generation; Semantic Web; Web Crawling},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Engineering research; Interoperability; Latent semantic analysis; Ontology; Reusability; Semantics; Web crawler; Academic conferences; Graph-based; Knowledge graphs; Ontology engineering; Ontology model; Ontology's; Research ecosystem; Retrieval-augmented generation; Semantic-Web; Web Crawling; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203317673&partnerID=40&md5=16e9ffb1be06509864b372b91808c489},
}

@Conference{Perevalov202414,
  author            = {Perevalov, Aleksandr and Both, Andreas},
  title             = {Towards LLM-driven Natural Language Generation based on SPARQL Queries and RDF Knowledge Graphs},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {14},
  volume            = {3747},
  abstract          = {Generating natural language based on structured data has been utilized in many use cases such as data augmentation, explainability, and education. In particular, when speaking about Knowledge Graphs, one may generate natural language representation of triples (i.e., facts) or “verbalize” SPARQL queries. The latter can be treated as a reverse semantic parsing task and, for instance, can be used by non-experts to better understand the meaning of SPARQL queries, and conduct data augmentation for question answering benchmarking datasets. In this paper, we make a first attempt to utilize Large Language Models for verbalizing SPARQL queries, i.e., converting them to natural language. The experimental setup uses both commercial and open-source models and benefits from multiple prompting techniques. We evaluate our approach on the well-known question answering datasets QALD-9-plus and QALD-10 while working with three languages: English, German, and Russian. For measuring the quality, we use machine translation metrics and human evaluation (survey) together. Even though we have observed such error classes as question overspecification, language and semantic mismatch, the results of this work suggest that Large Language Models (LLMs) are a good fit for the task of converting SPARQL queries to natural language. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {Large Language Models; RDF2NL; SPARQL to Natural Language; SPARQL verbalization; Text Generation},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Benchmarking; Large datasets; Natural language processing systems; Query languages; Semantics; Structured Query Language; Translation (languages); Data augmentation; Knowledge graphs; Language model; Large language model; Natural languages; Question Answering; RDF2NL; SPARQL to natural language; SPARQL verbalization; Text generations; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203316381&partnerID=40&md5=61ac7b9397feeb9b0e5729c12ad4c604},
}

@Conference{Zhao202451,
  author            = {Zhao, Wenting and Liu, Ye and Niu, Tong and Wan, Yao and Yu, Philip S. and Joty, Shafiq Rayhan and Zhou, Yingbo and Yavuz, Semih},
  title             = {DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text},
  year              = {2024},
  note              = {Cited by: 2},
  pages             = {51 - 68},
  abstract          = {Large Language Models (LLMs) excel in generating text but struggle with hallucinations, particularly for uncommon queries, due to reliance on internal knowledge. Retrieval-augmented models address this by integrating external knowledge, enhancing accuracy. Nonetheless, recent approaches have primarily emphasized retrieval from unstructured text corpora, owing to its seamless integration into prompts. When using structured data such as knowledge graphs, most methods simplify it into natural text, neglecting the underlying structures. Moreover, a significant gap in the current landscape is the absence of a realistic benchmark for evaluating the effectiveness of grounding LLMs on heterogeneous knowledge sources (e.g., knowledge base and text). To fill this gap, we have curated a comprehensive dataset that poses two unique challenges: (1) Two-hop multi-source questions that require retrieving information from both open-domain structured and unstructured knowledge sources; retrieving information from structured knowledge sources is a critical component in correctly answering the questions. (2) Generation of symbolic queries (e.g., SPARQL for Wikidata) is a key requirement, which adds another layer of challenge. Our dataset is created using a combination of automatic generation through predefined reasoning chains and human annotation. We also introduce a novel approach that leverages multiple retrieval tools, including text passage retrieval and symbolic language-assisted retrieval. Our model outperforms previous approaches by a significant margin, demonstrating its effectiveness in addressing the above-mentioned reasoning challenges. © 2024 Association for Computational Linguistics.},
  doi               = {10.18653/v1/2024.findings-naacl.5},
  keywords          = {Computational linguistics; Natural language processing systems; Excel; External knowledge; Knowledge graphs; Knowledge sources; Language model; Open domain question answering; Reasoning ability; Seamless integration; Structured data; Unstructured text corpus; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197851513&doi=10.18653%2Fv1%2F2024.findings-naacl.5&partnerID=40&md5=e6dc3ce1a55905c0600b963d1618504b},
}

@Article{Perevalov20243,
  author            = {Perevalov, Aleksandr and Gashkov, Aleksandr and Eltsova, Maria and Both, Andreas},
  journal           = {Lecture Notes in Computer Science},
  title             = {Language Models as SPARQL Query Filtering for Improving the Quality of Multilingual Question Answering over Knowledge Graphs},
  year              = {2024},
  note              = {Cited by: 2},
  pages             = {3 - 18},
  volume            = {14629 LNCS},
  abstract          = {Question Answering systems working over Knowledge Graphs (KGQA) generate a ranked list of SPARQL query candidates for a given natural-language question. In this paper, we follow our long-term research agenda of providing trustworthy KGQA systems – here – by presenting a query filtering approach that utilizes (large) language models (LMs/LLMs), s.t., correct and incorrect queries can be distinguished. In contrast to the previous work, we address here multilingual questions represented in major languages (English, German, French, Spanish, and Russian), and confirm the generalizability of our approach by also evaluating it on low-resource languages (Ukrainian, Armenian, Lithuanian, Belarusian, and Bashkir). For our experiments, we used the following LMs: BERT, DistilBERT, Mistral, Zephyr, GPT-3.5, and GPT-4. The LMs were applied to the KGQA systems – QAnswer and MemQA – as SPARQL query filters. The approach was evaluated on the multilingual Wikidata-based dataset QALD-9-plus. The experimental results suggest that the KGQA systems achieve quality improvements for all languages when using our query-filtering approach. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
  author_keywords   = {Query Candidate Filtering; Query Validation; Question Answering over Knowledge Graphs; Trustworthiness},
  doi               = {10.1007/978-3-031-62362-2_1},
  keywords          = {Computational linguistics; Natural language processing systems; Query processing; Knowledge graphs; Language model; Natural language questions; Query candidate filtering; Query validation; Question Answering; Question answering over knowledge graph; Question answering systems; Research agenda; Trustworthiness; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197764253&doi=10.1007%2F978-3-031-62362-2_1&partnerID=40&md5=dcd8421f967390991b748ffb3e971218},
}

@Article{Zimina202419,
  author            = {Zimina, Elizaveta and Jarvelin, Kalervo and Peltonen, Jaakko and Ranta, Aarne and Nummenmaa, Jyrki},
  journal           = {Lecture Notes in Computer Science},
  title             = {TraQuLA: Transparent Question Answering Over RDF Through Linguistic Analysis},
  year              = {2024},
  note              = {Cited by: 1},
  pages             = {19 - 33},
  volume            = {14629 LNCS},
  abstract          = {Answering complex questions over knowledge graphs has gained popularity recently. Systems based on large language models seem to achieve top performance. However, these models may generate content that looks reasonable but is incorrect. They also lack transparency, making it impossible to exactly explain why a particular answer was generated. To tackle these problems we present the TraQuLA (Transparent QUestion-answering through Linguistic Analysis) system – a rule-based system developed through linguistic analysis of datasets of complex questions over DBpedia and Wikidata. TraQuLA defines a question’s type and extracts its semantic component candidates (named entities, properties and class names). For the extraction of properties, whose natural language verbalisations are most diverse, we built an extensive database which matches DBpedia/Wikidata properties to natural language expressions, allowing linguistic variation. TraQuLA generates semantic parses for the components and ranks them by each question’s structure and morphological features. The ranked parses are then analysed top down according to their patterns, also noting linguistic aspects, until a solution is found and a SPARQL query is produced. TraQuLA outperforms the existing baseline systems on the LC-QuAD 1.0 and competes with ChatGPT-based systems on LC-QuAD 2.0. For the LC-QuAD 1.0 test set, we developed an evaluation approach that accepts multiple ways to answer the questions (some ignored by the dataset) and curated some errors. TraQuLa contains no “black boxes” of neural networks or machine learning and makes its answer construction traceable. Users can therefore better rely on them and assess their correctness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
  author_keywords   = {Linguistic analysis; Question-answering; RDF; Rule-based},
  doi               = {10.1007/978-3-031-62362-2_2},
  keywords          = {Complex networks; Knowledge graph; Natural language processing systems; Query processing; Resource Description Framework (RDF); Statistical tests; Complex questions; Dbpedia; Knowledge graphs; Language model; Linguistic analysis; Performance; Property; Question Answering; RDF; Rule based; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197756950&doi=10.1007%2F978-3-031-62362-2_2&partnerID=40&md5=375cebaec02dd2f0118bbe9f3dfd6e77},
}

@Conference{VieiradaSilva2024,
  author            = {Vieira da Silva, Luis Miguel and Köcher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
  title             = {On the Use of Large Language Models to Generate Capability Ontologies},
  year              = {2024},
  note              = {Cited by: 7},
  abstract          = {Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such onto-logical models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors. © 2024 IEEE.},
  author_keywords   = {Capabilities; Large Language Models; LLMs; Model-Generation; Ontologies; Semantic Web; Skills},
  doi               = {10.1109/ETFA61755.2024.10710775},
  file              = {:VieiradaSilva2024 - On the Use of Large Language Models to Generate Capability Ontologies.pdf:PDF:https\://arxiv.org/pdf/2404.17524v4;:VieiradaSilva2024 - On the Use of Large Language Models to Generate Capability Ontologies.pdf:PDF:https\://arxiv.org/pdf/2404.17524v4},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  journal           = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
  keywords          = {Computational linguistics; Natural language processing systems; Ontology; Capability; Language model; Large language model; Logical models; Model generation; Ontology's; Semantic-Web; Skill; Semantics},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197107836&doi=10.1109%2FETFA61755.2024.10710775&partnerID=40&md5=544ef7ed4c7c396646d5da759dd60db8},
}

@Conference{Meem202413129,
  author            = {Meem, Jannat Ara and Rashid, Muhammad Shihab and Dong, Yue and Hristidis, Vagelis},
  title             = {PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering},
  year              = {2024},
  note              = {Cited by: 6},
  pages             = {13129 - 13148},
  abstract          = {Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. 'Who was the US president in 1970?'). Little work has studied questions whose temporal context is relative to the present time (e.g. 'Who was the previous US president?'). We refer to this problem as Present-Anchored Temporal QA (PATQA). PATQA poses unique challenges: (1) large language models (LLMs) may have outdated knowledge, (2) complex temporal relationships (e.g. 'before', 'previous') are hard to reason, (3) multi-hop reasoning may be required, and (4) the gold answers of benchmarks must be continuously updated. To address these challenges, we introduce the PAT-Questions benchmark, which includes single and multi-hop temporal questions. The answers in PAT-Questions can be automatically refreshed by re-running SPARQL queries on a knowledge graph, if available. We evaluate several state-of-the-art LLMs and a SOTA temporal reasoning model (TEMPREASON-T5) on PAT-Questions through direct prompting and retrieval-augmented generation (RAG). The results highlight the limitations of existing solutions in PATQA and motivate the need for new methods to improve PATQA reasoning capabilities. © 2024 Association for Computational Linguistics.},
  doi               = {10.18653/v1/2024.findings-acl.777},
  journal           = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  keywords          = {Benchmarking; Computational linguistics; Problem oriented languages; Spatio-temporal data; Complex temporal relationships; Knowledge graphs; Language model; Multi-hops; Question Answering; Self-updating; Single hop; State of the art; Temporal questions; Time-stamp; Question answering},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196959448&doi=10.18653%2Fv1%2F2024.findings-acl.777&partnerID=40&md5=d805a0298fdac5ff9222807579ad7dba},
}

@Article{Yuan202475,
  author            = {Yuan, Jicheng and Le-Tuan, Anh and Nguyen-Duc, Manh and Tran, Trung Kien and Hauswirth, Manfred and Le-Phuoc, Danh},
  journal           = {Lecture Notes in Computer Science},
  title             = {VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph},
  year              = {2024},
  note              = {Cited by: 3; All Open Access; Hybrid Gold Open Access},
  pages             = {75 - 93},
  volume            = {14665 LNCS},
  abstract          = {The availability of vast amounts of visual data with diverse and fruitful features is a key factor for developing, verifying, and benchmarking advanced computer vision (CV) algorithms and architectures. Most visual datasets are created and curated for specific tasks or with limited data distribution for very specific fields of interest, and there is no unified approach to manage and access them across diverse sources, tasks, and taxonomies. This not only creates unnecessary overheads when building robust visual recognition systems, but also introduces biases into learning systems and limits the capabilities of data-centric AI. To address these problems, we propose the VisionKnowledge Graph (VisionKG), a novel resource that interlinks, organizes and manages visual datasets via knowledge graphs and Semantic Web technologies. It can serve as a unified framework facilitating simple access and querying of state-of-the-art visual datasets, regardless of their heterogeneous formats and taxonomies. One of the key differences between our approach and existing methods is that VisionKG is not only based on metadata but also utilizes a unified data schema and external knowledge bases to integrate, interlink, and align visual datasets. It enhances the enrichment of the semantic descriptions and interpretation at both image and instance levels and offers data retrieval and exploratory services via SPARQL and natural language empowered by Large Language Models (LLMs). VisionKG currently contains 617 million RDF triples that describe approximately 61 million entities, which can be accessed at https://vision.semkg.org and through APIs. With the integration of 37 datasets and four popular computer vision tasks, we demonstrate its usefulness across various scenarios when working with computer vision pipelines. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
  author_keywords   = {Computer Vision; Knowledge Graph; Linked Data; Ontology; RDF},
  doi               = {10.1007/978-3-031-60635-9_5},
  keywords          = {Computer vision; HTTP; Image enhancement; Knowledge graph; Learning systems; Resource Description Framework (RDF); Taxonomies; Computer vision algorithms; Computer vision architectures; Key factors; Knowledge graphs; Linked datum; Ontology's; Power; RDF; Specific tasks; Visual data; Linked data},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195295743&doi=10.1007%2F978-3-031-60635-9_5&partnerID=40&md5=eab58926055b88a002fdb11a494dccd6},
}

@Article{MinhLe2024284,
  author            = {Minh Le, Nguyen and Khang, Le Nguyen and Anh, Kieu Que and Hien, Nguyen Dieu and Nagai, Yukari},
  journal           = {Lecture Notes in Computer Science},
  title             = {Semantic Parsing for Question and Answering over Scholarly Knowledge Graph with Large Language Models},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {284 - 298},
  volume            = {14741 LNAI},
  abstract          = {This paper presents a study to answer the question of how to map a natural language (NL) sentence to a semantic representation and its application to question answering over the DBLP database. We investigate the deep learning approach using pre-trained models and their fine-tuning on training data for semantic parsing tasks. Experimental results on standard datasets show the effectiveness of pre-trained models in mapping an NL sentence to SPARQL, a query language for semantic databases. The results also show that the T5 and Flan-T5 models outperform other models in terms of translation accuracy. In addition to the empirical results on pre-trained models, we also consider the problem of examining large language models (LLMs) such as Llama and Mistras, or Qwen models for answering questions on the DBLP database. Experimental results showed the potentiality of using LLMs with chain-of-thought prompting methods. The results indicated that without using training data, we were able to obtain promising results for some types of questions when translating them to SPARQL. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
  author_keywords   = {Knowledge Graph; Mapping NL to SPARQL; Question Answering; Relation search; Semantic parsing; Semantic Representation},
  doi               = {10.1007/978-981-97-3076-6_20},
  groups            = {Reports not retrieved, Reports sought for retrieval},
  keywords          = {Computational linguistics; Deep learning; Knowledge graph; Mapping; Natural language processing systems; Query languages; Semantic Web; Semantics; Syntactics; Translation (languages); ITS applications; Knowledge graphs; Language model; Mapping natural language to SPARQL; Natural languages; Question Answering; Relation search; Semantic parsing; Semantic representation; Training data; Query processing},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195286062&doi=10.1007%2F978-981-97-3076-6_20&partnerID=40&md5=3af015615d0f1a1acda79ba02462a122},
}

@Conference{Pertsas202484,
  author            = {Pertsas, Vayianos and Kasapaki, Marialena and Constantopoulos, Panos},
  title             = {An Annotated Dataset for Transformer-based Scholarly Information Extraction and Linguistic Linked Data Generation},
  year              = {2024},
  note              = {Cited by: 1},
  pages             = {84 - 93},
  abstract          = {We present a manually curated and annotated, multidisciplinary dataset of 15,262 sentences from research articles (abstract and main text) that can be used for transformer-based extraction from scholarly publications of three types of entities: 1) research methods, named entities of variable length, 2) research goals, entities that appear as textual spans of variable length with mostly fixed lexico-syntactic-structure, and 3) research activities, entities that appear as textual spans of variable length with complex lexico-syntactic structure. We explore the capabilities of our dataset by using it for training/fine-tuning various ML and transformer-based models. We compare our finetuned models as well as LLM responses (chat-GPT 3.5) based on 10-shot learning, by measuring F1 scores in token-based, entity-based strict and entity-based partial evaluations across interdisciplinary and discipline-specific datasets in order to capture any possible differences in discipline-oriented writing styles. Results show that fine tuning of transformer-based models significantly outperforms the performance of few-shot learning of LLMs such as chat-GPT, highlighting the significance of annotation datasets in such tasks. Our dataset can also be used as a source for linguistic linked data by itself. We demonstrate this by presenting indicative queries in SPARQL, executed over such an RDF knowledge graph. © 2024 ELRA Language Resource Association.},
  author_keywords   = {Information Extraction from Text; Linguistic Linked Data; RDF Knowledge Graph; Scholarly Annotation Corpus; Transformer-based Information Extraction},
  keywords          = {Abstracting; Data handling; Data mining; Information retrieval; Knowledge graph; Learning systems; Natural language processing systems; Resource Description Framework (RDF); Syntactics; Fine tuning; Information extraction from text; Knowledge graphs; Linguistic linked data; Linked datum; RDF knowledge graph; Scholarly annotation corpus; Syntactic structure; Transformer-based information extraction; Variable length; Linked data},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195174004&partnerID=40&md5=5d136eb016cc4bb370972d511703c02c},
}

@Conference{Ogawa2024294,
  author            = {Ogawa, Tomohiro and Yoshioka, Kango and Fukuda, Ken and Morita, Takeshi},
  title             = {Prediction of actions and places by the time series recognition from images with Multimodal LLM},
  year              = {2024},
  note              = {Cited by: 3},
  pages             = {294 - 300},
  abstract          = {In recent years, the risk of accidents in the homes of older adults in an aging society has increased, and there is a need to address this problem. We took up the challenge of utilising explainable AI techniques to identify accident risks at home and suggest safer alternatives. This study combined knowledge graphs and large-scale language models to solve real-world problems. Specifically, we addressed answering questions using a multimodal dataset of videos recording daily activities and a knowledge graph. The dataset represents the living activities in the virtual space and provides environmental information. The task is divided into two main tasks. Task 1 utilises knowledge graph to answer direct questions and processes the data using SPARQL queries. Task 2 addresses more complex questions that cannot be answered by search alone. Consequently, in Task 1, the system could answer all questions using information from the SPARQL knowledge graph. In Task 2, a certain degree of success was achieved for complex questions by reasoning with images created by concatenating multimodal LLMs and time-series images. The source code used in the experiment is available at https://github.com/tomo1115tomo/kg_reasoning_challenge. © 2024 IEEE.},
  author_keywords   = {Knowledge Graph Reasoning Challenge},
  doi               = {10.1109/ICSC59802.2024.00053},
  journal           = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
  keywords          = {Accidents; Query processing; Time series; Accident risks; Aging societies; AI techniques; Complex questions; Knowledge graph reasoning challenge; Knowledge graphs; Multi-modal; Older adults; Risk of accidents; Time series recognition; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192266625&doi=10.1109%2FICSC59802.2024.00053&partnerID=40&md5=d80941afb5eac1cc5361033242d9cd7a},
}

@Conference{Avila2024277,
  author            = {Avila, Caio Viktor S. and Vidal, Vânia Maria Ponte and Franco, Wellington and Casanova, Marco Antonio},
  title             = {Experiments with text-to-SPARQL based on ChatGPT},
  year              = {2024},
  note              = {Cited by: 23},
  pages             = {277 - 284},
  abstract          = {Currently, large language models (LLMs) are the state of the art for pre-trained language models. LLMs have been applied to many tasks, including question and answering over Knowledge Graphs (KGs) and text-to-SPARQL, that is, the translation of Natural Language questions to SPARQL queries. With such motivation, this paper first describes preliminary experiments to evaluate the ability of ChatGPT to answer NL questions over KGs. Based on these experiments, the paper introduces Auto-KGQAGPT, an autonomous domain-independent framework based on LLMs for text-to-SPARQL. The framework selects fragments of the KG, which the LLM uses to translate the user's NL question to a SPARQL query on the KG. Finally, the paper describes preliminary experiments with Auto-KGQAGPT with ChatGPT that indicate that the framework substantially reduced the number of tokens passed to ChatGPT without sacrificing performance. © 2024 IEEE.},
  author_keywords   = {ChatGPT; Knowledge Graph; LLM; text-to-SPARQL},
  doi               = {10.1109/ICSC59802.2024.00050},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  journal           = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
  keywords          = {Computational linguistics; Natural language processing systems; Query processing; Translation (languages); Autonomous domains; ChatGPT; Domain independents; Graph-based; Knowledge graphs; Language model; Large language model; Natural language questions; State of the art; Text-to-SPARQL; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192238824&doi=10.1109%2FICSC59802.2024.00050&partnerID=40&md5=b8809dbaca2fa8eeffd44af0b66f48ff},
}

@Conference{Soularidis20247,
  author            = {Soularidis, Andreas and Kotis, Konstantinos I. and Lamolle, Myriam and Mejdoul, Zakaria and Lortal, Gaëlle and Vouros, George A.},
  title             = {LLM-Assisted Generation of SWRL Rules from Natural Language},
  year              = {2024},
  note              = {Cited by: 0},
  pages             = {7 - 12},
  abstract          = {Recently, Large Language Models (LLMs) have attracted great attention due to their remarkable performance in human-like text generation and reasoning skills (although their memory and hallucination problems still remain key issues to tackle more efficiently). LLMs have been applied to various application domains, including Knowledge Graph (KG) generation, question and answering over KGs and text-to-SPARQL translation. In this work, we investigate the capabilities of LLMs in text-to-SWRL translation, i.e., translation of Natural Language (NL) rules into Semantic Web Rule Language (SWRL) rules, put in the context of an industrial Ontology Engineering (OE) environment called GLUON, presenting our first experimental results. The aim of this work is to identify the level of automation that is adequate for the LLM to generate well-formed SWRL rules, towards the development of an LLM-based framework, as a plugin to the GLUON OE environment. In this direction we leverage and combine the reasoning capabilities of GPT-4o model, the Retrieval-Augmented Generation (RAG) technology, and prompt engineering. We employ quantitative and qualitative metrics to evaluate the generated SWRL rules, focusing on the correct syntax and the level of human intervention. © 2024 IEEE.},
  author_keywords   = {Large Language Models (LLM); Ontology Engineering; Retrieval-Augmented Generation (RAG); SWRL},
  doi               = {10.1109/AIxDKE63520.2024.00008},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  keywords          = {Computational linguistics; Knowledge management; Natural language processing systems; Translation (languages); Engineering environment; Language model; Large language model; Natural languages; Ontology engineering; Performance; Retrieval-augmented generation; Rules languages; Semantic web rule language; Semantic Web rules; Ontology},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498105&doi=10.1109%2FAIxDKE63520.2024.00008&partnerID=40&md5=5e63e58a9654eba4991ac8cb40693cc7},
}

@Conference{Rasheed2024,
  author            = {Rasheed, Mohammed H. and Aguado, Marina},
  title             = {LLM Based Chatbot to Find Railway Topology and Rail Vehicle Information in Europe},
  year              = {2024},
  note              = {Cited by: 0},
  volume            = {3967},
  abstract          = {The Interoperable Europe Act came into effect in April this year. Semantic interoperability as a key element can ensure cross-border interoperability between various public services such as rail and transport services. This demo introduces a chatbot engine that employs Large Language Model (LLM) to facilitate human interaction with domain-specific Knowledge Graphs (KG) governed by the European Union Agency for Railways. The chatbot engine facilitates domain-specific SPARQL query generation based on natural language query, thereby providing an intuitive interface for non-expert users to retrieve in-domain knowledge. In contrast, our chatbot automated query generation allows domain experts to directly query triple data stores more intuitively and without intermediaries, contributing to improving the quality of hosted information. The chatbot engine uses a zero-shot prompting approach by taking the user's natural language query as an input and translates into SPARQL query to retrieve factual knowledge from the target KG. To improve the quality of the generated SPARQL query and thus improve the relevancy of results corresponding to the user question, the LLM is supported with in-domain knowledge by injecting extracted KG vocabulary information along with the user natural language question as an input. The experiments conducted on twenty in-domain competency questions revealed that leveraging LLM is a promising approach and can be efficiently oriented to be utilized in domain-specific KGs to increase productivity, reduce query construction time and increase usability by allowing non-technical users to obtain knowledge intuitively. Furthermore, the chatbot offers a very fine feature inherited from LLMs, which is the ability to answer multilingual queries, allowing it's utilization among a wide range of users regardless of any language boundaries which ultimately contributes to the cross-border interoperability of public services in countries using different languages. © 2024 Copyright for this paper by its authors.},
  author_keywords   = {KGQA; Large Language Models; Prompt Engineering; RDF; SPARQL},
  groups            = {Reports assessed for eligibility. 30-50, Included in Review, Reports sought for retrieval},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {International cooperation; Interoperability; Query languages; Subways; Chatbots; Cross-border; KGQA; Knowledge graphs; Language model; Large language model; Prompt engineering; Public services; RDF; SPARQL; Railroad transportation},
  publication_stage = {Final},
  ranking           = {rank5},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006925624&partnerID=40&md5=e5919e7782af4332d07391aab9a54714},
}

@Conference{Ongris202444,
  author            = {Ongris, Jaycent Gunawan and Tjitrahardja, Eduardus and Darari, Fariz and Ekaputra, Fajar J.},
  title             = {Towards an Open NLI LLM-based System for KGs: A Case Study of Wikidata},
  year              = {2024},
  note              = {Cited by: 2},
  pages             = {44 - 49},
  abstract          = {The rise of large language models (LLMs) has significantly advanced information retrieval, yet challenges like the limitation of knowledge updating ability, lack of openness, and hallucination issues persist. To address these, Retrieval-Augmented Generation (RAG) has been introduced but remains limited in interpretability due to its reliance on vector-based representations. This paper presents a question-answering (QA) system using GraphRAG, a RAG system with knowledge graphs (KGs) as its base. We develop a natural language interface (NLI) for QA over Wikidata, a popular, open, and crowdsourced KG. Our approach employs LLM chaining, i.e., a paradigm that leverages multiple LLM calls sequentially, to generate SPARQL queries, with the aim of creating an open system that ensures transparency and allows direct inspection of its components. Utilizing an experimental research approach, we evaluated the generated SPARQL queries and found that incorporating a broader set of property candidates into the prompts significantly boosts performance, achieving a Jaccard similarity score of 0.7806. These findings demonstrate the system's effectiveness in SPARQL query generation, highlighting its potential for further development. However, we consider the limitation of the LLM's context window and the hallucination phenomenon as the major challenges that limit the system's performance. © 2024 IEEE.},
  author_keywords   = {GraphRAG; KG; LLM; RAG; Wikidata},
  doi               = {10.1109/ISRITI64779.2024.10963661},
  groups            = {Reports assessed for eligibility. 30-50, Reports excluded, Reports sought for retrieval},
  keywords          = {Advanced informations; Case-studies; Graphrag; Knowledge graphs; Language model; Large language model; Model-based systems; Natural language interfaces; Retrieval-augmented generation; Wikidata; Open systems},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004412345&doi=10.1109%2FISRITI64779.2024.10963661&partnerID=40&md5=6feb67265f63c00cfe1fc1ba0fbe7101},
}

@Article{Lehmann20231348,
  author            = {Lehmann, Jens F. and Gattogi, Preetam and Bhandiwad, Dhananjay and Ferré, Sébastien and Vahdati, Sahar},
  journal           = {Frontiers in Artificial Intelligence and Applications},
  title             = {Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering},
  year              = {2023},
  note              = {Cited by: 19; All Open Access; Green Accepted Open Access; Green Open Access; Hybrid Gold Open Access},
  pages             = {1348 - 1356},
  volume            = {372},
  abstract          = {We propose the use of controlled natural language as a target for knowledge graph question answering (KGQA) semantic parsing via language models as opposed to using formal query languages directly. Controlled natural languages are close to (human) natural languages, but can be unambiguously translated into a formal language such as SPARQL. Our research hypothesis is that the pre-training of large language models (LLMs) on vast amounts of textual data leads to the ability to parse into controlled natural language for KGQA with limited training data requirements. We devise an LLM-specific approach for semantic parsing to study this hypothesis. To conduct our study, we created a dataset that allows the comparison of one formal and two different controlled natural languages. Our analysis shows that training data requirements are indeed substantially reduced when using controlled natural languages, which is relevant since collecting and maintaining high-quality KGQA semantic parsing training data is very expensive and time-consuming. © 2023 The Authors.},
  doi               = {10.3233/FAIA230411},
  keywords          = {Computational linguistics; Formal languages; Natural language processing systems; Quality control; Query languages; Semantics; Controlled natural language; Data requirements; Knowledge graphs; Language model; Natural language semantics; Natural languages; Pre-training; Question Answering; Semantic parsing; Training data; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175792468&doi=10.3233%2FFAIA230411&partnerID=40&md5=ec96fd65c382ad8d32c2f3fb7aeeca22},
}

@Conference{Kosten20235272,
  author            = {Kosten, Catherine and Cudre-Mauroux, Philippe and Stockinger, Kurt},
  title             = {Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems},
  year              = {2023},
  note              = {Cited by: 12; All Open Access; Green Accepted Open Access; Green Open Access},
  pages             = {5272 - 5281},
  abstract          = {With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL -a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research. © 2023 IEEE.},
  author_keywords   = {Benchmark for Question Answering over Knowledge Graphs; Language Models; Performance Evaluation},
  doi               = {10.1109/BigData59044.2023.10386182},
  file              = {:Kosten20235272 - Spider4SPARQL_ a Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems.pdf:PDF:https\://arxiv.org/pdf/2309.16248v2},
  keywords          = {Benchmarking; Computational linguistics; Natural language processing systems; Automated methods; Benchmark for question answering over knowledge graph; Complex benchmark; Knowledge graphs; Language model; Natural language questions; Performances evaluation; Query generation; Question Answering; Question answering systems; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184975243&doi=10.1109%2FBigData59044.2023.10386182&partnerID=40&md5=e9f9603deb6910323726ccf90e5ce308},
}

@Conference{Mountantonakis2023,
  author            = {Mountantonakis, Michalis and Tzitzikas, Yannis},
  title             = {Real-Time Validation of ChatGPT facts using RDF Knowledge Graphs},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {3632},
  abstract          = {ChatGPT is an innovative application of Large Language Models (LLMs) that produces detailed and articulate responses across many domains of knowledge. However, it does not provide evidence for its responses, and it returns several erroneous facts, even for popular persons, places and others. For tackling the mentioned limitation, we present the fact checking service of the research prototype GPT∙LODS, which can validate ChatGPT facts by using RDF Knowledge Graphs (KGs) containing high quality structured data. Indeed, GPT∙LODS is able to generate triples for a question, an entity or a given text using ChatGPT. Afterwards, it can validate at real-time the generated ChatGPT triples through DBpedia or LODsyndesis KG (a KG that has indexed 400 other RDF KGs), by combining SPARQL queries, word embeddings and sentence similarity metrics. We present the functionality and use cases of GPT∙LODS, including fact checking, question answering, triples generation from text and comparison of different GPT models. © 2023 Copyright for this paper by its authors.},
  author_keywords   = {ChatGPT; Embeddings; Fact Checking; Knowledge Graphs; LODsyndesis; Provenance; Validation},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Graph embeddings; Natural language processing systems; Resource Description Framework (RDF); ChatGPT; Domain of knowledge; Embeddings; Fact checking; Knowledge graphs; Language model; Lodsyndesis; Provenance; Real-time validation; Validation; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184362692&partnerID=40&md5=241caf1cf1c52cec09cfeb1583443eb8},
}

@Conference{2023,
  title             = {Scholarly QALD 2023 and SemREC 2023 - Joint Proceedings of 1st Scholarly QALD Challenge 2023 and 4th SeMantic Answer Type, Relation and Entity Prediction Tasks Challenge 2023, co-located with 22nd International Semantic Web Conference, ISWC 2023},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {3592},
  abstract          = {The proceedings contain 9 papers. The topics discussed include: when context matters: entity linking in the scholarly domain; NLQxform: a language model-based question to SPARQL transformer; a structure and content prompt-based method for knowledge graph question answering over scholarly data; leveraging LLMs in scholarly knowledge graph question answering; improving subgraph extraction algorithms for one-shot SPARQL query generation with large language models; PSYCHIC: a neuro-symbolic framework for knowledge graph question-answering grounding; BERTologyNavigator: advanced question answering with BERT-based semantics; enhanced GAT: expanding receptive field with meta path-guided RDF rules for two-hop connectivity; and evaluating different methods for semantic reasoning over ontologies.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180801778&partnerID=40&md5=c2ad5e26f2c121747a43d361e9de2083},
}

@Conference{Pliukhin2023,
  author            = {Pliukhin, Dmitrii A. and Radyush, Daniil and Kovriguina, Liubov and Muromtsev, Dmitry I.},
  title             = {Improving Subgraph Extraction Algorithms for One-Shot SPARQL Query Generation with Large Language Models},
  year              = {2023},
  note              = {Cited by: 1},
  volume            = {3592},
  abstract          = {Question answering over scholarly knowledge graphs involves many challenges: complex graph patterns, long-tail distributed data, revision and evolution of the scholarly ontologies, and knowledge graphs incompleteness due to constant research dynamics. In this work, we present an LLM-based approach for SPARQL query generation over Open Research Knowledge Graph (ORKG) for the ISWC SciQA Challenge. Our approach proposes a couple of improvements to the recently published SPARQLGEN approach, that performs one-shot SPARQL query generation by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. Similar to SPARQLGEN, we include heterogeneous data sources in the SPARQL generation prompt: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query. In the current work, we focused on designing subgraph extraction algorithms, that are close to real-life scenarios of generative KGQA, and replaced the random choice of example question-query pair with similarity scoring. © 2023 CEUR-WS. All rights reserved.},
  author_keywords   = {Augmented Large Language Models; Knowledge Graphs Question Answering; Scholarly Knowledge Graphs; SPARQL query generation; Subgraph Extraction},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Data mining; Extraction; Graphic methods; Natural language processing systems; Query processing; Resource Description Framework (RDF); Augmented large language model; Knowledge graph question answering; Knowledge graphs; Language model; Query generation; Question Answering; Scholarly knowledge graph; SPARQL query generation; Subgraph extraction; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180551320&partnerID=40&md5=d3d62c78b1b2b37274a9e88314393de0},
}

@Conference{Taffa2023,
  author            = {Taffa, Tilahun Abedissa and Usbeck, Ricardo},
  title             = {Leveraging LLMs in Scholarly Knowledge Graph Question Answering},
  year              = {2023},
  note              = {Cited by: 1},
  volume            = {3592},
  abstract          = {This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner. The model initially identifies the top-n similar training questions related to a given test question via a BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the top-n similar question-SPARQL pairs as an example and the test question creates a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of the Scholarly-QALD-23 challenge benchmarks. © 2023 CEUR-WS. All rights reserved.},
  author_keywords   = {Knowledge Graph Question Answering (KGQA); Large Language Model; Open Research Knowledge Graph; ORKG; Scholarly KGQA; Scholarly-QALD; SciQA},
  file              = {:Taffa2023 - Leveraging LLMs in Scholarly Knowledge Graph Question Answering.pdf:PDF:https\://arxiv.org/pdf/2311.09841v1},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Knowledge management; Natural language processing systems; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Open research KG; Open research knowledge graph; Question Answering; Scholarly knowledge graph question answering; Scholarly-QALD; SciQA; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546080&partnerID=40&md5=ccf7f534c71dcf553c48378d6818a7ee},
}

@Conference{Jiang2023,
  author            = {Jiang, Longquan and Xi, Yan and Usbeck, Ricardo},
  title             = {A Structure and Content Prompt-based Method for Knowledge Graph Question Answering over Scholarly Data},
  year              = {2023},
  note              = {Cited by: 4},
  volume            = {3592},
  abstract          = {Answering scholarly questions is challenging without the help of query-based systems. Thus, we develop a divide-and-conquer approach based on a Large Language Model (LLM) for scholarly Knowledge Graph (KG) Question Answering (QA). Our system integrates the KG ontology into the LLM prompts and leverages a hybrid prompt learning strategy with both query structure and content. Our experiments suggest that given an ontology of a specific KG, LLMs are capable of automatically choosing the corresponding classes or predicates required to generate a target SPARQL query from a natural language question. Our approach shows state-of-the-art results over one scholarly KGQA dataset, namely sciQA [1]. © 2023 CEUR-WS. All rights reserved.},
  author_keywords   = {KGQA; Large Language Model; Question Answering; Scholarly KGQA},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Natural language processing systems; Ontology; Divide-and-conquer approach; KGQA; Knowledge graphs; Language model; Large language model; Learning strategy; Ontology's; Query structures; Question Answering; Scholarly KGQA; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180545725&partnerID=40&md5=f5ab3853af26941c54e4799988381362},
}

@Conference{Lippolis2023,
  author            = {Lippolis, Anna Sofia and Klironomos, Antonis and Milon-Flores, Daniela F. and Zheng, Heng and Jouglar, Alexane and Norouzi, Ebrahim and Hogan, Aidan},
  title             = {Enhancing Entity Alignment Between Wikidata and ArtGraph Using LLMs},
  year              = {2023},
  note              = {Cited by: 3},
  volume            = {3540},
  abstract          = {Knowledge graphs (KGs) are used in a wide variety of applications, including within the cultural heritage domain. An important prerequisite of such applications is the quality and completeness of the data. Using a single KG might not be enough to fulfill this requirement. The absence of connections between KGs complicates taking advantage of the complementary data they can provide. This paper focuses on the Wikidata and A rtG raph KGs, which exhibit gaps in content that can be filled by enriching one with data from the other. Entity alignment can help to combine data from KGs by connecting entities that refer to the same real-world entities. However, entity alignment in art-domain knowledge graphs remains under-explored. In the pursuit of entity alignment between A rtG raph and Wikidata, a hybrid approach is proposed. The first part, which we call WES (Wikidata Entity Search), utilizes traditional Wikidata SPARQL queries and is followed by a supplementary sequence-to-sequence large language model (LLM) pipeline that we denote as pArtLink. The combined approach successfully aligned artworks and artists, with WES identifying entities for 14,982 artworks and 2,029 artists, and pArtLink further aligning 76 additional artists, thus enhancing the alignment process beyond WES’ capabilities. © 2023 Copyright for this paper by its authors.},
  author_keywords   = {ArtGraph; Entity alignment; Knowledge-graphs; Large Language Models; Wikidata},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Alignment; Computational linguistics; Artgraph; Complementary data; Cultural heritages; Entity alignment; Entity search; Knowledge graphs; Language model; Large language model; Real-world entities; Wikidata; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178311919&partnerID=40&md5=ba7501ef8c69f4154305acfc78c3f637},
}

@Article{2023,
  journal           = {Communications in Computer and Information Science},
  title             = {8th China Conference on Knowledge Graph and Semantic Computing, CCKS 2023},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {1923 CCIS},
  abstract          = {The proceedings contain 28 papers. The special focus in this conference is on Knowledge Graph and Semantic Computing. The topics include: A Generalized Strategy of Chinese Grammatical Error Diagnosis Based on Task Decomposition and Transformation; conversational Search Based on Utterance-Mask-Passage Post-training; financial Fraud Detection Based on Deep Learning: Towards Large-Scale Pre-training Transformer Models; GERNS: A Graph Embedding with Repeat-Free Neighborhood Structure for Subgraph Matching Optimization; feature Enhanced Structured Reasoning for Question Answering; conditional Knowledge Graph: Design, Dataset and a Preliminary Model; ODKG: An Official Document Knowledge Graph for the Effective Management; CCD-ASQP: A Chinese Cross-Domain Aspect Sentiment Quadruple Prediction Dataset; move Structure Recognition in Scientific Papers with Saliency Attribution; causE: Towards Causal Knowledge Graph Embedding; Moral Essential Elements: MEE-A Dataset for Moral Judgement; improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views; single Source Path-Based Graph Neural Network for Inductive Knowledge Graph Reasoning; a Graph Learning Based Method for Inductive Knowledge Graph Relation Prediction; LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base; Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts; in-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models; a Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement; Advanced PromptCBLUE Performance: A Novel Approach Leveraging Large Language Models; exploring the Logical Expressiveness of Graph Neural Networks by Establishing a Connection with C<inf>2</inf> ; research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information; harvesting Event Schemas from Large Language Models; NTDA: Noise-Tolerant Data Augmentation for Document-Level Event Argument Extraction; Event-Centric Opinion Mining via In-Context Learning with ChatGPT; relation Repository Based Adaptive Clustering for Open Relation Extraction.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176944442&partnerID=40&md5=31c7f557ca86da031421f9b1bdf59b96},
}

@Conference{Kovriguina2023,
  author            = {Kovriguina, Liubov and Teucher, Roman and Radyush, Daniil and Muromtsev, Dmitry I.},
  title             = {SPARQLGEN: One-Shot Prompt-based Approach for SPARQL Query Generation},
  year              = {2023},
  note              = {Cited by: 9},
  volume            = {3526},
  abstract          = {In this work, we present a one-shot generative approach (further referred to as SPARQLGEN) for generating SPARQL queries by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. The prompt includes heterogeneous data sources: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query for a different question. In the experiments, GPT-3, a popular pre-trained language model from OpenAI, was leveraged, but it is possible to extend the approach to any other generative LLM. We evaluate, how different types of context in the prompt influence the query generation performance on QALD-9, QALD-10 and Bestiary dataset (BESTIARY), which was created to test LLM performance on unseen data, and provide a detailed error analysis. One of the findings is that providing the model with the underlying KG and a random correct query improve the generation results. The approach shows strong results on QALD-9 dataset, but doesn’t generalize on QALD-10 and BESTIARY which can be caused by memorization problem. © 2023 CEUR-WS. All rights reserved.},
  author_keywords   = {Augmented Large Language Models; Knowledge Graphs Question Answering; Prompt Template Design; SPARQL query generation},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Computational linguistics; Knowledge graph; Natural language processing systems; Resource Description Framework (RDF); Statistical tests; Augmented large language model; Heterogeneous data sources; Knowledge graph question answering; Knowledge graphs; Language model; Prompt template design; Query generation; Question Answering; SPARQL query generation; Template designs; Query processing},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176588073&partnerID=40&md5=c408e2ce15847ce28f17e9d1edb1c112},
}

@Conference{2023,
  title             = {SEMPDS 2023 - Proceedings of the Posters and Demo Track of the 19th International Conference on Semantic Systems, co-located with 19th International Conference on Semantic Systems, SEMANTiCS 2023},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {3526},
  abstract          = {The proceedings contain 9 papers. The topics discussed include: a framework generate, store, and publish FAIR data in experimental sciences; a mapping lifecycle for public procurement data; a toolset for normative interpretations in FLINT; developing a scalable benchmark for assessing large language models in knowledge graph engineering; enhancing interpretability of machine learning models over knowledge graphs; OntoAnon: an anonymizer for sharing ontology structure without data; SPARQLGEN: one-shot prompt-based approach for SPARQL query generation; and towards assessing FAIR research software best practices in an organization using RDF-star.},
  groups            = {Records Excluded},
  journal           = {CEUR Workshop Proceedings},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176562472&partnerID=40&md5=9fa6810968538af5fcc8f972422a755d},
}

@Article{2023,
  journal           = {Lecture Notes in Computer Science},
  title             = {20th Extended Semantic Web Conference, ESWC 2023},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {13998 LNCS},
  abstract          = {The proceedings contain 93 papers. The special focus in this conference is on Extended Semantic Web. The topics include: AgriNER: An NER Dataset of Agricultural Entities for the Semantic Web; clayBot: Increasing Human-Centricity in Conversational Recommender Systems; mining Symbolic Rules to Explain Lung Cancer Treatments; GLENDA: Querying RDF Archives with Full SPARQL; Piloting Topic-Aware Research Impact Assessment Features in BIP! Services; explanation-Based Tool for Helping Data Producers to Reduce Privacy Risks; pathWays: Entity-Focused Exploration of Heterogeneous Data Graphs; a Geological Case Study on Semantically Triggered Processes; A System for Repairing $${\mathcal{E}\mathcal{L}}$$ Ontologies Using Weakening and Completing; sparnatural: A Visual Knowledge Graph Exploration Tool; a User Interface Model for Digital Humanities Research: Case BookSampo – Finnish Fiction Literature on the Semantic Web; modeling Grammars with Knowledge Representation Methods: Subcategorization as a Test Case; TRIC: A Triples Corrupter for Knowledge Graphs; ExeKGLib: Knowledge Graphs-Empowered Machine Learning Analytics; hannotate: Flexible Annotation for Text Analytics from Anywhere; study-Buddy: A Knowledge Graph-Powered Learning Companion for School Students; On the Problem of Automatically Aligning Indicators to SDGs; automating Benchmark Generation for Named Entity Recognition and Entity Linking; VRKG-CollaborativeExploration - Data-Driven Discussions in the Metaverse; FOO: An Upper-Level Ontology for the Forest Observatory; integrating Faceted Search with Data Analytic Tools in the User Interface of ParliamentSampo – Parliament of Finland on the Semantic Web; roXi: A Framework for Reactive Reasoning; SummaryGPT: Leveraging ChatGPT for Summarizing Knowledge Graphs; entity Typing with Triples Using Language Models; addressing the Scalability Bottleneck of Semantic Technologies at Bosch; Knowledge Injection to Counter Large Language Model (LLM) Hallucination; towards the Deployment of Knowledge Based Systems in Safety-Critical Systems; a Source-Agnostic Platform for Finding and Exploring Ontologies at Bosch; wisdom of the Sellers: Mining Seller Data for eCommerce Knowledge Graph Generation.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175965513&partnerID=40&md5=2f734909c53a66c228b68809319185d7},
}

@Conference{Klager2023171,
  author            = {Klager, Gerhard G. and Polleres, Axel Florian},
  title             = {Is GPT fit for KGQA? – Preliminary Results},
  year              = {2023},
  note              = {Cited by: 4},
  pages             = {171 - 191},
  volume            = {3447},
  abstract          = {In this paper we report about preliminary results on running question answering benchmarks against the recently hyped conversational AI services such as ChatGPT: we focus on questions that are known to be possible to be answered by information in existing Knowledge graphs such as Wikidata. In a preliminary study we experiment, on the one hand, with questions from established KGQA benchmarks, and on the other hand, present a set of questions established in a student experiment, which should be particularly hard for Large Language Models (LLMs) to answer, mainly focusing on questions on recent events. In a second experiment, we assess how far GPT could be used for query generation in SPARQL. While our results are mostly negative for now, we hope to provide insights for further research in this direction, in terms of isolating and discussing the most obvious challenges and gaps, and to provide a research roadmap for a more extensive study planned as a current master thesis project. © 2023 CEUR-WS. All rights reserved.},
  author_keywords   = {GPT; KGQA; LLMs; Question Answering},
  journal           = {CEUR Workshop Proceedings},
  keywords          = {Natural language processing systems; GPT; KGQA; Knowledge graphs; Language model; Large language model; Query generation; Question Answering; Research roadmap; Set of questions; Student experiments; Knowledge graph},
  publication_stage = {Final},
  source            = {Scopus},
  type              = {Conference paper},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169102980&partnerID=40&md5=bb331974a8da999aabf59b44e16e6bc4},
}

@Article{2025,
  journal           = {Lecture Notes in Computer Science},
  title             = {European Semantic Web Conference, ESWC 2024},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {15344 LNCS},
  abstract          = {The proceedings contain 75 papers. The special focus in this conference is on Semantic Web. The topics include: LLMs4OM: Matching Ontologies with Large Language Models; NeOn-GPT: A Large Language Model-Powered Pipeline for Ontology Learning; Assessing the Evolution of LLM Capabilities for Knowledge Graph Engineering in 2023; column Property Annotation Using Large Language Models; Can LLMs Generate Competency Questions?; 12 Shades of RDF: Impact of Syntaxes on Data Extraction with Language Models; validating Semantic Artifacts with Large Language Models; ontoChat: A Framework for Conversational Ontology Engineering Using Language Models; dataset Management Powered by Semantic Web Technologies; Optimizing Aerospace Product Maintenance: A Novel Multi-Modal Knowledge Graph and LLM Approach for Enhanced Decision Support; LLM-Based Guided Generation of Ontology Term Definitions; towards Solid-Based B2B Data Value Chains; Rapid Graph Generation from Job Descriptions: Combining Taxonomies and LLMs; FAIR Internet of Things Data: Enabling Process Optimization at Munich Airport; product Information Management Systems Powered by Knowledge Graphs; artSampo – Finnish Art on the Semantic Web; towards Semantic Annotation for Scientific Datasets; a Framework for Question Answering on Knowledge Graphs Using Large Language Models; KinGVisher – Knowledge Graph Visualizer; gotta Catch’em All: From Data Silos to a Knowledge Graph; The Helmholtz Knowledge Graph: Driving the Transition Towards a FAIR Data Ecosystem in the Helmholtz Association; Data Search and Discovery in RDF Sources; MLSeascape: Search over Machine Learning Metadata Empowered by Knowledge Graphs; SCOOP-UI: SHACL Shape Extraction in Just a Click!; converter: Enhancing Interoperability in Research Data Management; RDFminer: An Interactive Tool for the Evolutionary Discovery of SHACL Shapes; MusicBO, an Application of Text2AMR2FRED to the Musical Heritage Domain; RDF2vec Embeddings for Updateable Knowledge Graphs – Reuse, Don’t Retrain!; critical Path Identification in Supply Chain Knowledge Graphs with Large Language Models; observations on Bloom Filters for Traversal-Based Query Execution over Solid Pods; PySPARQL Anything Showcase.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218675521&partnerID=40&md5=3fae09c5dfa9e1a714b11558c089562c},
}

@Article{2025,
  journal           = {Lecture Notes in Computer Science},
  title             = {22nd European Semantic Web Conference, ESWC 2025},
  year              = {2025},
  note              = {Cited by: 0},
  volume            = {15718 LNCS},
  abstract          = {The proceedings contain 19 papers. The special focus in this conference is on European Semantic Web. The topics include: OWL<inf>strict</inf>: A Constrained OWL Fragment to Avoid Ambiguities for Knowledge Graph Practitioners; py-amr2fred: A Python Library for Converting Text into OWL-Compliant RDF KGs; LLM-Supported Mapping Generation for Semantic Manufacturing Treasure Hunting; knowledge Graph Construction for Health, Lifestyle and Fitness Applications; Semantic Technologies for Global Governance: A Hybrid AI Approach to Tracking and Monitoring WHO Resolutions; research Knowledge Graphs: The Shifting Paradigm of Scholarly Information Representation; MOOC on Linguistic Linked Data; ontoAligner: A Comprehensive Modular and Robust Python Toolkit for Ontology Alignment; Interoperable Interpretation and Evaluation of ODRL Policies; the Semantic Web Language Server: Enhancing the Developer Experience for Semantic Web Practitioners; mobilityDCAT-AP: A Metadata Specification for Enhanced Cross-Border Mobility Data Sharing; LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models; DBpedia-TKG: Capturing Wikipedia’s Evolution as Temporal Knowledge Graphs; LLM-KG-Bench 3.0: A Compass for Semantic Technology Capabilities in the Ocean of LLMs; Incremunica: Web-Based Incremental View Maintenance for SPARQL; showVoc: A Thorough Platform for Publishing and Browsing Linked Open Datasets; Procedural Knowledge Ontology (PKO).},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007976068&partnerID=40&md5=6f00ebc82ac43e42cb161098fad3f26d},
}

@Article{2023,
  journal           = {Lecture Notes in Computer Science},
  title             = {22nd International Semantic Web Conference, ISWC 2023},
  year              = {2023},
  note              = {Cited by: 0},
  volume            = {14266 LNCS},
  abstract          = {The proceedings contain 58 papers. The special focus in this conference is on Semantic Web. The topics include: How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs; iterative Geographic Entity Alignment with Cross-Attention; entity-Relation Distribution-Aware Negative Sampling for Knowledge Graph Embedding; negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding; comparison of Knowledge Graph Representations for Consumer Scenarios; a Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning; Compact Encoding of Reified Triples Using HDTr; causal Inference-Based Debiasing Framework for Knowledge Graph Completion; Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family; Dense Re-Ranking with Weak Supervision for RDF Dataset Search; mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation; integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces; LLMs4OL: Large Language Models for Ontology Learning; biomedical Knowledge Graph Embeddings with Negative Statements; knowledge Graph Enhanced Language Models for Sentiment Analysis; TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs; Assessing the Generalization Capabilities of Neural Machine Translation Models for SPARQL Query Generation; linking Tabular Columns to Unseen Ontologies; neural Multi-hop Logical Query Answering with Concept-Level Answers; ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs; Optimizing SPARQL Queries with SHACL; SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT; visualizing Mappings Between Pairwise Ontologies - An Empirical Study of Matrix and Linked Indented List in Their User Support During Class Mapping Creation and Evaluation; FeaBI: A Feature Selection-Based Framework for Interpreting KG Embeddings; CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion; HAEE: Low-Resource Event Detection with Hierarchy-Aware Event Graph Embeddings; textual Entailment for Effective Triple Validation in Object Prediction.},
  groups            = {Records Excluded},
  publication_stage = {Final},
  ranking           = {rank1},
  source            = {Scopus},
  type              = {Conference review},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177448280&partnerID=40&md5=5a6a808bf67cfb68607e7e3cb9533d1f},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Records Excluded\;0\;0\;0x60bf8aff\;CLOSE_BOX\;\;;
1 StaticGroup:Reports sought for retrieval\;0\;1\;0x607abfff\;MAGNIFY\;Those that survived the screening process. Must be 40-60\;;
1 StaticGroup:Reports not retrieved\;0\;1\;0xbf6095ff\;MDI_CLOSE_OCTAGON\;paywall, missing pdfs etc\;;
1 StaticGroup:Reports assessed for eligibility. 30-50\;0\;0\;0xbfa560ff\;DOWNLOAD\;Those we managed to retrieve as documents\;;
1 StaticGroup:Reports excluded\;0\;1\;0x8fbf60ff\;CLOSE_CIRCLE_MULTIPLE_OUTLINE\;\;;
1 StaticGroup:Included in Review\;0\;1\;\;MDI_CHECK\;Final group, should be around 20-30 papers.\;;
}
