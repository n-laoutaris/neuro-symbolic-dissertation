\chapter{Systematic Literature Review} \label{ch:slr}
This chapter details a Systematic Literature Review (SLR) with the goal to establish the necessary theoretical foundations of Neuro-Symbolic AI, narrowing the scope where necessary to the context defined as this dissertation's motivations in the previous chapter.

\section{Introduction}
We approach the current research in Neuro-Symbolic AI specifically focusing on how Large Language Models (LLMs) and Knowledge Graphs (KGs) are combined. We aim to find existing approaches for extracting rules from text and generating formal logic (with a focus on SPARQL and SHACL particularly), as well as methods of evaluating the results of such a process.

\section{Methodology}
To ensure scientific strictness and reproducibility, the review adheres to the PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) guidelines \cite{prisma}. The process was structured into four phases, which themselves define the structure of the rest of this chapter.
\begin{enumerate}
    \item Defined the Research Questions (RQs).
    \item Formulated a query and executed a search on the \textit{Scopus} database.
    \item Applied a two-stage screening process: An initial \textit{practical} screening of only titles and abstracts, and then a more thorough \textit{quality assessment} screening of the full texts. These screenings utilized specific inclusion/exclusion criteria and quality assessment criteria.
    \item Extracted data from the selected primary studies into a standardized matrix to synthesize key themes and composed them into a thematic analysis.
\end{enumerate}

\subsection{PRISMA Flow Diagram}
The above search and screening process can be summarized in the PRISMA flow diagram (Figure \ref{fig:prisma}). \par
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/prisma_flow_diagram.pdf}
    \caption{PRISMA Flow Diagram of the selection process}
    \label{fig:prisma}
\end{figure}

\subsection{Research Questions}
To achieve our objective, we defined three Research Questions that guided the data extraction and synthesis process:
\begin{itemize}
    \item \textbf{RQ1:} How are Large Language Models (LLMs) currently utilized to extract structured knowledge and conditional rules from unstructured text?
    \item \textbf{RQ2:} What are the state-of-the-art approaches for translating natural language requirements into executable constraint languages (specifically SHACL and SPARQL)?
    \item \textbf{RQ3:} What methodologies exist for evaluating the functional correctness and operational stability of LLM-generated logic?
\end{itemize}
\textbf{RQ1} explores the initial phases of the proposed pipeline (Text-to-Graph). \textbf{RQ2} deals with logic generation, being the core challenge of the proposed system. \textbf{RQ3} allows to examine how existing studies evaluate trust and correctness.

\subsection{Search Strategy}
To identify relevant records, an automated search was performed on the \textit{Scopus} database. The search was executed on the 1st of December 2025. The search query was formed in a way able to find the intersection of Generative AI and Semantic Web technologies. We employed Boolean logic to combine three conceptual blocks:
\begin{enumerate}
    \item \textbf{Generative AI Terms:} ("Large Language Model" OR "LLM")
    \item \textbf{Target Logic:} ("SHACL" OR "SPARQL")
    \item \textbf{Symbolic Terms:} ("Semantic Web" OR "Knowledge Graph")
\end{enumerate}
These blocks were combined using the \texttt{AND} operator. Thus, the final search string applied to the Title, Abstract, and Keywords fields was:
\begin{quote}
\texttt{( "Large Language Model" OR "LLM" ) AND \\
( "SHACL" OR "SPARQL" ) AND \\ 
( "Semantic Web" OR "Knowledge Graph" )}
\end{quote}
We also applied some necessary metadata filters during this phase:
\begin{itemize}
    \item \textbf{Language:} Only papers written in English were considered.
    \item \textbf{Document Type:} We restricted the search to Articles and Conference Papers, excluding trade journals and errata.
\end{itemize}
Interestingly, despite the Date Range not being restricted, all results fell in the range of years 2023--2026. This could be an indication that the application of Large Language Models to formal constraint languages like SHACL is a newly emerging field, that appeared primarily after the widespread adoption of "GPT-4 class" models. \par
The described search strategy yielded an initial set of 125 candidates which, after removing 3 duplicates, were then subjected to the screening process described next.

\subsection{Inclusion/Exclusion Criteria}
We established a set of inclusion and exclusion criteria that reflect the focus of this review. These were applied to Titles and Abstracts during the initial "Practical Screening" phase of the 122 records. Table \ref{tab:criteria} summarizes the criteria used. \par
\begin{table}[htbp]
    \centering
    \caption{Inclusion and Exclusion Criteria}
    \label{tab:criteria}
    \renewcommand{\arraystretch}{1.4} % Adds breathing room to rows
    \resizebox{\textwidth}{!}{ % Resize to fit page width
    \begin{tabular}{|p{0.15\textwidth}|p{0.4\textwidth}|p{0.4\textwidth}|}
        \hline
        \textbf{Category} & \textbf{Inclusion Criteria} & \textbf{Exclusion Criteria} \\ \hline
        
        \textbf{Task Focus} & 
        Text-to-Graph extraction, Text-to-SPARQL, SHACL shapes generation, GraphRAG architectures. & 
        Pure NLP (summarization), low-level graph mechanics (Entity Alignment, Link Prediction, Subgraph Extraction), Dataset creation. \\ \hline
        
        \textbf{Methodology} & 
        Neuro-Symbolic architectures, Prompt Engineering for logic generation, Fine-tuning, Evaluation Frameworks for Semantic Accuracy. & 
        Traditional Machine Learning (non-generative), Reinforcement Learning without LLMs. \\ \hline
        
        \textbf{Data Flow} & 
        \textit{Forward:} Transforming unstructured text into formal logic or structured data (Text $\rightarrow$ Logic). & 
        \textit{Reverse:} Transforming structured data into natural language (Verbalization/Explanation). \\ \hline

        \textbf{Mode} & 
        Textual inputs with or without pre-processing. & 
        Multimodal studies (Speech/Image), Computer Vision, Temporal Data. \\ \hline
        
        \textbf{Type} & 
        Peer-reviewed Articles and Conference Papers. & 
        Conference Proceedings (Meta-entries), Posters, Editorials, Preliminary Results. \\ \hline
    \end{tabular}
    }
\end{table}
This screening process excluded 61 papers from the review. The rest were sought for retrieval from official channels. Of the 61 papers sought, 8 could not be retrieved due to access restrictions (paywall). The remaining 53 were downloaded and assessed for eligibility by reading the full text. In this "Quality Screening" phase, we applied a second set of quality exclusion criteria (QE), with the goal to further focus our scope and increase relevance to this study.
\begin{itemize}
    \item \textbf{QE1 (Domain \& Logic Mismatch):} From articles situated in descriptive scientific domains (e.g., bioinformatics, chemistry), exclude those where the knowledge structure is purely factual or relational rather than normative or rule-based. These are suspected of offering low transferability to eligibility logic.
    \item \textbf{QE2 (Complexity \& Task Focus):} From studies focusing on simple factoid Question Answering (KGQA), exclude those that do not analyze the extraction or generation of complex conditional constraints required for compliance or eligibility. Otherwise, the core challenge and objective shifts significantly.
    \item \textbf{QE3 (Methodological Maturity):} From studies focusing on model-vs-model benchmarking or evaluation of existing datasets, exclude those that do not propose some novel approaches, architectures or logic validation frameworks. Benchmarking generally falls outside the scope of this research.
\end{itemize}
Following this quality assessment, 28 papers were excluded from the review (13 due to QE1, 6 due to QE2 and 9 due to QE3), leaving 25 papers to be included.

\section{Results - Data Extraction Matrix}
Table \ref{tab:extraction_matrix} presents the data extraction summary for the 25 included studies. The studies are categorized thematically, to reflect the research trajectory: from domain-specific applications in public administration and normative compliance, through the technical mechanisms of logic synthesis, to the frameworks of validation and trust. 
{ \small
\begin{longtable}[c]{|p{2.6cm}|p{2.8cm}|p{1.4cm}|p{3.5cm}|p{3.3cm}|}
    \caption{Data Extraction Matrix of Included Studies ($n=25$)} \label{tab:extraction_matrix} \\
    \hline
    \textbf{Study} & \textbf{Core Task / Domain} & \textbf{Logic} & \textbf{Neuro-Symbolic Integration} & \textbf{Validation Method} \\ \hline
    \endfirsthead

    \multicolumn{5}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\ \hline
    \textbf{Study} & \textbf{Core Task / Domain} & \textbf{Logic} & \textbf{Neuro-Symbolic Integration} & \textbf{Validation Method} \\ \hline
    \endhead % This is where headers for page 2+ stop

    \hline
    \multicolumn{5}{|r|}{{Continued on next page...}} \\ \hline
    \endfoot % This is the footer for split pages

    \hline
    \endlastfoot % This is the final footer (usually just a line)

    \multicolumn{5}{|c|}{\textit{Category 1: Public Administration \& Normative Compliance}} \\ \hline
    Konstantinidis (2025) \cite{Konstantinidis2025} & Recommendation (Public Services) & RDF, SHACL & LLM extraction, SHACL validation & Human Expert Assessment \\ \hline
    Oranekwu (2026) \cite{Oranekwu2026} & Cybersecurity Compliance (IoT) & OWL, SPARQL & Ontology-driven RAG & Similarity over ground truth \\ \hline
    Spyropoulos (2025) \cite{Spyropoulos2025} & Entity Mining (Police Reports) & RDF, OWL & LLM Entity Extraction \& linking & Visual and SPARQL Verification \\ \hline
    Hanuragav (2025) \cite{Hanuragav2025} & CSR Validation (Medical) & SHACL, SPARQL &  RTF to JSON to RDF with YAML mapper & SHACL (structure), SPARQL (content) \\ \hline

    \multicolumn{5}{|c|}{\textit{Category 2: Automated Logic Synthesis \& Semantic Parsing}} \\ \hline
    Agarwal (2024) \cite{Agarwal202410119} & Complex QA (KGQA) & KoPL & SymKGQA: Symbolic Program Generation & Hits@1 and F1 on Benchmarks \\ \hline
    Avila (2025) \cite{Avila202576} & Scientific QA (KGQA) & SPARQL & Text-to-SPARQL with RAG + Few-shot ICL & F1 on Benchmarks \\ \hline
    Jiang (2025) \cite{Jiang202528} & Multi-KG Generalization (KGQA) & SPARQL & Semantic sketch + KG population & Hits@1 and F1 on Benchmarks \\ \hline
    Shah (2024) \cite{Shah2024125} & Multi-hop QA (KGQA) & Cypher, SPARQL & Text-to-Logic with Few-shot + CoT & Match Accuracy on Benchmarks\\ \hline
    Walter (2026) \cite{Walter2026271} & Reasoning / QA (Multi-domain) & SPARQL & Zero-shot Iterative Agent KG exploration & F1 on Benchmarks \\ \hline
    Soularidis (2024) \cite{Soularidis20247} & Rule Generation (Search \& Rescue) & SWRL & Ontology-driven Text-to-SWRL & F1 on Human Expert \\ \hline
    Lehmann (2023) \cite{Lehmann20231348} & Semantic Parsing (Wikidata) & CNL, SPARQL & Controlled Natural Language to Logic & Hits@1 on Benchmarks \\ \hline
    Kovriguina (2023) \cite{Kovriguina2023} & SPARQL Generation (Fantasy) & SPARQL & Augmenting prompts with RDF subgraphs & F1-macro on Benchmarks \\ \hline
    Mountantonakis \cite{Mountantonakis2025} (2025) & Cultural Heritage (Art) & SPARQL & Path Pattern prediction + query generation & Accuracy on Benchmark \\ \hline
    Ongris (2024) \cite{Ongris202444} & Wikidata QA (KGQA) & SPARQL & Sequential LLM Chaining + GraphRAG & Jaccard Similarity on Ground Truth \\ \hline
    Vieira da Silva (2024) \cite{VieiradaSilva2024} & Capability Modeling (IoT) & OWL & TBox-contextualized prompting & Pellet (OWL reasoning) + SHACL \\ \hline
    Emonet (2025) \cite{Emonet2025} & Federated QA (Bioinformatics) & SPARQL & ShEx/VoID-driven RAG query generation & Execution Success Rate and F1 \\ \hline
    Mashhaditafreshi (2025) \cite{Mashhaditafreshi202536} & Digital Twins (IoT) & RDF, SHACL & JSON to Aspect Models via bootstrapping & Human evaluation, Jena (RDF syntax) \\ \hline

    \multicolumn{5}{|c|}{\textit{Category 3: Evaluation, Stability \& Trustworthiness}} \\ \hline
    Sequeda (2025) \cite{Sequeda2025} & SQL Databases (Enterprise) & SPARQL & LLM query correction & Comparison with SQL ground truth \\ \hline
    Allemang (2024) \cite{Allemang2025324} & SQL Databases (Enterprise) & SPARQL & Ontology-based Error Detection + Repair & Execution Accuracy on Benchmark \\ \hline
    Gashkov (2025) \cite{Gashkov2025177} & Query Filtering (Multilingual) & SPARQL & LLM-as-a-Judge binary classifier & Answer Trustworthiness on Benchmark \\ \hline
    Adam (2025) \cite{Adam2025} & Statement Verification (Bio-sci) & RDF & RAG using External Snippets & Precision / Recall on fixed dataset \\ \hline
    Meyer (2025) \cite{Meyer2025280} & KGE Benchmarking (Web) & RDF, SPARQL & LLM-KG-Bench 3.0 Framework & Parseable Syntax and F1 \\ \hline
    Kosten (2024) \cite{Kosten2024} & Complex QA (KGQA) & SPARQL & Ontology-based prompt engineering & Execution Accuracy on Benchmark\\ \hline
    Schmidt (2026) \cite{Schmidt20263} & Systematicity Testing (Wiki) & SPARQL & CompoST: Compositional Testing & Compositionality F1 on ground truth \\ \hline
    Tufek (2025) \cite{Tufek202592} & Artifact Validation (Industrial) & SPARQL & Zero-shot Instruction Prompting & Domain-specific Precision, Recall, F1 \\ \hline

    \hline
\end{longtable}
}

\section{Thematic Analysis}
After the described systematic selection process, all included studies were synthesized into a thematic analysis. The idea of this section is to escape the obsolete summarization of papers, but instead to construct a coherent narrative. \par
Three are the primary themes around which the this narrative is structured. First, an exploration of how high-stakes regulatory texts are being formalized in the present. Second, a technical dive into the mechanics of translating natural language into structured executable logic. Finally, a critical assessment of how the correctness and stability of these systems is being verified.

\subsection{Neuro-Symbolic Pipelines in Public Administration}
Neuro-Symbolic AI is frequently characterized as the integration of Large Language Models (LLMs) and Knowledge Graphs (KGs). It seeks to combine the flexibility of neural networks with the rigor of formal ontologies \cite{Allemang2025324}. One of the many goals of this intersection is to address the complexities of public sector data management \cite{Konstantinidis2025}. In this domain, authors are increasingly moving away from unstructured legislative texts and narrative reports and towards formal logic, to enable proactive and data-centric governance \cite{Konstantinidis2025}\cite{Spyropoulos2025}.

\subsubsection{Knowledge Extraction and Formalization}
The transition from unstructured text to formal logic typically follows a multi-stage pipeline. Ideally, such a pipeline is designed to preserve the semantic intricacies that are inherently present in legal rules, while trying to reduce hallucinations or at least control them as much as possible. \cite{Konstantinidis2025}\cite{Oranekwu2026}. \par
Konstantinidis et al. \cite{Konstantinidis2025} utilize LLMs to interpret complex legislative documents (in raw PDF format) which describe public services. First, they extract preconditions for eligibility and then, they translate them into SHACL (SHApes Constraint Language) rules. Their approach touches on Retrieval-Augmented Generation (RAG) and uses prompt chaining, with which they transform the raw input text into RDF-based evidence models. Notably, they make a point ensuring that the extracted rules are grounded in established EU standard vocabularies like \textit{CPSV-AP} and \textit{CCCEV}. \par
Similarly, Oranekwu et al. \cite{Oranekwu2026} employ a RAG pipeline to ingest regulatory texts and manufacturer privacy policies, using LLMs to extract subject-predicate-object triples that are then mapped into a compliance knowledge graph. \par
Spyropoulos and Tsiantos \cite{Spyropoulos2025} focus on law-enforcement archives, using instruction-tuned models like OpenAI o3 on narrative police reports to extract entities and their interrelationships, subsequently converting this knowledge into OWL-compliant triples for ingestion into a triplestore.

\subsubsection{The Role of Intermediate Models}
Intermediate representations serve as \textit{blueprints} or \textit{mappers} that connect unstructured narratives with executable logic \cite{Spyropoulos2025}\cite{Hanuragav2025}. \par
Hanuragav and Gopinath \cite{Hanuragav2025} demonstrate the utility of intermediate representations through a multi-stage pipeline designed for regulatory validation. In their framework, the transition from unstructured rich-text documents into formal RDF is facilitated by a JSON-to-YAML mapper. By using LLMs to draft YAML mapper files rather than direct triples, their architecture decouples the semantic extraction of data from the technical generation of the knowledge graph (thus essentially decoupling logic and reasoning from syntax and formality). This reliance on non-executable intermediate schemas suggests a shift toward modularity in public sector pipelines, where the LLM's role is confined to architectural drafting, a failsafe to ensure that the resulting logic is structurally "anchored" before final conversion. \par 
Konstantinidis et al. \cite{Konstantinidis2025} also utilize intermediate steps to formulate natural language rules into a template format before final SHACL generation, allowing for the hierarchical structuring of evidence data. \par 
Spyropoulos and Tsiantos \cite{Spyropoulos2025} employ intermediate tabular forms to organize recognized entities before they are formally mapped to the OWL ontology. As a side-effect, they report this makes human-in-the-loop validation much easier.

\subsubsection{Current Limitations}
Despite results showing promise, the afformentioned systems are currently characterized as conceptual or pilot-scale prototypes \cite{Konstantinidis2025}\cite{Oranekwu2026}. \par
Konstantinidis et al. \cite{Konstantinidis2025} emphasize that their pipeline is not yet end-to-end operational and faces significant hurdles regarding data fragmentation across administrative silos. \par
A primary critique of current methods is the lack of automated testing at scale. For instance, Oranekwu et al. \cite{Oranekwu2026} note that their ground truth dataset remains limited in statistical generalizability and has not yet undergone testing with end-users, in real-world conditions. \par
Furthermore, Spyropoulos and Tsiantos \cite{Spyropoulos2025} admit to the use of simulated reports rather than authentic documents due to confidentiality, which may raise concerns about not fully capturing the complexity of real-world law-enforcement data. \par
Proposing future work in this sector, authors focus on overcoming legal and policy complexities, as continuous updates are required to accommodate rapidly evolving regulations \cite{Konstantinidis2025}\cite{Oranekwu2026}. Authors also suggest that federated Knowledge Graphs and decentralized technologies (like blockchain) may be necessary to address issues of data ownership and privacy compliance (such as GDPR requirements) \cite{Konstantinidis2025}. Additionally, there is an identified need for more robust benchmarking methods to validate AI-driven interpretations against human-expert evaluations in high-stakes public environments \cite{Konstantinidis2025}\cite{Oranekwu2026}.

\subsection{State-of-the-art in Logic Synthesis}
The challenge of logic synthesis appears to have evolved rapidly. An effort is being made to move toward modular, Neuro-Symbolic pipelines that break down the task of semantically parsing natural language into manageable logical components \cite{Agarwal202410119}\cite{Jiang202528}. These state-of-the-art approaches take advantage of the linguistic fluency of Large Language Models while enforcing the structural constraints of Knowledge Graphs, through various technical mechanisms and intermediate representations \cite{Walter2026271}\cite{Kovriguina2023}\cite{Emonet2025}.

\subsubsection{Technical Mechanisms for Translation}
Notable Neuro-Symbolic techniques for translating natural language to structured logic include Few-shot In-Context Learning (ICL) \cite{Avila202576}, Retrieval-Augmented Generation (RAG) \cite{Emonet2025} and Iterative Agentic Exploration \cite{Walter2026271}. \par
Frameworks such as \textit{SymKGQA} \cite{Agarwal202410119} combine few-shot ICL with function definitions, to generate symbolic programs in \textit{KoPL} (Knowledge Oriented Programming Language), allowing step-by-step reasoning that is independent of the model's pre-trained knowledge of language grammars. Shah et al. \cite{Shah2024125} further enhance this via what they refer to as "Planned Query Guidance", where few-shot examples demonstrate a code-style reasoning process that handles multi-hop transitions line-by-line. \par
To ground logic in specific KG schemas, authors utilize RAG variations that inject minimal subgraphs \cite{Kovriguina2023}, \textit{VoID} (Vocabulary of Interlinked Datasets) descriptions or \textit{ShEx} (Shape Expression) schemas into the prompt \cite{Emonet2025}. For example, \textit{SPARQLGEN} \cite{Kovriguina2023} enriches prompts with a minimal RDF subgraph, sufficient to answer the query, reducing the need for models to memorize the entire graph. Emonet et al. \cite{Emonet2025} utilize \textit{ShEx} to define available predicates for specific classes, which proved to significantly improve the model's ability to generate valid federated queries. \par
The use of RAG is further extended beyond simple fact retrieval to the generation of \textit{ABox} (Assertional Box, storing factual statements) instances for complex domain models. Vieira da Silva et al. \cite{VieiradaSilva2024} demonstrate that providing the full \textit{TBox} (Terminological Box, the schema-level knowledge of an ontology), within the prompt as context is essential. Their findings show that this approach reduced hallucinations when modeling industrial capabilities. By explicitly injecting the \textit{TBox}, the LLM is forced to conform with predefined class hierarchies and relationship constraints, such as domain - range axioms. With this contextualization, the authors claim to ensure that generated instances are both linguistically plausible and logically consistent with the underlying ontology. The result is the successful reduction of of model contradictions and invented properties. \par
Most recent research introduces iterative frameworks like \textit{GRASP} \cite{Walter2026271}, which treats the LLM as an agent. The agent is tasked with exploring a graph through sequential function calls (search, list, execute). Authors claim that this approach allows the model to refine its understanding of the graph's topology iteratively, without being constrained by a fixed context window. Similarly, \textit{SAMM Copilot} \cite{Mashhaditafreshi202536} employs iterative prompting and feedback loops to generate semantic Aspect Models from JSON data. \par
Beyond the choice of underlying model, the selection of the formal target language itself has become a point of contention. A significant shift in logic synthesis came with the proposal by Lehmann et al. \cite{Lehmann20231348} to relinquish formal languages like SPARQL as the target logical form and instead use Controlled Natural Languages (CNLs), such as \textit{SQUALL} or \textit{Sparklis}. The authors argue that  CNLs will require significantly less fine-tuning to achieve high accuracy, since they are linguistically closer to natural language text, huge amount of which is used in LLM pre-training data, and also linguistically closer to the input question. Their findings indicate that despite LLMs struggling with the strict syntax of SPARQL, they show a "deeper understanding" of CNLs, allowing them to generate valid syntactic variations that are semantically equivalent to ground truth. For especially complex queries (comparatives, ordinals, differences), switching the parsing target from SPARQL to a natural and compact language like \textit{SQUALL} seems to as much as double the semantic parsing accuracy.

\subsubsection{Managing Structural Complexity}
Handling complex schema mapping, particularly in event-based or multi-hop scenarios, requires more advanced strategies than simple triple-matching \cite{Jiang202528}\cite{Mountantonakis2025}. \par
Jiang et al. \cite{Jiang202528} propose \textit{OntoSCPrompt}, a two-stage architecture that separates Query Structure Prediction (dubbed Stage-S) from KG Content Population (dubbed Stage-C). In the first stage, the model predicts a sketch or "skeleton" of the SPARQL query, using special placeholders (e.g., [ent], [rel], [cct]), which is then populated with graph-specific identifiers in the second stage. \par
For event-based models like \textit{CIDOC-CRM}, where answering a single question often requires traversing long complex paths, Mountantonakis and Tzitzikas \cite{Mountantonakis2025} introduce a two-stage process using \textit{Ontology Path Patterns}. Their method first predicts the required properties and classes to identify relevant paths of a specific radius before synthesizing the final query, effectively reducing the search space for the LLM.

\subsubsection{Descriptive vs. Prescriptive Logic Synthesis}
At this point of the analysis, it is important to make a distinction. While many (the majority, in fact) technical advancements focus on \textit{Descriptive} Question Answering (QA), which is retrieving factual data such as birthplaces or award winners \cite{Agarwal202410119}\cite{Walter2026271}\cite{Ongris202444}, a distinct and smaller subset of research addresses the synthesis of \textit{Prescriptive} or Normative Rules \cite{Konstantinidis2025}\cite{Soularidis20247}. \par 
Systems like \textit{GraphRAG} \cite{Ongris202444} and \textit{UniKGQA} \cite{Jiang202528} primarily focus on factual retrieval, done by translating natural language into executable queries (SPARQL, Cypher) to fetch stored static values \cite{Agarwal202410119}\cite{Walter2026271}. \par
In contrast, Soularidis et al. \cite{Soularidis20247} and Konstantinidis et al. \cite{Konstantinidis2025} attempt to synthesize formal logic that encodes rules for behavior or eligibility. Soularidis et al. utilize template-driven prompts and RAG to translate natural language rules from the Search and Rescue (SAR) domain into \textit{SWRL} (Semantic Web Rule Language). Similarly, Konstantinidis et al. use LLMs to extract regulatory preconditions from legislative texts and formalize them as SHACL shapes, which serve as machine-readable rules for public service eligibility checks and recommendations. Oranekwu et al. \cite{Oranekwu2026} create a union between the two, by extracting triples from manufacturer privacy policies to verify compliance against structured \textit{NIST} standards.

\subsection{Methodologies for Logic Validation and Trust}
If Neuro-Symbolic systems are to transition from conceptual pilots to operational environments, the methodologies we use in order to to validate their outputs need to become a priority for research. This idea is already shifting the emphasis from simple performance metrics to the establishment of trust and traceability \cite{Lehmann20231348}. Knowledge Graphs serve as the fundamental \textit{source of trust} in these architectures, providing a formal framework to evaluate the validity of queries generated by Large Language Models and acting as a foundation for explaining results \cite{Sequeda2025}.

\subsubsection{Knowledge Graphs as a Source of Grounding and Repair}
The integration of KGs into the validation pipeline provides the necessary grounding to remedy the risks that stem from the probabilistic nature of LLMs \cite{Lehmann20231348}. \par
Allemang and Sequeda \cite{Allemang2025324} introduce \textit{Ontology-based Query Check (OBQC)}, a deterministic approach that utilizes the semantic constraints of an ontology (such as domain - range rules) to identify errors in generated SPARQL queries without relying on an LLM. When an error is detected, an LLM-powered repair mechanism utilizes the previously output deterministic error explanations, to iteratively prompt the model for correction, a cycle that continues until the query passes the ontological rules or reaches a predefined iteration limit. \par
This focus on traceability is further advanced by Adam and Kliegr \cite{Adam2025}, who propose an inherently traceable approach to verification. They instruct LLMs to avoid (internal) factual knowledge and instead find justification for RDF statements within retrieved (external) text snippets. Part of the LLM instructions becomes to directly generate references for every claim they make in the process and the end result.

\subsubsection{Probabilistic vs. Deterministic}
Current literature reveals a quite clear separation between probabilistic and deterministic validation techniques. \par
Probabilistic approaches often rely on benchmarking and "LLM-as-a-Judge" frameworks. Gashkov et al. \cite{Gashkov2025177} employ instruction-tuned LLMs as binary classifiers to act as post-processing filters, removing potentially incorrect SPARQL queries to enhance their \textit{Answer Trustworthiness Score (ATS)}. Similarly, Kosten et al. \cite{Kosten2024} and their \textit{Spider4SPARQL} benchmark \cite{Kosten_2023} evaluate model performances across queries of varying levels of difficulty. They then find that even state-of-the-art models struggle to surpass 51\% accuracy on complex multi-hop tasks. Meyer et al. \cite{Meyer2025280} provide an extensible framework, \textit{LLM-KG-Bench 3.0}, which automates the evaluation of LLM answers using metrics such as normalized triple F1 and string similarity. \par
In contrast, high-stakes domains prioritize deterministic approaches and rigid constraints. Tufek et al. \cite{Tufek202592} focus on validating semantic artifacts against industrial standards (e.g., \textit{OPC UA}), where natural language requirements are translated into SPARQL queries to ensure compliance. The requirement for absolute precision in high-stakes domains has led to the adoption of the \textit{"draft only, never execute"} paradigm As proposed by Hanuragav and Gopinath \cite{Hanuragav2025}, this methodology explicitly prohibits the Large Language Model from direct interaction with the triple store. Instead, the model's output is restricted to intermediate mappers that are subsequently processed by a deterministic Python translator. This creates a symbolic "circuit breaker", ensuring that the final RDF output is idempotent, auditable and strictly compliant with regulatory requirements. This is a level of reliability that probabilistic filtering methods struggle to guarantee. Furthermore, SHACL shapes are frequently used as \textit{logical gates} to enforce structural integrity and detect hallucinations in digital twins and public administration service models \cite{Konstantinidis2025}\cite{Hanuragav2025}\cite{VieiradaSilva2024}.

\subsubsection{Stability and Systematicity}
A critical shortcoming in current validation research is the fact that models fail to maintain logical consistency across novel tasks. Schmidt et al. \cite{Schmidt20263} investigate \textit{systematicity}, defined as the ability of an agent to understand complex expressions built from known components, through the \textit{CompoST} benchmark. Their findings indicate that LLMs have trouble interpreting questions when the complexity of their components deviates from their training samples. In fact, performance scores rarely exceeded 0.57 even under optimal self-contained conditions. This highlights that most current validation is static, that is, comparing an LLM's output against a single "golden standard" answer in a single-pass execution \cite{Shah2024125}\cite{Lehmann20231348}\cite{Sequeda2025}.

\section{Discussion and Research Gap}
The systematic review of the current literature paints a certain picture. The trajectory of Neuro-Symbolic research appears to be moving away from monolithic sequence-to-sequence translation and towards modular pipelines. These pipelines tend to distinguish semantic parsing from logical execution. However, the synthesis of the included studies identifies three fundamental gaps that remain unaddressed, as explained next.

\subsection{The Prescriptive Synthesis Gap: From Facts to Rules}
While the broader field of logic synthesis has achieved high accuracy in descriptive tasks, there is a marked lack of research into the synthesis of prescriptive governance logic. As established in the thematic analysis, dominant frameworks such as \textit{UniKGQA} \cite{Jiang202528} and \textit{GRASP} \cite{Walter2026271} focus almost exclusively on Knowledge Graph Question Answering (KGQA), that is, translating natural language into queries to retrieve stored facts. In contrast, the requirements of digital governance necessitate the synthesis of \textit{rules} rather than just \textit{questions}. \par
If we revisit Table \ref{tab:extraction_matrix}, we can see that even within Category 1 (Public Administration), where we can find studies like Konstantinidis et al. \cite{Konstantinidis2025} that attempt to extract service preconditions, the methodology remains largely conceptual. There is a noticable absence of a means to ensure that synthesized prescriptive logic (SHACL shapes) can survive the edge cases of diverse citizen profiles.

\subsection{The Stability Gap: Correctness vs. Resilience}
A significant paradox emerges in how current literature defines "trust" and "correctness." Current state-of-the-art mechanisms, such as \textit{Ontology-based Query Check (OBQC)} and \textit{LLM-Repair} \cite{Sequeda2025}\cite{Allemang2025324}, are designed as one-off error-correction loops. These systems simply ensure that a specific generated query is semantically valid according to an ontology schema for \textit{a single} execution pass. \par
However, in the context of public service eligibility, the concept of a synthesized rule being similar to a one-off query does not respond well to reality. On the contrary, a rule is more of a permanent logic structure, and one intended for repeated application across potentially heterogeneous datasets. The literature focuses on making the LLM a more accurate translator momentarily, but fails to validate if the resulting logic is \textit{stable} across a spectrum of different inputs. There is no evidence of research into whether a synthesized SHACL shape, once generated, remains logically consistent when tested attributes are systematically altered, a requirement for the proactive "No-Stop Government" vision \cite{Konstantinidis2025}.

\subsection{The Validation Gap: The Need for Mutation Testing}
The most critical shortage identified by this research is the reliance on static or otherwise single-pass validation methodologies. Benchmarks like \textit{CompoST} \cite{Schmidt20263} and \textit{LLM-KG-Bench 3.0} \cite{Meyer2025280} measure accuracy by comparing model outputs against a "golden standard" answer. These metrics are definitely useful for measuring retrieval precision, but they appear to be insufficient for verifying the functional correctness of eligibility rules. \par
As identified in Table \ref{tab:extraction_matrix}, current validation is predominantly probabilistic. Even deterministic approaches, for example those by Hanuragav and Gopinath \cite{Hanuragav2025} or Tufek et al. \cite{Tufek202592}, focus on structural syntax or version-control compliance. To date, no study has implemented a comprehensive \textit{Mutation Testing Framework} to strictly test the structural and logical stability of LLM-generated SHACL shapes. For high-stakes digital governance, an 88\% precision rate (as reported in descriptive tasks \cite{Adam2025}) is not a useful nor representative result. Future frameworks must address the variability of non-deterministic systems by establishing testing methodologies that guarantee logical stability across constantly evolving regulatory landscapes. \par
While Sequeda et al. \cite{Sequeda2025} acknowledge the importance of regression testing to ensure that accuracy does not decrease as ontologies are extended, there is no evidence of widespread use to ensure logic remains resilient under variable conditions. For high-stakes governance and public administration, measuring accuracy on a single pass is simply insufficient.

\section{Contribution of this Study}
Based on the gaps identified above and the established methodologies described in modern literature, this dissertation proposes a Neuro-Symbolic framework that utilizes a \textit{JSON Information Model} as an intermediate architectural stepping stone to generate SHACL-based eligibility rules. SHACL is chosen specifically for its ability to act as a \textit{logical gate}, providing the unified graph structure and explainability required for public administration. \par
To address the topic of validation, this dissertation introduces a custom deterministic \textit{Mutation Testing} framework. By systematically altering (mutating) citizen attributes to evaluate the rejection rate of synthesized SPARQL logic, we try to move beyond probabilistic retrieval to provide a functional guarantee of stability. \par
This approach, explained in granular detail in the following Pilot Study chapter, represents a transition from checking if a model is correct \textit{once}, to verifying that the synthesized law is functionally infallible across variable scenarios.